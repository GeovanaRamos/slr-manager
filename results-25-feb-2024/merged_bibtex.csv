BibtexKey,Title,Abstract,Author,Journal,BookTitle,Year,Doi,Url,Source,CreatedAt,Status
10.1145/3582515.3609536,Data Decentralisation of LLM-Based Chatbot Systems in Chronic Disease Self-Management,"Chronic patient self-management is crucial for maintaining physical and psychological health, reducing pressure on healthcare systems, and promoting patient empowerment. Digital technologies, particularly chatbots, have emerged as powerful tools for supporting patients in managing their chronic conditions. Large language models (LLMs), such as GPT-4, have shown potential in improving chatbot-based systems in healthcare. However, their adoption in clinical practice faces challenges, including reliability, the need for clinical trials, and privacy concerns. This paper proposes a general architecture for developing an LLM-based chatbot system that supports chronic patients while addressing privacy and security concerns. The architecture is designed to be independent of specific technologies and health conditions, focusing on data protection legislation compliance. A prototype of the system has been developed for hypertension management, demonstrating its potential for motivating patients to monitor their blood pressure and adhere to prescriptions.","Montagna, Sara and Ferretti, Stefano and Klopfenstein, Lorenz Cuno and Florio, Antonio and Pengo, Martino Francesco",,Proceedings of the 2023 ACM Conference on Information Technology for Social Good,2023,10.1145/3582515.3609536,https://doi.org/10.1145/3582515.3609536,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3340495.3342751,Hospitality of chatbot building platforms,"The temptation to be able to talk to a machine is not new. Recent advancements in the field of Natural Language Understanding has made it possible to build conversational components that can be plugged inside an application, similar to other components. These components, called chatbots, can be created from scratch or with the help of commercially available platforms. These platforms make it easier to build and deploy chatbots, often without writing a single line of code. However, similar to any other software component, chatbots also have quality concerns. Despite significant contributions in the field, an architectural perspective of building chatbots with desired quality requirements is missing in the literature. In the current work, we highlight the impact of features provided by these platforms (along with their quality) on the application design process and overall quality attributes. We propose a methodological framework to evaluate support provided by a chatbot platform towards achieving quality in the application. The framework, called Hospitality Framework, is based on software architectural body of knowledge, especially architectural tactics. The framework produces a metric, called Hospitality Index, which has utilities for making various design decisions for the overall application. We present the use of our framework on a simple use case to highlight the phases of evaluation. We showcase the process by picking three popular chatbot platforms - Watson Assistant, DialogFlow and Lex, over four quality attributes - Modifiability, Security \&amp; Privacy, Interoperability and Reliability. Our results show that different platforms provide different support for these four quality attributes.","Srivastava, Saurabh and Prabhakar, T.V.",,Proceedings of the 2nd ACM SIGSOFT International Workshop on Software Qualities and Their Dependencies,2019,10.1145/3340495.3342751,https://doi.org/10.1145/3340495.3342751,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3512353.3512363,Privacy and Security in Mixed Reality Learning Environments by Input and User/Bot Interaction Protection,"Mixed reality is known as an advanced technology that provides a new approach for learning environments. Such environments allow learners to interact with both virtual and real worlds and bringing in potential enhancements to the learning process at the same time. For example, chatbots can facilitate the learning process. However, security and privacy settings for interacting with chatbots in such mixed reality environments are complex. In this paper, we introduce a mixed reality virtual assistant that is integrated into the collaborative environment of our existing application VIAProMa. This embodied chatbot allows lecturers and students to participate in mixed reality and online classrooms in real-time. The participants can interact with each other via VIAProMa’s avatar representations and can communicate with the chatbot that is represented by the mixed reality bot. The bot is realized by connecting a Slack chatbot with the mixed reality learning environment. It is displayed as an intuitive 3D model and is able to communicate with the users in spoken language. In this environment, privacy and security settings are conducted to protect the user input and user interaction with the bot. The evaluation results show that the system works stably with good performance. All the visualizations and features are well designed and were understood by the users. Users preferred the speech interface with the bot over a textual interface. The research has a strong impact on the design of security and privacy features for mixed reality environments in general.","Tran, Lan Anh and Hensen, Benedikt and Klamma, Ralf and Chantaraskul, Soamsiri",,Proceedings of the 2022 4th Asia Pacific Information Technology Conference,2022,10.1145/3512353.3512363,https://doi.org/10.1145/3512353.3512363,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3290605.3300857,Transformation through Provocation?,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely.","Roussou, Maria and Perry, Sara and Katifori, Akrivi and Vassos, Stavros and Tzouganatou, Angeliki and McKinney, Sierra",,Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems,2019,10.1145/3290605.3300857,https://doi.org/10.1145/3290605.3300857,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3411764.3445312,Heuristic Evaluation of Conversational Agents,"Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen’s heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We find that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen’s heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy.","Langevin, Raina and Lordon, Ross J and Avrahami, Thi and Cowan, Benjamin R. and Hirsch, Tad and Hsieh, Gary",,Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,2021,10.1145/3411764.3445312,https://doi.org/10.1145/3411764.3445312,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3276954.3276958,Protecting chatbots from toxic content,"There is a paradigm shift in web-based services towards conversational user interfaces. Companies increasingly offer conversational interfaces, or chatbots, to let their customers or employees interact with their services in a more flexible and mobile manner. Unfortunately, this new paradigm faces a major problem, namely toxic content in user inputs. Toxic content in user inputs to chatbots may cause privacy concerns, may be adversarial or malicious, and can cause the chatbot provider substantial economic, reputational, or legal harm. We address this problem with an interdisciplinary approach, drawing upon programming languages, cloud computing, and other disciplines to build protections for chatbots. Our solution, called BotShield, is non-intrusive in that it does not require changes to existing chatbots or underlying conversational platforms. This paper introduces novel security mechanisms, articulates their security guarantees, and illustrates them via case studies.","Baudart, Guillaume and Dolby, Julian and Duesterwald, Evelyn and Hirzel, Martin and Shinnar, Avraham",,"Proceedings of the 2018 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software",2018,10.1145/3276954.3276958,https://doi.org/10.1145/3276954.3276958,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3279972.3279980,Exploring Siamese Neural Network Architectures for Preserving Speaker Identity in Speech Emotion Classification,"Voice-enabled communication is increasingly being used in real-world applications, such as the ones involving conversational bots or ""chatbots"". Chatbots can spark and sustain user engagement by effectively recognizing their emotions and acting upon them. However, the majority of emotion recognition systems rely on rich spectrotemporal acoustic features. Beyond the emotion-related information, such systems tend to preserve information relevant to the identity of the speaker, therefore raising major privacy concerns from the users. This paper introduces two hybrid architectures for privacy-preserving emotion recognition from speech. These architectures rely on a Siamese neural network, whose input and intermediate layers are transformed using various privacy-performing operations in order to retain emotion-dependent content and suppress information related to the identity of a speaker. The proposed approach is evaluated through emotion classification and speaker identification performance metrics. Results indicate that the proposed framework can achieve up to 67.4\% for classifying between happy, sad, frustrated, anger, neutral and other emotions, obtained from the publicly available Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset. At the same time, the proposed approach reduces speaker identification accuracy to 50\%, compared to 81\%, the latter being achieved through a feedforward neural network solely trained on the speaker identification task using the same input features.","Arora, Priya and Chaspari, Theodora",,Proceedings of the 4th International Workshop on Multimodal Analyses Enabling Artificial Agents in Human-Machine Interaction,2018,10.1145/3279972.3279980,https://doi.org/10.1145/3279972.3279980,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3313831.3376315,"Adhering, Steering, and Queering: Treatment of Gender in Natural Language Generation","Natural Language Generation (NLG) supports the creation of personalized, contextualized, and targeted content. However, the algorithms underpinning NLG have come under scrutiny for reinforcing gender, racial, and other problematic biases. Recent research in NLG seeks to remove these biases through principles of fairness and privacy. Drawing on gender and queer theories from sociology and Science and Technology studies, we consider how NLG can contribute towards the advancement of gender equity in society. We propose a conceptual framework and technical parameters for aligning NLG with feminist HCI qualities. We present three approaches: (1) adhering to current approaches of removing sensitive gender attributes, (2) steering gender differences away from the norm, and (3) queering gender by troubling stereotypes. We discuss the advantages and limitations of these approaches across three hypothetical scenarios; newspaper headlines, job advertisements, and chatbots. We conclude by discussing considerations for implementing this framework and related ethical and equity agendas.","Strengers, Yolande and Qu, Lizhen and Xu, Qiongkai and Knibbe, Jarrod",,Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems,2020,10.1145/3313831.3376315,https://doi.org/10.1145/3313831.3376315,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3517745.3561433,Exploring the security and privacy risks of chatbots in messaging services,"The unprecedented adoption of messaging platforms for work and recreation has made it an attractive target for malicious actors. In this context, third-party apps (so-called chatbots) offer a variety of attractive functionalities that support the experience in large channels. Unfortunately, under the current permission and deployment models, chatbots in messaging systems could steal information from channels without the victim's awareness. In this paper, we propose a methodology that incorporates static and dynamic analysis for automatically assessing security and privacy issues in messaging platform chatbots. We also provide preliminary findings from the popular Discord platform that highlight the risks that chatbots pose to users. Unlike other popular platforms like Slack or MS Teams, Discord does not implement user-permission checks---a task entrusted to third-party developers. Among others, we find that 55\% of chatbots from a leading Discord repository request the ""administrator"" permission, and only 4.35\% of chatbots with permissions actually provide a privacy policy.","Edu, Jide and Mulligan, Cliona and Pierazzi, Fabio and Polakis, Jason and Suarez-Tangil, Guillermo and Such, Jose",,Proceedings of the 22nd ACM Internet Measurement Conference,2022,10.1145/3517745.3561433,https://doi.org/10.1145/3517745.3561433,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3449171,Let's Talk It Out: A Chatbot for Effective Study Habit Behavioral Change,"Research has shown study habits and skills to be correlated with academic success, calling for a deeper comprehension of these behaviors and processes to design effective interventions for struggling students. Chatbots have recently been used as a persuasive technology to help support behavioral change, making them an intriguing design space for students' study habits and skills. This paper investigated the feasibility of using chatbots for promoting behavioral change of college students majoring in Computer Science (CS). We conducted semi-structured interviews with CS peer-tutors and surveyed university freshmen to understand students' study habits and identify technical intervention opportunities. Inspired by the findings, we designed StudyBuddy, a chatbot prototype deployed in Slack that periodically sends tips, provides assessments of students' study habits via surveys, helps the students break down assignments, recommends academic resources, and sends reminders. We evaluated the usability of the prototype in-depth with 8 students (both first-year and senior students) and 5 course instructors followed by a large scale evaluative survey (n=117) using video of the prototype. Our research identified important design challenges such as building trust and preserving privacy, limiting interaction costs, and supporting both immediate and long-term sustainable support. Likewise, we proposed design recommendations that demonstrate context awareness, personalize the experience based on user preferences, and adapt over time as students mature and grow.","Tian, Xiaoyi and Risha, Zak and Ahmed, Ishrat and Lekshmi Narayanan, Arun Balajiee and Biehl, Jacob",Proc. ACM Hum.-Comput. Interact.,,2021,10.1145/3449171,https://doi.org/10.1145/3449171,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3625469.3625483,AI Chatbots in Social Media: Ethical Responsibilities and Privacy Challenges of Information and Communication Technology,"In recent years, the pervasive integration of Artificial Intelligence (AI) chatbots into social media platforms has transformed the way individuals communicate and access information. This paper aims to critically examine the ethical responsibilities and privacy challenges associated with the application of Information and Communication Technology (ICT) in AI chatbots within social media environments. The purpose of this investigation is to highlight the complexities surrounding the implementation of chatbots and understand the implications of ICT with regards to ethical and privacy concerns. The study addresses the adoption of AI chatbots for varied applications such as customer support, content moderation, and personalized advertising. The central focus is on how ICT can inadvertently contribute to potential ethical dilemmas, including data bias, transparency, accountability, and privacy breaches. Moreover, the paper explores the existing regulatory frameworks governing the use of AI chatbots and recommends a set of best practices for ensuring ethical compliance and safeguarding user privacy. By evaluating the interplay between AI chatbots and ICT, this research offers valuable insights into the responsibilities and challenges that need to be considered to foster a more ethical and privacy-conscious implementation of AI chatbots in social media.","Liu, Yage",,Proceedings of the 2023 6th International Conference on Information Management and Management Science,2023,10.1145/3625469.3625483,https://doi.org/10.1145/3625469.3625483,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3523150.3523168,Predicting Depression Symptoms from Discord Chat Messaging Using AI Medical Chatbots,"Depression is a chronic illness with even Olympic athletes [1] and top tennis players [2] withdrawing from competitions due to it. It's important to diagnose depression early. Traditional methods rely on questionnaires to evaluate depression. But they have their limitations due to inherent bias and inhibitions in self reporting. We propose an intelligent chatbot powered by AI approach to assist medical professionals diagnose depression. Specifically, the AI could predict depression symptoms in conversations with pre-care health care personnel and/or personal chats. Notably, due to sensitivity and privacy regulation (HIPPA) such data is not readily available [3]. To use AI driven medical assistants, and to overcome this limitation in training AI models, we propose to seed the models with recent chat engine (Discord) conversation dataset in the channel #depression. We achieve at least 73\% accuracy in predicting seven key symptoms for depression using our best ML models. Secondly, with our ensemble random forest model we could recall 30-69\% of depression symptoms with 60-99\% depression diagnosis accuracy which could be further tuned by medical professional if they know which ones of these symptoms is a key predictor of depression.","Duvvuri, Venkata and Guan, Qihan and Daddala, Swetha and Harris, Mitch and Kaushik, Sudhakar",,Proceedings of the 2022 6th International Conference on Machine Learning and Soft Computing,2022,10.1145/3523150.3523168,https://doi.org/10.1145/3523150.3523168,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3461778.3462143,“I wrote as if I were telling a story to someone I knew.”: Designing Chatbot Interactions for Expressive Writing in Mental Health,"Writing about experiences of trauma and other challenges in life is known to provide measurable health benefits. Though writing for an audience may ensure better benefits, confiding one's most troubled memories in others risks a social stigma. Conversational agents can provide a virtual audience that ensures privacy and allows social disclosure. To understand the writing experience with an agent, we created Diarybot, a chatbot assistant for expressive writing. We designed two versions, Basic and Responsive, to explore the writing experience with and without bot follow-up interactions compared to a Google doc baseline. Findings from a 4-day user study with 30 participants reveal that social disclosure with Diarybot can encourage narrative writing, with relative ease and emotional expression in Basic chat. Responsive chat can mediate social acceptance of the bot and provide guidance for self-reflection in the process. We discuss design reflections on social disclosure with agents in pursuit of wellbeing.","Park, SoHyun and Thieme, Anja and Han, Jeongyun and Lee, Sungwoo and Rhee, Wonjong and Suh, Bongwon",,Proceedings of the 2021 ACM Designing Interactive Systems Conference,2021,10.1145/3461778.3462143,https://doi.org/10.1145/3461778.3462143,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3472301.3484358,Posthumous data at stake: An Overview of Digital Immortality Issues,"Who wants to be immortal? While this rhetorical question seems to haunt humans, digital immortality is already a reality. Social networks have allowed and facilitated our digital footprints to remain forever at reach of Internet users. We will all die, on the other hand, our digital self may remain forever. Social media technology has also allowed people to browse or even post messages to maintain the memory of a person alive. It seems spooky, but it is technically feasible to build a chatbot from a deceased person's digital legacy allowing a certain degree of presence of a deceased. This unaware digital immortality brings new cultural, technical, social, ethical, and legal challenges and implications that should be brought to light and discussed. There is an urge to recognize the limits for an adequate use of digital immortality. By means of an overview, this paper reports our literature survey where we identified some key issues regarding digital immortality, looking at the benefits, consequences and complications from its use. Our study identified differences when dealing with famous versus non-famous deceased, explicitly defined public versus private data, right and duties related to data preservation versus deletion, technological advances versus restrictions, cultural impedance, and differences from the reasons for desiring immortalization. With this article, we aim to encourage discussions on digital immortality, its current limits and points that need to be considered regarding such a sensitive theme that is already a current issue.","Galv\~{a}o, Vinicius Ferreira and Maciel, Cristiano and Pereira, Vinicius Carvalho and Garcia, Ana Cristina Bicharra and Pereira, Roberto and Viterbo, Jos\'{e}",,Proceedings of the XX Brazilian Symposium on Human Factors in Computing Systems,2021,10.1145/3472301.3484358,https://doi.org/10.1145/3472301.3484358,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3406522.3446043,Dataset of Natural Language Queries for E-Commerce,"Shopping online is more and more frequent in our everyday life. For e-commerce search systems, understanding natural language coming through voice assistants, chatbots or from conversational search is an essential ability to understand what the user really wants. However, evaluation datasets with natural and detailed information needs of product-seekers which could be used for research do not exist. Due to privacy issues and competitive consequences, only few datasets with real user search queries from logs are openly available. In this paper, we present a dataset of 3,540 natural language queries in two domains that describe what users want when searching for a laptop or a jacket of their choice. The dataset contains annotations of vague terms and key facts of 1,754 laptop queries. This dataset opens up a range of research opportunities in the fields of natural language processing and (interactive) information retrieval for product search.","Papenmeier, Andrea and Kern, Dagmar and Hienert, Daniel and Sliwa, Alfred and Aker, Ahmet and Fuhr, Norbert",,Proceedings of the 2021 Conference on Human Information Interaction and Retrieval,2021,10.1145/3406522.3446043,https://doi.org/10.1145/3406522.3446043,acm.bib,2024-02-25 11:35:40,Unclassified
10.1145/3616961.3616974,"""\""Call me Kiran\"" – ChatGPT as a Tutoring Chatbot in a Computer Science Course""","Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.","Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\""{a}, Pia",,Proceedings of the 26th International Academic Mindtrek Conference,2023,10.1145/3616961.3616974,https://doi.org/10.1145/3616961.3616974,acm.bib,2024-02-25 11:35:40,Unclassified
8814570,Children Privacy Identification System in LINE Chatbot for Smart Toys,"Children's privacy concerns about smart toys are becoming more and more critical in the toy industry. Parents and guardians continue to strive to protect their children from unnecessary privacy risks such as collection, and unconsented use of or access to their children's information. However, there is still no standardized privacy framework, which focuses on smart toys in this paradigm; making it difficult to determine possible privacy violation in for example determining whether a phrase shared with a smart toy is sensitive or not. To overcome this challenge, we build a privacy identification system through Chatbot technology. We call this system a Children Privacy Identification (CPI) system. To develop CPI system, we divide our research works into two parts: (1) Collect the phrase from the smart toys; and (2) Explore privacy Identification based on Personally Identifiable Information (PII) and Children's Online Privacy Protection Act (COPPA). For illustration, we integrate the CPI system in LINE Chatbot. The result shows that people feel more comfortable in talking to LINE Chatbot with privacy protection.","Lin, Pei-Chun and Yankson, Benjamin and Lu, Zhihui and Hung, Patrick C.K.",,2019 IEEE 12th International Conference on Cloud Computing (CLOUD),2019,10.1109/CLOUD.2019.00026,,ieee.bib,2024-02-25 11:35:40,Unclassified
10189497,A Privacy-Preserving Framework for Mental Health Chatbots Based on Confidential Computing,"Mental health chatbots can provide psychological counseling services to patients at any time regardless of time and location, which can not only relieve patients’ ailments but also reduce the workload of psychologists. In order to provide patients with accurate diagnosis and treatment services, mental health robots inevitably collect patient-related information during the communication process with patients, which is often very sensitive and must be well protected. There is a lack of targeted research on how mental health chatbots can provide systematic privacy preserving for patients in the process of providing mental health services to them. In this paper, we propose a privacy preserving framework based on blockchain and confidential computing that can provide comprehensive privacy preserving for patients during mental health chatbot services. We conduct tests using existing mental health chatbots, and the experimental results demonstrate that our proposed framework can meet the requirements for privacy preserving and computational performance of mental health chatbots.","Tian, Wensheng and Lu, Yifan and Yu, Jinhao and Fan, Jiafeng and Tang, Panpan and Zhang, Lei",,"2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)",2022,10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00160,,ieee.bib,2024-02-25 11:35:40,Unclassified
9355474,Privacy Preserving Chatbot Conversations,"With chatbots gaining traction and their adoption growing in different verticals, e.g. Health, Banking, Dating; and users sharing more and more private information with chatbots - studies have started to highlight the privacy risks of chatbots. In this paper, we propose two privacypreserving approaches for chatbot conversations. The first approach applies `entity' based privacy filtering and transformation, and can be applied directly on the app (client) side. It however requires knowledge of the chatbot design to be enabled. We present a second scheme based on Searchable Encryption that is able to preserve user chat privacy, without requiring any knowledge of the chatbot design. Finally, we present some experimental results based on a real-life employee Help Desk chatbot that validates both the need and feasibility of the proposed approaches.","Biswas, Debmalya",,2020 IEEE Third International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),2020,10.1109/AIKE48582.2020.00035,,ieee.bib,2024-02-25 11:35:40,Unclassified
10386087,Saving the Day for Users in Web Platforms: A Chatbot-based Solution for Privacy,"In the rapidly evolving online digital landscape, privacy is an issue of great importance for individuals, while the use of web platforms handling personal data has reached significant levels. Regulations like the European Union General Data Protection Regulation (GDPR) enforce systems to integrate an array of privacy features allowing users to exercise their privacy rights and shield their personal data. However, users tend to find themselves overwhelmed or even ignorant, unsure of how to locate and use them. Research also showed that users find privacy policies hard to read and tend to skip them. This work introduces a novel approach to addressing these privacy concerns by presenting a user-centric solution to enhancing user privacy in web platforms and empowering users in handling their own personal data: an easy-to-use chatbot-based solution. The tool aims to provide a user-friendly and intuitive all-in-one interface, allowing users to easily navigate and access privacy features and manage their personal data while retrieving information about privacy aspects effortlessly from one location. An admin panel enables the customisation of important privacy parameters. We present the design and development process, evaluation and results.","Vanezi, Evangelia and Kallenou, Aliki and Papadopoulos, George A.",,2023 10th International Conference on Behavioural and Social Computing (BESC),2023,10.1109/BESC59560.2023.10386087,,ieee.bib,2024-02-25 11:35:40,Unclassified
10271802,"Security Risks, User Privacy Risks, and a Trust Framework for the Metaverse Space","The Metaverse is an incredible 3D virtual reality experience that anyone worldwide can access. It is a digital space not limited by geography, and it is made up of interconnected systems with unique rules and capabilities. The best thing about the Metaverse is that it allows people to interact with others in an environment that they might not have been able to visit otherwise. It is a perfect way to immerse oneself in other domains, such as entertainment and education, and it is also a great way to collaborate on projects with people worldwide. However, it is essential to note that the trustworthiness of the data collected from the disparate systems for the Metaverse needs to be studied in some areas. Trust is a significant issue in the Metaverse because users will interact with each other and virtual objects in a fully immersive environment. Security risks are also to consider, such as the attack surface that contributes to integrating various cutting-edge technology in the Metaverse. Additionally, the immersive workplace metaverse is subject to privacy risks to the users. Therefore, exploring the Metaverse’s security, privacy, and trust components is crucial to assist in research in these emerging areas. This research paper defines the trust framework and goals for Metaverse space, which are the key ingredients that ensure users use the products or services to buy, renew, and continue to trust their data. It is essential to address the trust issues to ensure the Metaverse is a safe, secure, and trustworthy experience for all users.","Kharvi, Prakash Laxman",,"2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)",2023,10.1109/MetaCom57706.2023.00033,,ieee.bib,2024-02-25 11:35:40,Unclassified
10219493,Transforming Chronic Disease Management with Chatbots: Key Use Cases for Personalized and Cost-effective Care,"Globally, the problem of chronic diseases like diabetes, hypertension, and heart disease is getting worse. These diseases have a significant impact on patients and healthcare systems. Innovative technologies like chatbots, which promise to improve the management of chronic diseases, have emerged as potential solutions to these difficulties. Chatbots are man-made brainpower (artificial intelligence) programs that can recreate discussions with people and give customized and practical consideration. The primary purposes of this study are to investigate the most important applications of chatbots in the management of chronic diseases, including personalized education, symptom monitoring, medication management, and lifestyle coaching. In addition, it discusses the potential advantages and disadvantages of chatbots in the management of chronic diseases, including the need for human oversight, data privacy, and patient engagement. The paper concludes that, although chatbots have the potential to transform the management of chronic diseases by providing personalized and cost-effective care, careful consideration of ethical, legal, and regulatory frameworks is required for their integration into healthcare systems.","Haque, Ahshanul and Chowdhury, Md Naseef-Ur-Rahman and Soliman, Hamdy",,"2023 Sixth International Symposium on Computer, Consumer and Control (IS3C)",2023,10.1109/IS3C57901.2023.00104,,ieee.bib,2024-02-25 11:35:40,Unclassified
10253855,HCPP: A Data-Oriented Framework to Preserve Privacy during Interactions with Healthcare Chatbot,"Healthcare chatbots are becoming increasingly popular, but with their use comes the issues of excessive personal information collection and privacy leakage. To address this issue, we propose a Healthcare Chatbot-based Privacy Preserving (HCPP) Framework that adopts a data-oriented approach to reduce the excessive disclosure of personal information. HCPP consists of two main components: the Healthcare Chatbot-based Minimized Personal Information (HCMPI) method and the Healthcare Chatbot-based Zero Knowledge Proof (HCZKP) method. HCMPI leverages large language models (LLMs) to minimize the acquisition of unnecessary personal health information without significantly affecting healthcare service. HCZKP further encrypts a part of the minimized information, making the data available but invisible. The experimental evaluation results demonstrate the effectiveness and feasibility of our approach.","Cai, Ziyan and Chang, Xin and Li, Ping",,"2023 IEEE International Performance, Computing, and Communications Conference (IPCCC)",2023,10.1109/IPCCC59175.2023.10253855,,ieee.bib,2024-02-25 11:35:40,Unclassified
10320174,Security and Privacy Perceptions of Mental Health Chatbots,"Mental health chatbots are AI chatbots that aim to mimic human conversations about how a user feels, help a user work through issues they are facing, suggest wellness exercises to complete, and help track a user’s mood over time. We compare the information disclosure practices and security and privacy concerns of adopters and non-adopters of mental health chatbots. We conducted a survey with 180 participants (30 adopters, 150 non-adopters), collecting data about what information they would hypothetically disclose to mental health chatbots, and concerns they had related to chatbots. We found that compared to non-adopters, adopters were more trusting of chatbots, were willing to reveal more information, perceived security and privacy risks to be less likely, and took fewer precautions.","Chametka, Paulina and Maqsood, Sana and Chiasson, Sonia",,"2023 20th Annual International Conference on Privacy, Security and Trust (PST)",2023,10.1109/PST58708.2023.10320174,,ieee.bib,2024-02-25 11:35:40,Unclassified
9125183,Work-in-Progress: A Preliminary Study on Students’ Acceptance of Chatbots for Studio-Based Learning,"Studio-based learning (SBL) is a pedagogy that encompasses collaborative active learning strategies focusing on creativity, peer learning, and problem-solving. The iterative design procedures and critique sessions are the primary learning practices of SBL, which relays to a need to have effective communication between instructors and students. Due to this, we designed a Telegram chatbot using the TextIt to facilitate some of the interactions that are common in SBL. In this preliminary study, students’ acceptance of chatbot was investigated based on the Technology Acceptance Model (TAM) using a mix-method approach. Preliminary results indicated positive acceptance and intention to use chatbots due to ease of use, mobile accessibility, human-like communications, and privacy in communicating and providing feedback.","Kumar, Jeya Amantha and Silva, Paula Alexandra",,2020 IEEE Global Engineering Education Conference (EDUCON),2020,10.1109/EDUCON45650.2020.9125183,,ieee.bib,2024-02-25 11:35:40,Unclassified
9680760,Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations,"AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.","Bang, Junseong and Kim, Sineae and Nam, Jang Won and Yang, Dong-Geun",,2021 International Conference on Platform Technology and Service (PlatCon),2021,10.1109/PlatCon53246.2021.9680760,,ieee.bib,2024-02-25 11:35:40,Unclassified
9853807,Data Ethics Framework for Artificial Intelligence in Education (AIED),"In recent years, we have gradually adopted the applications of artificial intelligence in education (AIED) to improve our understanding of students’ learning and enhance their learning experiences. AIED can have a profound impact on the educational landscape, influencing the role of all involved in education. The adoption of AIED and its related large-scale data collection and analysis to do with learners seriously concern human-rights and related ethical and privacy aspects. This paper presents conceptual research establishing a data ethics framework for AIED by mapping and analyzing international organizations’ current policies and guidelines. In addition to contributing to the discussion of the benefits of AI in education, this paper raises data ethics concern for AIED. The proposed framework helps promote the design, development, and implementation of ethical and trustworthy AIED.","Hong, Yvonne and Nguyen, Andy and Dang, Belle and Nguyen, Bich-Phuong Thi",,2022 International Conference on Advanced Learning Technologies (ICALT),2022,10.1109/ICALT55010.2022.00095,,ieee.bib,2024-02-25 11:35:40,Unclassified
10178747,A Chatbot-based Recommendation Framework for Hypertensive Patients,"Chatbot-based systems are recognised in literature as an effective tool to support chronic diseases self-management. However, the core of most of this work is on the description of the application domain and on the motivations behind the adoption of recommendation systems that exploit chatbot to mediate the interaction with users, but they fail in providing sufficient details on the system architecture and on the technology adopted. Moreover, they are usually designed with a strong focus on the specific pathology, and a reference architectural solution that can be adopted in different contexts is missing, thus making the work useful only in the domain it is devised for. In this paper we provide a framework for developing recommendation systems based on chatbots that is meant to be applied in different scenarios. The framework is composed by a back-end recommendation engine that autonomously computes the user's adherence profile to prescription, and proactively provides motivational feedback to the user through the application front-end based on a chatbot. The chatbot is also meant to collect and aggregate data for profiling the individual health and habits. To demonstrate the feasibility of our framework, we present a recommendation system, based on a Telegram chatbot, that has been developed and trained for managing hypertensive patients.","Montagna, Sara and Mariani, Stefano and Pengo, Martino Francesco",,2023 IEEE 36th International Symposium on Computer-Based Medical Systems (CBMS),2023,10.1109/CBMS58004.2023.00309,,ieee.bib,2024-02-25 11:35:40,Unclassified
9238116,A Prototype of Privacy Identification System for Smart Toy Dialogue Design,"Privacy issues are becoming more and more important in Artificial Intelligent (AI). Yet, there is a lack of systematized or standardized privacy framework that focuses on AI embedded smart toys, with conversation functionality, to address user privacy requirements. To address this issue, we develop a prototype of a Privacy Identification (PI) system for Dialogue Design (DD). We call this system a PI-DD system. To develop such a PI-DD system, our research works were separated into two parts: (1) Create phrases' database that considers the Personally Identifiable Information (PII) law which states privacy laws and information security best practices and is used in various U.S. federal, and (2) Build the dialogue rule for robot conversations. To illustrate the algorithms of the PI-DD system, we take the sample phrase of Mattel's Hello-Barbie smart toy. We present an architecture of the PI-DD algorithm at the end of this paper.","Lin, Pei-Chun and Yankson, Benjamin and Hung, Patrick C. K.",,"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)",2020,10.1109/ICNSC48988.2020.9238116,,ieee.bib,2024-02-25 11:35:40,Unclassified
10125731,Data Preservation in Chatbot with Cloud Deployment,"In today's digital age, the importance of preserving and organizing important documents and information cannot be overstated. To create a comprehensive solution for secure file sharing through the use of a Telegram chatbot. The bot will have the ability to encrypt and decrypt files, allowing users to share sensitive information with confidence. The encryption and decryption will be performed using AES algorithms to ensure the security of the files. To further enhance security and scalability, the chatbot will be deployed to a cloud platform, allowing it to be accessed from anywhere and handle a larger number of users. Additionally, this project will also focus on implementing data preservation functionality within the chatbot. This will ensure that files are retained and accessible even when they are deleted from the Telegram chat or when the chatbot is deployed to the doud. This will be achieved through techniques such as data backup and disaster recovery to ensure data availability. Overall, this aims to provide a secure and reliable system for sharing files through Telegram, that guarantees the security of the files, the availability of the data and the scalability of the system. It is tailored for organizations, businesses and individuals who need to share sensitive information regularly.","T, Vijaya Kumar and P, Rajasekaran and L, Jeevika and S, Lavan and R, Tharshan",,2023 7th International Conference on Trends in Electronics and Informatics (ICOEI),2023,10.1109/ICOEI56765.2023.10125731,,ieee.bib,2024-02-25 11:35:40,Unclassified
10430048,An Approach for Ensuring the Privacy in Smart Contracts,"Ensuring the privacy in smart contracts is critical to the success of the technique. Adequately testing privacy in smart contracts is a practical and effective way for ensuring the privacy. In this research, we experimented with a new approach that leverages the capacity of generative AI for automated testing privacy in blockchain based smart contracts. Generative AI tool ChatGPT was used for modeling privacy in smart contracts and producing tests according to the generated privacy model. The capacity of ChatGPT could have the potential for producing relatively comprehensive privacy requirements and adequate tests. We implemented a smart contract for managing real estate investment in Solidity based on the Ethereum blockchain platform and demonstrated the procedure and effectiveness of the proposed approach.","Zhao, Wenqian and Patibandla, Meghana and Ding, Junhua",,"2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)",2023,10.1109/QRS-C60940.2023.00046,,ieee.bib,2024-02-25 11:35:40,Unclassified
9840620,Increasing Safety and Privacy Against COVID-19 using IoTs and Enhanced Positioning Methods,"This paper introduces and demonstrates a new approach to enhance safety against COVID-19, or other dangerous and contagious diseases, on mainly indoor public spaces, using enhanced privacy protection and an enhanced localization techniques. In most of the existing COVID-19 tracing systems and mobile apps, the focus is on identifying possible infected individuals, that were closed to a human source of transmission. This work includes primarily results and demonstrates a mobile app prototype and a corresponding support system to identify unsafe “COVID-19 areas”, from where infected individuals have recently crossed, so these spots to be avoided by individuals, until they will be characterized again as open to be used.","Marias, Giannis F. and Spentzouris, Panagiotis and Kontantinou, Vasileios and Dimitroulis, Christos and Tsigkanos, Theodoros",,2022 IEEE Zooming Innovation in Consumer Technologies Conference (ZINC),2022,10.1109/ZINC55034.2022.9840620,,ieee.bib,2024-02-25 11:35:40,Unclassified
10219468,Chatbots: A Game Changer in mHealth,"Chatbots have emerged as a promising tool in healthcare for improving patient engagement, providing education and support, and delivering interventions for a variety of health conditions. In the field of mHealth (mobile health), chatbots are being increasingly used to support self-management, provide remote monitoring, and offer personalized coaching to patients with chronic conditions. A growing body of research has demonstrated the feasibility, acceptability, and effectiveness of chatbots in mHealth, with many studies reporting positive outcomes such as improved patient adherence, increased physical activity, and reduced hospital readmissions. However, there are also limitations and challenges to the use of chatbots in mHealth, such as concerns around data privacy and security, the need for effective natural language processing and machine learning algorithms, and ensuring that chatbots are designed with the end user in mind. Future research is needed to further explore the potential of chatbots in mHealth, and to develop best practices for their design, implementation, and evaluation.","Chowdhury, Md Naseef-Ur-Rahman and Haque, Ahshanul and Soliman, Hamdy",,"2023 Sixth International Symposium on Computer, Consumer and Control (IS3C)",2023,10.1109/IS3C57901.2023.00103,,ieee.bib,2024-02-25 11:35:40,Unclassified
10303313,Boulez: A Chatbot-Based Federated Learning System for Distance Learning,"In recent years, also due to the covid-19 pandemic, the possibilities for distance learning have increased considerably, through web-based learning platforms, available on the Internet without space and time limits. As a result, the offer of courses and the number of enrolled students has grown exponentially. In order to be able to guarantee students a better learning support service, one of the proposals regards the intelligent Chatbots. These well known interactive applications are based mainly on machine or deep learning and in this paper we present Boulez, a system allowing the orchestration of a community of individual chatbots, each one with its algorithm and its private training dataset. We apply a technique called Federated Learning, where several individual chatbots, collaborate. In particular, here the approach is “centralized”, meaning that a main system orchestrates the collaboration of the federated systems. By addressing the communication inefficiencies and privacy issues of conventional federated learning, Boulez offers a more efficient and effective approach to chatbot interaction, ultimately leading to improved user experience. The paper presents the Boulez system, its operation principle, methods used, and potential benefits, along with a use case of its application.","D'Urso, Stefano and Sciarrone, Filippo and Temperini, Marco",,2023 27th International Conference Information Visualisation (IV),2023,10.1109/IV60283.2023.00045,,ieee.bib,2024-02-25 11:35:40,Unclassified
10368616,A Novel AI-based chatbot Application for Personalized Medical Diagnosis and review using Large Language Models,"This research showcases a groundbreaking application in the medical industry by leveraging the cutting-edge OpenAI service's GPT-3.5 model, powered by large language models (LLMs). Through the implementation of a Java-based Android app, it introduces a medical chatbot that redefines the way individuals interact with healthcare systems. By capitalizing on the advanced capabilities of LLMs, the app enables users to effortlessly input their symptoms and receive accurate insights, personalized diagnoses, and actionable medical advice. The utilization of natural language processing and AI algorithms ensures a seamless and intuitive user experience. The significance of this innovation lies in the revolutionary impact of LLMs on the entire medical industry. The integration of LLMs empowers the app to comprehend complex medical queries, interpret contextual information, and deliver reliable and up-to-date medical knowledge to users. This transformative technology facilitates improved access to healthcare information, enhances decision-making processes, and ultimately contributes to the optimization of healthcare services.","S, Akilesh and A, Sheik Abdullah and R, Abinaya and S, Dhanushkodi and Sekar, Rajeev",,"2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)",2023,10.1109/RMKMATE59243.2023.10368616,,ieee.bib,2024-02-25 11:35:40,Unclassified
10343248,Chatbots in Educational Recommender Systems: A Systematic Literature Review,"This summary refers to a full research article. The article presents a Systematic Literature Review (SLR) that aims to characterize the use of conversational agents (CHATBOTS) in the current scenario of Educational Recommendation Systems (ERS).The objective of this work is to improve the quality of teaching by using chatbots and ERS as valuable tools for teaching, in order to personalize the student learning experience and provide relevant recommendations based on their behavior and learning history, making it more engaging, personalized, and efficient. Following the SLR protocol proposed by Kitchenham, the string and connector chain (“recommendation” OR “recommender”) AND (“chatbot” OR “chatbots” OR “chaterbots”) was planned and used in the search fields of 4 highly relevant academic data repositories in the computing area: Institute of Electrical and Electronic Engineers (IEEE), Scopus, Association for Computing Machinery (ACM), and Science Direct, covering the period from 2018 to 2023, selecting 1,401 published articles, of which, after applying inclusion criteria, 158 were analyzed in the final phase of the review. As main results, we can highlight: Personalization of learning: with the help of chatbots, ERS can analyze student data, such as academic history, test results, and learning preferences, to provide personalized recommendations for educational content, maximizing student learning; Accessibility: Chatbots help make education more accessible to students, as they are available without interruption, which means that students can get help whenever they need it, regardless of the time or location; Engagement: Chatbots help with educational content by providing personalized recommendations for content that is relevant and interesting, keeping students engaged and motivated. Additionally, chatbots can use gamification techniques, such as rewards and competitions, to encourage students to engage more with educational content; Data analysis: Chatbots help collect and analyze data on student performance, tracking student progress and learning activities and signaling according to predefined parameters; Integration with existing technologies, such as learning management systems and online teaching platforms, can help provide a more integrated and unified learning experience for students. In conclusion, the use of chatbots in ERS has the potential to transform education, providing a more personalized, accessible, and efficient learning experience for students, being a complementary tool to help improve the learning experience of students.","Ramos Pinho, Paulo Cesar and Primo, Tiago Thompsen",,2023 IEEE Frontiers in Education Conference (FIE),2023,10.1109/FIE58773.2023.10343248,,ieee.bib,2024-02-25 11:35:40,Unclassified
10322527,"The outlook of ChatGPT, an AI-based tool adoption in Academia: applications, challenges, and opportunities","Artificial intelligence (AI) technologies continually improve and become more pervasive in many facets of our lives. ChatGPT is a chatbot created by OpenAI with a conversational artificial intelligence interface. Academic institutions could routinely use artificial intelligence (AI) and language models like ChatGPT, with an increasing range of applications and ramifications. This study investigates the adoption of ChatGPT in academia which include applications, challenges and opportunities using the lenses of educational transformation, response service quality, usefulness privacy concerns. The article first examine diverse applications of ChatGPT, including automation, sentiment analysis and natural language processing. Second, it addresses the challenges and limitations that come with using these technologies, like regulatory compliance algorithmic prejudice, and ethical issues. Third, the study emphasize the opportunities brought about by the implementation of AI and ChatGPT, such as improved research capacities, individualized learning experiences, and new career pathways. To promote an efficient and responsible adoption and deployment of ChatGPT, the study's findings offer several research directions and implications in academia.","Ahadi, Navidreza and Zanjanab, Ali Ghalehban and Sorooshian, Shahryar and Monametsi, Gladness and Virutamasen, Porngarm and Wongpreedee, Kageeporn and Deebhijarn, Samart and Taghipour, Amirhossein",,TENCON 2023 - 2023 IEEE Region 10 Conference (TENCON),2023,10.1109/TENCON58879.2023.10322527,,ieee.bib,2024-02-25 11:35:40,Unclassified
10342742,A Multianalytical SEM-ANN Approach to Investigate the Social Sustainability of AI Chatbots Based on Cybersecurity and Protection Motivation Theory,"With a primary focus on cybersecurity risks, this study endeavors to explore the sustainable deployment of artificial intelligence (AI) chatbots and, ultimately, to promote their social sustainability. The study introduces an enhanced model built upon the “Protection Motivation Theory” (PMT) to explore the factors that predict the social sustainability of AI chatbots. The proposed model is evaluated using both “structural equation modeling” and “artificial neural network” (ANN) analyses, leveraging data obtained from 1741 participants. The findings reveal that PMT factors significantly predict the sustainable use of AI chatbots. Moreover, cybersecurity concerns, including confidentiality and privacy, have emerged as significant predictors of sustainable use, impacting the social sustainability of AI chatbots. The indicated paths in the model explain 70% and 74% of the variance in sustainable use and social sustainability, respectively. The results from the ANN analysis also emphasize the critical role of confidentiality as the primary predictor. The significance of this study lies in the development of a unified model that integrates cybersecurity and PMT, offering a distinctive framework. In addition to its theoretical contributions, the study offers practical insights for service providers, application developers, and decision-makers in the field, thereby influencing the future of AI chatbots.","Arpaci, Ibrahim",IEEE Transactions on Engineering Management,,2024,10.1109/TEM.2023.3339578,,ieee.bib,2024-02-25 11:35:40,Unclassified
9766793,Impersonating Chatbots in a Code Review Exercise to Teach Software Engineering Best Practices,"Over the past decade, the use of chatbots for educational purposes has gained considerable traction. A similar trend has been observed in social coding platforms, where automated agents support software developers with tasks such as performing code reviews. While incorporating code reviews and social coding platforms into software engineering education has been found to be beneficial, challenges such as steep learning curves and privacy considerations are barriers to their adoption. Furthermore, no study has addressed the role chatbots play in supporting code reviews as a pedagogical tool. To help address this gap, we developed an online learning application that simulates the code review features available on social coding platforms and allows instructors to interact with students using chatbot identities. We then embedded this application within a lesson on software engineering best practices and conducted a controlled in-class experiment. This experiment examined the effect that explaining content via chatbot identities had on three aspects: (i) students’ perceived usability of the lesson, (ii) their engagement with the code review process, and (iii) their learning gains. While our findings show that it is feasible to simulate the code review process within an online learning platform and achieve good usability, our quantitative analysis did not yield significant differences across treatment conditions for any of the aspects considered. Nevertheless, our qualitative results suggest that students expect explicit feedback when performing this type of exercise and could thus benefit from automated replies provided by an interactive chatbot. We propose to build on our current findings to further explore this line of research in future work.","Farah, Juan Carlos and Spaenlehauer, Basile and Sharma, Vandit and Rodríguez-Triana, María Jesús and Ingram, Sandy and Gillet, Denis",,2022 IEEE Global Engineering Education Conference (EDUCON),2022,10.1109/EDUCON52537.2022.9766793,,ieee.bib,2024-02-25 11:35:40,Unclassified
9619970,SkillVet: Automated Traceability Analysis of Amazon Alexa Skills,"Skills, are essential components in Smart Personal Assistants (SPA). The number of skills has grown rapidly, dominated by a changing environment that has no clear business model. Skills can access personal information and this may pose a risk to users. However, there is little information about how this ecosystem works, let alone the tools that can facilitate its study. In this article, we present the largest systematic measurement of the Amazon Alexa skill ecosystem to date. We study developers’ practices in this ecosystem, including how they collect and justify the need for sensitive information, by designing a methodology to identify over-privileged skills with broken privacy policies. We collect 199,295 Alexa skills and uncover that around 43% of the skills (and 50% of the developers) that request these permissions follow bad privacy practices, including (partially) broken data permissions traceability. In order to perform this kind of analysis at scale, we present SkillVet that leverages machine learning and natural language processing techniques, and generates high-accuracy prediction sets. We report several concerning practices, including how developers can bypass Alexa's permission system through account linking and conversational skills, and offer recommendations on how to improve transparency, privacy and security. Resulting from the responsible disclosure we did, 13% of the reported issues no longer pose a threat at submission time.","Edu, Jide S. and Ferrer-Aran, Xavier and Such, Jose and Suarez-Tangil, Guillermo",IEEE Transactions on Dependable and Secure Computing,,2023,10.1109/TDSC.2021.3129116,,ieee.bib,2024-02-25 11:35:40,Unclassified
10292448,Advancing Decentralized IoT with Privacy-preserving AI: Harnessing Federated Learning and NLP Techniques,"This study introduces a cross-platform application built on the Flutter framework that employs federated learning (FL) and natural language processing (NLP) for personalized event discovery. The system includes an NLP-based chatbot and utilizes a second-generation Matrix homeserver known as Dendrite for decentralized communication. The system design is configured to ensure data privacy. The FL model runs on users’ devices, employing data such as browsing history and application usage patterns to build user-interest profiles and provide personalized event suggestions. A practical use case underscores the implementation of end-to-end encrypted communication, indicating the system’s commitment to ensuring privacy and security. The integration of FL and NLP into an IoT context demonstrates a significant advancement in privacy-preserving, personalized applications.","Sarker, Arpita and Jesser, Alexander and Speidel, Markus",,"2023 IEEE International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings)",2023,10.1109/AIBThings58340.2023.10292448,,ieee.bib,2024-02-25 11:35:40,Unclassified
10370937,ChatGPT Based Image Steganography (CGIS): A Novel Intelligent Information Hiding Approach to Achieve Secure Covert Communication,"Covert communication refers to the practice of exchanging information or messages in a discreet or secretive manner, with the intent of keeping the communication hidden from unintended or unauthorized recipients. Steganography is a widely used, strategy for establishing covert communication, for maintaining the privacy and security of sensitive information. Steganography ensures that the message remains concealed from surveillance or eavesdropping. Artificial Intelligence (AI) plays a crucial role in enhancing security across various domains of covert communication. ChatGPT is an AI model, specifically a natural language processing (NLP) model. It belongs to the broader category of AI models which can comprehend and produce language for humans. In this paper, a new image steganographic model named CGIS is developed for covert communication using ChatGPT. Proposed steganographic method has achieved 3.0 bpp of hiding capacity. In situations where confidentiality is critical, such as in military operations, intelligence agencies, or corporate strategies, proposed method ensures that the message cannot be detected and or extracted by any surveillance or eavesdropper.","Mukherjee, Subhadip and Mukhopadhyay, Somnath and Sarkar, Sunita",,"2023 First International Conference on Advances in Electrical, Electronics and Computational Intelligence (ICAEECI)",2023,10.1109/ICAEECI58247.2023.10370937,,ieee.bib,2024-02-25 11:35:40,Unclassified
8937382,Adoption of AI-Chatbots to Enhance Student Learning Experience in Higher Education in India,"Today, every organisation depends on Information and Communication Technology (ICT) for the efficient service delivery and cost-effective application of technological resources. With growing preference towards faster services and acceptance of Artificial Intelligence (AI) based tools in business operations globally as well as in India, the global Chatbot market is going to accelerate in the next decade. In the era of AI, the Chatbot market is witnessing extraordinary growth with the increased demand for smartphones and increased use of messaging applications. In the past few years, the food delivery business, finance and the E-commerce industry have embraced Chatbot technology. One of the industries which can really benefit from using this technology is the educational sector. Education can benefit from Chatbot development. It can improve productivity, communication, learning, efficient teaching assistance, and minimize ambiguity from interaction. A new education platform can solve next-level problems in education using this technology as the engagement tool. The aim of this research paper is to find out the factors which affect the adoption of Chatbot technology in order to enhance the student learning experience in the Indian higher education sector. In this research, a Quantitative method is used through data collection from surveys of some of the prominent higher education institutes using Chatbot technology in India. It is expected that the research outcome will help Chatbot developers and higher education providers to better understand the requirements of students while providing an interactive learning and communication platform for them.","Sandu, Nitirajsingh and Gide, Ergun",,2019 18th International Conference on Information Technology Based Higher Education and Training (ITHET),2019,10.1109/ITHET46829.2019.8937382,,ieee.bib,2024-02-25 11:35:40,Unclassified
9794852,Sociocultural and Information Security Issues in the Implementation of Neural Network Technologies in Chat-bots Design,"Neural networks are trained on actual material. People in their communication use both socio-cultural rules of courtesy and good taste, and take into account threats to protect data, based on long-term experience and long-term risk prediction. Human behavior provides neural networks with examples of both appropriate behavior and manners with limited application depending on the context, as well as unacceptable and unacceptable behaviors, such as rude emotional discharge or information disclosure in associated metadata. Based on the analysis of several cases of the implementation and functioning of chatbots, the main groups of ethical problems and the main tasks in the field of information security are shown, key approaches to ensuring etiquette and data protection are identified, and proposals are formulated for procedures for machine learning in relation to chatbots in corporate ecosystems.","Pokrovskaia, Nadezhda N.",,2022 XXV International Conference on Soft Computing and Measurements (SCM),2022,10.1109/SCM55405.2022.9794852,,ieee.bib,2024-02-25 11:35:40,Unclassified
10343639,The Risks Associated with AI Chatbots in Teaching Future Engineering Graduates: A Systematic Review,"The educational system's trajectory has shifted dramatically in recent years. The introduction of chatbots and artificial intelligence (AI) techniques has mostly pushed the trend. Fundamentally, these methods are intended to improve the culture and experience of teaching and learning. However, there are risks associated with these technologies. The risks of using AI chatbots in the education of future engineering graduates are severely examined in this systematic review. This review identifies and addresses pedagogical, ethical, technological, and socio-cultural dangers that may come from the widespread use of AI chatbots based on an intensive review of the available research. The findings provide useful insights for educators, institutions, and policymakers as they manage the hurdles of implementing AI chatbots in engineering education responsibly.","Moloi, K. and Maladzhi, R. W. and Nemavhola, F. J. and Mthombeni, N. H. and Tsoeu, M. S. and Mashifana, T.",,2023 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC),2023,10.1109/WEEF-GEDC59520.2023.10343639,,ieee.bib,2024-02-25 11:35:40,Unclassified
9665642,Human Firewall: Cyber Awareness using WhatApp AI Chatbot,"The use of technology is a necessary component for the success of business operations. Yet cyber risks related to technology are well known. In previous works, three different layers were defined to be responsible of the cyber physical security of any given system: the network layer, the device layer and the human factor layer. However, statistics and experience have proven that the third factor is the weakest link in the cyber security of any company. This factor is divided into two subsections: the ignorance of the user (which will be treated in this paper) and the malignancy of the user. As the two previous layers were presented in previous works, this paper will focus on enhancing security by raising the cyber awareness of users thus creating a human firewall. For that, an AI-based conversational bot that focuses on cyber threat awareness and acts as a personal assistant relating to security issues was developed. This bot is based on AI-approach and it is used to make the interaction with the user appealing and friendly through the use of WhatsApp as a mean of communication. The implementation and testing of this bot has shown great interest for the users who have tried it due to its simplicity, the quality of deliverable data and the evaluation technique.","El Hajal, Georges and Abi Zeid Daou, Roy and Ducq, Yves",,2021 IEEE 3rd International Multidisciplinary Conference on Engineering Technology (IMCET),2021,10.1109/IMCET53404.2021.9665642,,ieee.bib,2024-02-25 11:35:40,Unclassified
10270725,Emerging Role of Healthcare Chatbots in Improving Medical Assistance,"This study proposes integrating healthcare chatbots and assistive robots to address issues in densely populated areas with limited medical services. These robots offer benefits such as quicker and more accurate diagnoses, alleviating the workload of medical workers. The suggested healthcare chatbot enables efficient health inquiries through question-and-answer discussions. Users can input symptoms and receive ideas for suspected diseases, along with guidance on how to seek medical help. The chatbot uses natural language processing and machine learning. The chatbot compares symptoms to a database of recognized ailments, achieving an impressive 93% accuracy and outperforming existing models. The combination of accurate healthcare chatbots and assistive robots shows excellent potential for improving patient access and healthcare delivery, benefiting the medical sector.","Sowmya, Daram and Debbata, Kousthubha and Vignesh, Gunda Sai and Sagar, Dasari Subbayyagari Nandhu and Bavanthula, Anudeep Reddy and Pallavi, Lanke",,2023 3rd Asian Conference on Innovation in Technology (ASIANCON),2023,10.1109/ASIANCON58793.2023.10270725,,ieee.bib,2024-02-25 11:35:40,Unclassified
10142289,"Secured Framework for Banking Chatbots using AI, ML and NLP","Artificial intelligence (AI) Machine Learning (ML), and Natural Language Processing (NLP)are being employed in a growing number of sectors and is evolving as the technology of the future. It has been widely used to improve the quality of decision-making and problem-solving. This research study proposes a secured framework for banking chatbots using AI-ML and NLP. The framework based on qualitative in-depth experts interviews can be used for developing efficient chartbots for managing customer interactions of various data forms. AI enabled chatbots involves use of machine learning algorithms that can communicate with consumers in a conversational manner. AI enabled chatbots can speak common man’s language language and utilize voice as a user interface. Chatbots are used in the public and private sectors to provide virtual help in areas such as telecommunications, media, tourism, retail, stock markets, and banking. In the banking business, chatbot can act as a communication tool between customers and banks. It has a special advantage in financial industry as it can be automated and does not necessitate human interaction; and can enhance accessibility and provide a lot of features to customers.","Chanda, Rajat and Prabhu, Sandeep",,2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS),2023,10.1109/ICICCS56967.2023.10142289,,ieee.bib,2024-02-25 11:35:40,Unclassified
10200330,A Machine Learning-Based Methodology for IoT Security,"The popularity of IoT and gadget connectivity is rapidly growing in the present world. Cyber risk has become a significant issue for IoT devices, particularly edge devices, as D2D communication and Internet traffic have grown. The use case of machine learning for IoT security is presented in this proposal. Recent scientific advancements often lead to the development of new technologies. In order to help with this proposal, machine learning is now used by our society. It is because maintaining and managing the data is extremely difficult for humans. As new technologies are developed, cybersecurity measures can be enhanced through innovative methods. The most recent and promising strategy in cyber-physical security is machine learning (ML), which can help address a number of burgeoning issues. Explore potential problems with IoT security controls when applying machine learning to IoT systems and the design of IoT systems. Because smart gadgets are so accessible and in such high demand, IoT systems are exposed to new cyber-physical security and privacy assaults. IoT systems need to be secured with strong, adaptable, and contemporary security techniques.","S, Pousia and N, Kowsick and M S, Rinishvanth and D, Rahul and S, Shri Hari and S, Pravin Kumar",,"2023 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)",2023,10.1109/ACCAI58221.2023.10200330,,ieee.bib,2024-02-25 11:35:40,Unclassified
10410298,Leveraging AI and NLP in Chatbot Development: An Experimental Study,"In the current era of chatbots, this research delves into the advancements in AI chatbots, drawing on artificial intelligence (AI) and natural language processing (NLP) techniques to mimic human-like conversations. A particular focus is given to the potential of chatbots in facilitating multitasking dialogues, offering emotional support, and addressing complex subject matter, all the while respecting user privacy and trust. The implemented chatbot model is trained on a neural network, using Keras and TensorFlow libraries. This model’s performance indicates a considerable dependence on the dataset’s size, with larger datasets leading to better outcomes by providing more extensive language usage and context examples. Additionally, we also analyze the effect of varying architectures and hyperparameters on chatbot performance. The significance of localizing chatbots to adapt to different languages and cultures is also highlighted. While promising, the study identifies areas of improvement, suggesting future research directions in enhancing language capture techniques, expanding training datasets, and integrating emotional intelligence within chatbot systems.","Paracha, Abdul Wahab and Arshad, Usama and Ali, Raja Hashim and Ul Abideen, Zain and Shah, Muhammad Huzaifa and Ali Khan, Talha and Ijaz, Ali Zeeshan and Ali, Nisar and Siddique, Abu Bakar",,2023 International Conference on Frontiers of Information Technology (FIT),2023,10.1109/FIT60620.2023.00040,,ieee.bib,2024-02-25 11:35:40,Unclassified
10344203,How important are Chatbots within Engineering Education? A literature-based review from 2011 to 2023,"Over the years, the emergence of the fourth industrial revolution has brought a much-needed transition within the education sector. COVID-19 has contributed immensely on how teaching and learning is currently evolving. Most of the traditional face-to-face institutions found themselves utilizing technology to enhance teaching and learning activities. Technological tools brought amongst others, artificial intelligence that is currently dictating the direction of education system. Chatbots amongst others found its space within teaching and learning, allowing both students and academics to find education interesting. The current study evaluated the existence of Chatbots in engineering education fraternity by carrying out a literature-based review method focusing 2011 until recent. The findings of the study revealed that Chatbots were spotted as early as 2008 within the engineering education. It continued to make headways in various engineering modules such as Thermodynamics, Design Engineering, as well as in the administration of teaching and learning itself. In conclusion, the challenges and concerns associated with AI chatbots in education underscore the need for a nuanced and balanced approach. Ethical considerations, including data privacy and algorithmic bias, must be carefully navigated.","Maladzhi, Rendani Wilson and Tsoeu, Mohohlo and Mthombeni, Nomcebo and Moloi, Katleho and Mashifana, Tebogo and Nemavhola, Fulufhelo",,2023 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC),2023,10.1109/WEEF-GEDC59520.2023.10344203,,ieee.bib,2024-02-25 11:35:40,Unclassified
10198233,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.","Gupta, Maanak and Akiri, Charankumar and Aryal, Kshitiz and Parker, Eli and Praharaj, Lopamudra",IEEE Access,,2023,10.1109/ACCESS.2023.3300381,,ieee.bib,2024-02-25 11:35:40,Unclassified
10063528,A Multilingual Virtual Guide for Self-Attachment Technique,"In this work, we propose a computational framework that leverages existing out-of-language data to create a conversational agent for the delivery of Self-Attachment Technique (SAT) in Mandarin. Our framework does not require large-scale human translations, yet it achieves a comparable performance whilst also maintaining safety and reliability. We propose two different methods of augmenting available response data through empathetic rewriting. We evaluate our chatbot against a previous, English-only SAT chatbot through non-clinical human trials (N = 42), each lasting five days, and quantitatively show that we are able to attain a comparable level of performance to the English SAT chatbot. We provide qualitative analysis on the limitations of our study and suggestions with the aim of guiding future improvements.","Law, Alicia Jiayun and Hu, Ruoyu and Alazraki, Lisa and Gopalan, Anandha and Polydorou, Neophytos and Edalat, Abbas",,2022 IEEE 4th International Conference on Cognitive Machine Intelligence (CogMI),2022,10.1109/CogMI56440.2022.00025,,ieee.bib,2024-02-25 11:35:40,Unclassified
9914844,Psyche Conversa - A Deep Learning Based Chatbot Framework to Detect Mental Health State,"Mental health is one of the most pressing challenges in today's modern world. Traditional thinking, family pressure, unemployment issues, homesickness, and an unhappy relationship are the most common reasons for mental illness, which may also lead to suicidal attempts. People in impoverished countries do not give this issue enough attention. Furthermore, many are hesitant to seek professional counseling from a psychiatrist to retain their privacy. Monitoring social media activities, in addition to common symptoms, is critical for improving the accuracy of detecting early signs of mental illness because it impacts mental health. So, rather than a psychiatrist, a user-friendly deep learning-based mobile application that will chat with them to support and monitor their social media behaviors to determine their mental health status will be an effective way of handling the situation. This study proposes a deep learning-based chatbot framework to help mentally ill individuals identify their mental health conditions and provide appropriate therapy. This framework comprises three components: a keylogger module, a chat module, and a deep learning-based mental illness detection module. In the background, the keylogger collects data from the user's keyboard to track social media activity. The chatbot converses with users and stores their daily chat history in real-time. Both modules pass the data to a deep learning model to determine mental health conditions. This study also compared the accuracy of multiple deep learning classifiers such as Conv-LSTM and BERT for the Reddit Mental Health Dataset.","Abu Noman Siddik, Sayed and Arifuzzaman, B.M. and Kalam, Abul",,2022 10th International Conference on Information and Communication Technology (ICoICT),2022,10.1109/ICoICT55009.2022.9914844,,ieee.bib,2024-02-25 11:35:40,Unclassified
10430064,A Service-Oriented Framework for An Integrated Study of Intelligent Data Collection and Application,"Service-Oriented Architecture (SOA) provides an optimized and transformative approach to software design that uses flexible mechanisms for linking services. Recently, it has been used in the technical phases of large-scale software system projects. Integrating the connection between services and artificial intelligence enables faster and smarter application development while providing a reliable, scalable, and interoperable framework for easy integration of different services. In addition, SOA architecture helps businesses and developers better understand the composition and operation of their services, leading to more efficient service design and development. In this project, we design an SOA framework based on Taiwan's meteorological and ChatGPT services. This experiment architecture will help users understand the services' composition and construction process, enabling better future design and integration of additional assistance.","Ke, Po-Chuan and Liao, Yuan-Hsun and Lee, Shou-Yu and Huang, Shih-Yun and Chu, William Cheng-Chung",,"2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)",2023,10.1109/QRS-C60940.2023.00034,,ieee.bib,2024-02-25 11:35:40,Unclassified
10269099,CONFLUENCE: An Integration Model for Human-in-the-Loop IoT Privacy-Preserving Solutions Toward Sustainability in a Smart City,"The evolution of the Internet of Things (IoT), progressing from a hyper-connected world of seamless device interaction to a paradigm that emphasizes the human factor as a central component, is driven by approaches like human-in-the-loop IoT (HITL-IoT). This shift enables the development of innovative systems in various environments. For example, in the context of a smart city, which comprises diverse solutions aimed at enhancing citizens’ quality of life and urban service efficiency, HITL-IoT approaches are employed to promote sustainability. Given the strong human involvement in these systems, challenges related to personal data protection, transparency, and participation must be addressed. Additionally, ensuring interoperability among different smart city entities is crucial for the coexistence and synergy of these solutions. This article presents a model that incorporates contemporary technologies like Blockchain and LoRa to integrate citizen-centric IoT privacy preservation solutions, fostering the vision of smart and sustainable cities. To demonstrate the feasibility of the proposed model, a prototype was designed, implemented, and deployed in a realistic scenario. Assessment results include metrics, such as latency, throughput, and communication aspects of the components.","Rivadeneira, Jorge Eduardo and Sánchez, Oscar Torres and Dias, Moisés and Rodrigues, André and Boavida, Fernando and Silva, Jorge Sá",IEEE Internet of Things Journal,,2024,10.1109/JIOT.2023.3321778,,ieee.bib,2024-02-25 11:35:40,Unclassified
10075801,Voice-Based Interaction for an Aging Population: A Systematic Review,"In the past twenty years, voice-based systems have emerged as a technology with high usability and accessibility. Research in the field of Human-Computer Interaction (HCI) has investigated this trend and how these systems can bridge the gap in technology use across all generations, specifically for older adults. This study aims to conduct a systematic literature review of research on voice-based systems for older adults published in the past twenty years. These articles were obtained from reputed databases, filtered out based on specific eligibility criteria, and perused by the authors of this study. This study answers questions concerning the research methodologies often employed for this particular topic and the trends in existing voice-based systems studied in research experiments. It discusses the benefits of voice technologies for the elderly, their challenges, and how to address them.","Pednekar, Sayli and Dhirawani, Palka and Shah, Richa and Shekokar, Narendra and Ghag, Kranti",,2023 3rd International Conference on Intelligent Communication and Computational Techniques (ICCT),2023,10.1109/ICCT56969.2023.10075801,,ieee.bib,2024-02-25 11:35:40,Unclassified
9123051,SLA as a mechanism to manage risks related to chatbot services,Intelligent Chatbot services become one of the mainstream applications in user help and many other areas. Apart from bringing numerous benefits to users these services may bring additional risks to the companies that employ them. The study starts with the review of the scale of chatbot industry and common use cases by focusing on their applications & industry tendencies. Review of functionality and architecture of typical chatbot services shows the potential risks associated with chatbots. Analysis of such risks in the paper helped to build a checklist that security managers can use to assess risks prior to chatbot implementation. The proposed checklist was tested by reviewing a number of Service Level Agreements (SLA) of real chatbot providers.,"Gondaliya, Krishna and Butakov, Sergey and Zavarsky, Pavol",,"2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)",2020,10.1109/BigDataSecurity-HPSC-IDS49724.2020.00050,,ieee.bib,2024-02-25 11:35:40,Unclassified
9310984,A conceptual framework for AI system development and sustainable social equality,"Artificial intelligence (AI) technology has been used for some years and is growing rapidly. We are living in a world where AI has been involved in many different ways; from helping us to perform online search, shopping on the internet, customer service over internet, medical research, advices over banking activities, advices for legal matters, or to determine different stages of our life, even since when a baby is born. AI has also been significantly having a strong impact on the way we conduct business; for example, customer analysis, product research, trend analysis, making price policy, and recruiting process. However, awareness levels among end-users is still low. Authorities and industries are still looking for possibilities to regulate, optimise and harmonise negative issues that have been raised. In addition to just following general policies, developers and companies also need to take ethical issues into consideration in order to build trustworthy AI powered systems. This paper is aiming to design a conceptual framework by seeking possibilities in/among known debates, issues, theories, policies, dilemmas, and with personal view, instead of finding general solutions. The opinion of this paper does not necessarily reflect the views of the organisation.","Chen, Lucien Yen-Hao",,2020 IEEE / ITU International Conference on Artificial Intelligence for Good (AI4G),2020,10.1109/AI4G50087.2020.9310984,,ieee.bib,2024-02-25 11:35:40,Unclassified
10368930,A Fuzzy Logic and NLP Approach to Emotion Driven Response Generation for Voice Interaction,"The voice modality has become the most prominent channel in the rapidly emerging field of human-computer interactions. Emotional connection is the foundation of successful communication. Our words are enhanced in human-to-human interactions by emotional undertones, vocal specifics, and contextual interpretations. When correctly interpreted, these hidden signals open the door to empathy, understanding, and effective communication. However, this emotional depth is not addressed in human computer verbal interactions. The challenge is comparable to having a conversation in which the words are understood but the feelings are not. Our idea focuses on bridging this emotional divide. We introduce an innovative approach to human-computer vocal interactions using a blend of advanced Natural Language Processing and Fuzzy Logic-based Voice Sentiment Analysis. Because human emotions are naturally complex, we use fuzzy logic to extract nuanced sentiment scores from voice inputs. Both the content, which is obtained from NLP, and the tone, which is modified to either mirror or contradict the detected sentiment, are informed by these evaluations in the form of voice. This bonds people with AI not only through words but also through emotions. Such a system has broad applications, from emotionally intelligent virtual assistants to support lines and teletherapy solutions. By ensuring AI can not only understand but also respond aptly to human emotion, bringing AI one step closer to reality.","M, Gopika Sri and G, Karthiga and K, Jayakarthika and N, Ilakkiya and V, Lavanyagayathri and D, Uma Mageswari S",,"2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)",2023,10.1109/RMKMATE59243.2023.10368930,,ieee.bib,2024-02-25 11:35:40,Unclassified
10308236,Adaptive Mental Health And Mood Uplifting Chatbot,"Mental health concerns are on the rise worldwide, and the stigma and lack of confidentiality surrounding therapy make it difficult for many people to seek the help they need. In response to this problem, my research proposes the development of an AI chatbot that acts as a virtual psychologist, providing accessible and confidential mental health support. Using NLP technology, the chatbot will be able to understand and respond to user queries, offering personalized therapy sessions based on individual input. My paper explores various NLP models and techniques that can be used for the chatbot's development, as well as ethical and privacy considerations. We are truly passionate about the potential of this chatbot to revolutionize the mental health industry, providing affordable and accessible therapy while breaking down the stigma associated with seeking help. While there is still much work to be done to ensure the chatbot's reliability and effectiveness, We are excited to be at the forefront of this innovative new field, working towards a brighter future for mental health support.","Siddiqui, Taha and Sharma, Arun and Arora, Mamta",,2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT),2023,10.1109/ICCCNT56998.2023.10308236,,ieee.bib,2024-02-25 11:35:40,Unclassified
10386683,Trustworthy Medical Operational AI: Marrying AI and Regulatory Requirements,"Despite recent advancements in AI and Data Science, the vast Big Data sources available to medical and health care providers are far from living up to their potential. Addressing the underlying transparency and data protection concerns helps to unleash these advancements in the medical domain and thus benefits research and patient care. Subsequently, we propose a system for trustworthy medical operational AI in this paper. We present our vision to align medical operational AI with regulatory demands of the medical domain. We propose guiding principles to marry data-driven diagnostic recommendations with legal frameworks, clinical protocols, and expert-driven reasoning. Through this research, we aim for AI systems in medicine that not only provide accurate predictions but also empower users to comprehend and trust the underlying decision-making processes.","Berns, Fabian and Zimmermann, Georg and Borgelt, Christian and Heilig, Niclas and Kirchhoff, Jan and Stumpe, Florian",,2023 IEEE International Conference on Big Data (BigData),2023,10.1109/BigData59044.2023.10386683,,ieee.bib,2024-02-25 11:35:40,Unclassified
10053130,A Holistic Approach to Ensure Security and Compliance while using Robotic Process Automation,"Robotic Process Automation (RPA) is gained immense popularity among IT leaders over the years. RPA Bots are often easily and quickly deployed for automating repetitive business processes or tasks, which successively helps organizations to save lots of a substantial amount of their time and money. There are several success stories which vouch for usage of RPA, at the same time, there are some key aspects to be taken care in terms of security to minimize problems with the RPA. RPA automates a process, reducing human intervention and involvement. So, many expect it increases security by default. It should be noted, automation doesn’t mean it ensures security and compliance of the process by default. It's important to note that the method of RPA can often be quite risky in some cases. This is because RPA bots will handle sensitive data and transmitting it across systems associated with the business for various processes. So, if the sensitive data is not secured in right manner, it might get exposed, which can impact the business. So, while considering RPA, an organization should make sure it understands the security implications to the business process. With this paper, we would like to present a holistic approach to address all key aspects organizations needs to take care in terms of security, compliance and auditability starting from identification of the business case, design and development of the RPA bots till usage. It covers the crucial 3rd dimension of RPA Bot, along with the software and human user of the traditional software usage to consider and ensure overall security and compliance of the business process.","Bhamidipati, Venkateswara Sarma",,"2022 Seventh International Conference on Parallel, Distributed and Grid Computing (PDGC)",2022,10.1109/PDGC56933.2022.10053130,,ieee.bib,2024-02-25 11:35:40,Unclassified
10065328,"Chatbots in Healthcare: Challenges, Technologies and Applications","Artificial intelligence (AI) technologies have been around for more than fifty years. However, current improvements in processing power, the accessibility of huge amounts of data, and improved algorithms have led to significant advancements in AI. A chatbot is a software program with AI that simulates user interactions. Healthcare chatbots gradually eliminate hospital wait times, appointments, and consultation meetups, thus instantly assisting patients in connecting with the right doctor. Chatbots reduce the workload of healthcare providers by decreasing the number of hospital visits and unnecessary treatments, providing suggestions and alerts. However, the introduction of such chatbots in the healthcare domain exposes users to a plethora of challenges. This paper presents a systematic survey of recent developments by researchers in the field of healthcare chatbots. This research brings to light general information regarding the application type, various technologies and evaluation methods that have been used to evaluate the effectiveness of healthcare chatbots and aims to serve as a research guideline which may be valuable for the development of chatbots in various fields.","Sharma, Deepali and Kaushal, Sakshi and Kumar, Harish and Gainder, Shalini",,2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST),2022,10.1109/AIST55798.2022.10065328,,ieee.bib,2024-02-25 11:35:40,Unclassified
9788120,Theoretical Evaluation of Securing Modules for Educational Chatbot,"A ""chatbot"" is a computer programme that interacts with and processes human conversations while also enabling humans to interact with and communicate with digital devices. It is also described as one of the most advanced and promising expressions of interactions between humans and machines. Its main task is to help students by providing answers to their questions. Existing chatbots are not entirely secure and can create open passages for cyber criminals or hackers to access the data flowing through the chatbot interface. So the chatbot will be made secure using the techniques of authentication (session) timeout and encryption. ""Encryption is a method of secure communication that prevents others from accessing data while it is being transferred from one end system to another. The data is encrypted on the sender’s system, so only the intended recipient can decrypt it. "" Authentication (session) timeout restricts a time limit on how long an authenticated user can stay ""logged in,"" so this prevents cyber criminals from having enough time to predict their way into somebody’s secured account. This review addresses the various methods and techniques that assist in protecting the student’s information from hackers and making the conversations secure for both the educational institute and the students.","Shah, Milind H and Panchal, Mahesh",,2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS),2022,10.1109/ICICCS53718.2022.9788120,,ieee.bib,2024-02-25 11:35:40,Unclassified
8929183,On Design and Implementation a Federated Chat Service Framework in Social Network Applications,"As many organizations deploy their chatbots on social network applications to interact with their customers, a person may switch among different chatbots for different services. To reduce the switching cost, this study proposed the Federated Chat Service Framework. The framework maintains user profiles and historical behaviors. Instead of deploying chatbots, organizations follow the rules of the framework to provide chat services. Therefore, the framework can organize service requests with context information and responses to emulate the conversations between users and chat services. Consequently, the study can hopefully contribute to reducing the cost for a user to communicate with different chatbots.","Cha, Shi-Cho and Li, Zhuo-Xun and Fan, Chuan-Yen and Tsai, Mila and Li, Je-Yu and Huang, Tzu-Chia",,2019 IEEE International Conference on Agents (ICA),2019,10.1109/AGENTS.2019.8929183,,ieee.bib,2024-02-25 11:35:40,Unclassified
10397884,Enhancing Guest Experience and Operations Efficiency in Homestays Through Artificial Intelligence: A Conceptual Framework,"Artificial intelligence (AI) in homestays could improve the tourist experience and operational efficiency. This article proposes a comprehensive conceptual framework for AI in homestays, encompassing visitor experience enhancement, personalized suggestions, predictive analytics, inventory management, maintenance scheduling, and data analytics. AI algorithms allow homestay owners to make personalized recommendations for activities, local sights, and meals. AI-powered home automation systems let guests customize lighting, temperature, and entertainment. AI-powered chatbots and virtual assistants help visitors with questions and requests. Predictive analytics models help operators optimize pricing, estimate demand, and allocate resources, improving revenue management and operational efficiency. AI-based inventory management systems optimize inventory levels, reduce waste, and ensure supplies. Proactive maintenance using AI lowers downtime and enhances the visitor experience. AI-enabled data analytics systems measure occupancy rates, revenue, and visitor satisfaction in real time for informed decision-making and ongoing development. AI in homestays must handle ethical issues including openness, fairness, and accountability, as well as privacy and data security. Cost, technological knowledge, and user approval are other challenges. This article concludes that AI technology in homestays can improve tourist experiences and operational efficiency. Future research should address ethical, privacy, and implementation issues to fully fulfill AI's transformational potential in homestays.","Semwal, Rajeev and Anil and Yadav, Suman Avdhesh and Madhav, Rupesh Chandra and Sharma, Smita and Srivastava, Pihu",,2023 6th International Conference on Contemporary Computing and Informatics (IC3I),2023,10.1109/IC3I59117.2023.10397884,,ieee.bib,2024-02-25 11:35:40,Unclassified
9530938,Cyber Security Risk Analysis for a Virtual Assistant G2C Digital Service Using FAIR Model,"During development and deployment of Government-to-Citizen (G2C) e-services, stakeholders must take cybersecurity risks into account. Recently, Estonia proposed a novel e-service delivery through the use of virtual assistants. Cybersecurity is important to any organization due to the prevalence of attacks in recent times. Organizations in both the public sector and private sector typically have a program that determines, calculates and treats risks. These programs are identified as “risk management,” and cybersecurity risk assessment and analysis are a key part of these organizations. When correctly implemented, these programs can help decision makers allocate their cyber defense budgets in a more effective manner.The researchers conducted interviews with seven cybersecurity experts discussing cybersecurity data, metrics and risk assessment and analysis methods. These interviews informed the use of the Open Group’s Factor Analysis of Information Risk (FAIR) model in this paper.Because Estonia is one of the first countries in the world to prioritize e-service development in this domain, there is a literature gap pertaining to cybersecurity risk analyses of virtual assistant enabled e-services. Although a multiplicity of methods exist for risk assessment and analysis, this research follows the FAIR method to assess a G2C e-service which uses a third party provider for an Amazon Alexa skill that has become corrupted due to malware infection. The FAIR method projects the risk for a particular vulnerability in terms of dollar amount loss over time. It states the annualized loss exposure in terms of a minimum loss, a maximum loss, and a most likely amount of loss.Aggregated global public sector cyber breach frequency data was taken from the Privacy Rights Clearinghouse database and loss magnitude data was taken from the Cyentia IRIS 2020 report which utilized the Advisen cyber loss database. Based upon a Project Evaluation and Review Technique (PERT) distribution Monte Carlo simulation of this data, the annualized loss exposure projection for the public sector entity was $0 minimum likely value, most likely value $70,500 and maximum likely value of $6,000,000. Future work proposes more country and organization specific data for FAIR methodology use for G2C virtual assistant e-services analysis. The value of the work is that it shows how public sector agencies could use the FAIR model to make their cybersecurity risk models more quantitative than is generally currently practiced even in cases of new types of developments and services in order to aid decision-makers in allocation of funding to better defend against the most impactful risks.","Dreyling, Richard and Jackson, Eric and Pappel, Ingrid",,2021 Eighth International Conference on eDemocracy & eGovernment (ICEDEG),2021,10.1109/ICEDEG52154.2021.9530938,,ieee.bib,2024-02-25 11:35:40,Unclassified
9660118,Development of Esteem Support based on Psychodrama and Design Thinking approach,"So far, we have proposed the Stress management framework and developed methods for stress measurement and coping. There are three types of coping in this framework: information support, emotional support, and esteem support. This time, we developed esteem support. In order to increase self-esteem, we focused on psychodrama techniques and developed a system to realize psychodrama using robots. The advantages of using robots include the ability to carry out a psychodrama alone and to provide privacy-friendly support. In the experiment, a scenario was created for medical staff and a robot psychodrama was performed. As a result, we showed that robots can be used for psychodrama and esteem support can be carried out by combination of robots and the chatbot.","Yorita, Akihiro and Egerton, Simon and Chan, Carina and Kubota, Naoyuki",,2021 IEEE Symposium Series on Computational Intelligence (SSCI),2021,10.1109/SSCI50451.2021.9660118,,ieee.bib,2024-02-25 11:35:40,Unclassified
10179452,"When and Why Do People Want Ad Targeting Explanations? Evidence from a Four-Week, Mixed-Methods Field Study","Many people are concerned about how their personal data is used for online behavioral advertising (OBA). Ad targeting explanations have been proposed as a way to reduce this concern by improving transparency. However, it is unclear when and why people might want ad targeting explanations. Without this insight, we run the risk of designing explanations that do not address real concerns. To bridge this gap, we conducted a four-week, mixed-methods field study with 60 participants to understand when and why people want targeting explanations for the ads they actually encountered while browsing the web. We found that users wanted explanations for around 30% of the 4,251 ads we asked them about during the study, and that subjective perceptions of how their personal data was collected and shared were highly correlated with when users wanted ad explanations. Often, users wanted these explanations to confirm or deny their own preconceptions about how their data was collected or the motives of advertisers. A key upshot of our work is that one-size-fits-all approaches to ad explanations are likely to fail at addressing people’s lived concerns about ad targeting; instead, more personalized explanations are needed.","Lee, Hao-Ping Hank and Logas, Jacob and Yang, Stephanie and Li, Zhouyu and Barbosa, Natã and Wang, Yang and Das, Sauvik",,2023 IEEE Symposium on Security and Privacy (SP),2023,10.1109/SP46215.2023.10179452,,ieee.bib,2024-02-25 11:35:40,Unclassified
9920434,Study Literature Review: Discovering the Effect of Chatbot Implementation in E-commerce Customer Service System Towards Customer Satisfaction,"Customer service plays a crucial role for a company. As an important aspect of e-commerce companies, they would be required to directly interact and try to solve customers’ problems that might occur anywhere and anytime. However, the limitation of human man hours became a barrier to overcome customers’ problems. On one hand, the rapid development of technology was predicted to replace the traditional human customer service with an Artificial Intelligence agent. On the other hand, this replacement affects the customer satisfaction. This paper performed a study literature review to discover the effect of chatbots and its impact towards customer satisfaction. In an e-commerce customer service use case, chatbots could be implemented in a number of methods. The methods implemented by chatbots are avatar-based, verbal-based, text-based, and menu-based. Research showed that text-based chatbot is the most commonly used methodology and has advanced the most, where some are implementing higher level machine learning methods, such as deep learning. The usage of such chatbot in e-commerce customer service systems will lower the cost but might also lower customer satisfaction, due to reasons such as unsatisfying answers and inhuman behavior. Research showed that even a more sophisticated chatbot doesn’t always mean higher customer satisfaction, even with high accuracy ratings. To look into customer satisfaction, this paper has identified 4 aspects of a chatbot that are relevant to customer satisfaction, which are privacy, reliability, personalization, and responsiveness. Chatbots currently excel in some of these quality measures, but require further research to effectively replace human customer service agents.","Antonio, Randy and Tyandra, Nadya and Nusantara, Linggar Tembus and Anderies and Agung Santoso Gunawan, Alexander",,2022 International Seminar on Application for Technology of Information and Communication (iSemantic),2022,10.1109/iSemantic55962.2022.9920434,,ieee.bib,2024-02-25 11:35:40,Unclassified
10384863,Generative AI: Impactful Considerations to Responsible Data Practices in Business Execution,"AI is shaping our society and changing what it means to be human. The future is getting frenetic since the adoption of Generative AI (GenAI) in our everyday life. Humanity is slowly transcending from a society of consumers to creators. We first began with Siri and Alexa; now it is ChatGPT, DALL-E, Stable Diffusion and several other tools powered by Artificial Intelligence (AI) and Machine Learning (ML). Audi as well has started the use of Generative Adversarial Networks (GANs) to get inspiration on wheel design. This paper will focus on: the advantages; the social and cultural impact that GenAI opposes; use cases on how GenAI can enhance innovation and drive business value from the technical prospect; the potential risks that might arise if GenAI is abused and conclude with how technology teams alongside the C-Suite and Board of Directors should take action. These risks include deepfakes, legal confusion, hiring biases and inaccurate chatbots. AI is in the service of humanity and it is a responsibility of ours to treat(/train) it with dignity and fairness.","Osmëni, Tea and Ali, Maaruf",,"2023 International Conference on Computing, Networking, Telecommunications & Engineering Sciences Applications (CoNTESA)",2023,10.1109/CoNTESA61248.2023.10384863,,ieee.bib,2024-02-25 11:35:40,Unclassified
10296668,A Review of the Role of ChatGPT for Clinical Decision Support Systems,"The development of artificial intelligence (AI) provided powerful assistant tools for humans in various aspects. Healthcare is rapidly evolving, with AI playing a crucial role in improving patient care. The extensive use of AI in Clinical Decision Support Systems (CDSS) enables providing real-time evidence-based recommendations to healthcare professionals at the point of Care. The AI chatbot ChatGPT proved its ability to solve several natural language processing tasks. One notable advancement is the integration of ChatGPT into Clinical Decision Support Systems. ChatGPT, despite not being healthcare-specific, can offer accurate and practical information for medical professionals and patients. It aids in diagnosis and treatment, supports decision-making, and enhances the overall accuracy and efficiency of the healthcare system. In this review, we present a selection of representative examples of ChatGPT applications in CDSS.","Fawzi, Sahar",,2023 5th Novel Intelligent and Leading Emerging Sciences Conference (NILES),2023,10.1109/NILES59815.2023.10296668,,ieee.bib,2024-02-25 11:35:40,Unclassified
10391027,AI-Powered Software Testing: The Impact of Large Language Models on Testing Methodologies,"Software testing is a crucial aspect of the software development lifecycle, ensuring the delivery of high-quality, reliable, and secure software systems. With the advancements in Artificial Intelligence (AI) and Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools capable of understanding and processing natural language texts easly. This article investigates the application of AI-based software testing, with a specific focus on the impact of LLMs in traditional testing methodologies. Through a comprehensive review of relevant literature and SeturDigital’s 25 year testing experience, this article explores the potential benefits, challenges, and prospects of integrating LLMs into software testing.","Bayrı, Vahit and Demirel, Ece",,2023 4th International Informatics and Software Engineering Conference (IISEC),2023,10.1109/IISEC59749.2023.10391027,,ieee.bib,2024-02-25 11:35:40,Unclassified
10104905,Artificial Intelligence’s Contribution To Mental Health Education,"As AI offers a suitable response to various challenges associated with this disease, it plays a crucial role in mental health. A fundamental concept of the AI-based mental health remedy and its impact on directly affecting social-emotional learning has also been examined in this study with the appropriate material and references. The many types of AI that may unquestionably aid in general mental health education have already been specifically outlined in this research using all the data from existing books and publications. In addition to this, an AI-based chatbot platform has been built within the software system to identify various health factors that seem to be directly linked to mental health. The main challenges in this regard remained consistent with other AI-related healthcare systems including concerns for privacy and confidentiality apart from data integrity.","Anand, Neha and Pant, Lalit Mohan and Alam, Tanweer and Pundir, Sumit and Thomas, Lims and Rakshith, U.R.",,2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),2023,10.1109/ICSCDS56580.2023.10104905,,ieee.bib,2024-02-25 11:35:40,Unclassified
10356554,Authentic Dialogue Generation to Improve Youth’s Awareness of Cybergrooming for Online Safety,"This paper deals with a cybergrooming and sexual misconduct topic in artificial intelligence-based educational programs. Although cybergrooming has been recognized as a cybercrime, there is a lack of programs to protect youth from cybergrooming. We present a generative chatbot framework, SERI (Stop cybERgroomIng), that can generate fluent authentic conversations in the context of cybergrooming between a perpetrator chatbot and a potential victim chatbot. Furthermore, we propose deep-reinforcement-learning-based dialogue generation with a stage-related reward to lead the conversation to the expected stage. We also minimize potential ethical issues introduced by the perverted languages when deploying the chatbots for cybersecurity education programs. We evaluated the conversations of SERI with open-source referenced, unreferenced metrics and human evaluation. We developed SERI as a platform for deploying perpetrator chatbot to interact with youth users to observe their responses and collect reactions when they are asked for private or sensitive information by the perpetrator.","Guo, Zhen and Wang, Pei and Huang, Lifu and Cho, Jin-Hee",,2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI),2023,10.1109/ICTAI59109.2023.00017,,ieee.bib,2024-02-25 11:35:40,Unclassified
8983405,Is there an Optimal Technology to Provide Personal Supportive Feedback in Prevention of Obesity?,"Obesity is a global challenge that affects health and wellbeing worldwide. In this position paper, we review the digital technology used in prevention of obesity and present the proposed STOP project that integrates state-of-the-art wearable technology, chatbot, gamification data fusion, and machine learning with the aim to provide personalised supportive feedback for preventing obesity and maintaining healthy weight. Implication of sensitive data with General Data Protection Regulation (GDPR) is discussed. We conclude that machine learning plays an important role in data fusion, analytics, and providing optimal messaging tailored design to support healthy weight.","Sandri, Simone and Zheng, Huiru and Engel, Felix and Moorhead, Anne and Wang, Haiying and Bond, Raymond and McTear, Mike and Molinari, Andrea and Bouquet, Paolo and Hemmje, Matthias",,2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),2019,10.1109/BIBM47256.2019.8983405,,ieee.bib,2024-02-25 11:35:40,Unclassified
9672894,Developing an Implementation Framework for Automated Customer Support Service in Collaborative Customer Relationship Management Systems,"Collaborative Customer Relationship Management (CCRM) has developed Automated Customer Support Services (ACSS), where it focuses on providing more efficient and immediate customer service. Through chatbots, virtual customers, internet routing, and automated responses, technology has evolved to aid the customer support sector through automations trained by Artificial Intelligence (AI), Machine Learning (ML), and other advancements in technology. However, ACSS is relatively new with various implementation frameworks in choosing ACSS platforms developed by CRM experts for organizations. The study aims to cover the research gaps of integrating the customer perspective in terms of behavioral trends, data security issues, engagement and responses, and proper maintenance and evaluation of the ACSS performance based on the customer relationships and experience, through the development of a new implementation framework for ACSS in an organization. Through a rating-questionnaire answered by CRM experts on three (3) different ACSS based on different frameworks and the developed one by the study, the findings show that the developed framework enhances customer relationships and experiences more than the existing frameworks, thereby validating the effectiveness of the implementation framework in the study.","Li, R. C. and Tee, M. L.",,2021 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM),2021,10.1109/IEEM50564.2021.9672894,,ieee.bib,2024-02-25 11:35:40,Unclassified
9892366,Domain-Aware Federated Social Bot Detection with Multi-Relational Graph Neural Networks,"Social networks have been the widespread popular tools for communication and socialization, and it also been the ideal platform for bots to publish malicious information. Therefore, social bot detection is essential for the social network's security. Existing methods almost ignore the differences in bot behaviors in multiple domains. Thus, we first propose a DomainAware detection method with Multi-Relational Graph neural networks (DA-MRG) to improve detection performance. Specifically, DA-MRG constructs multi-relational graphs with users' features and relationships, obtains the user presentations with graph embedding and distinguishes bots from humans with domainaware classifiers. Meanwhile, considering the similarity between bot behaviors in different social networks, we believe that sharing data among them could boost detection performance. However, the data privacy of users needs to be strictly protected. To overcome the problem, we implement a study of federated learning framework for DA-MRG to achieve data sharing between different social networks and protect data privacy simultaneously. We conduct extensive experiments on TwiBot-20, and the results demonstrate that the proposed method can effectively achieve federated social bot detection.","Peng, Huailiang and Zhang, Yujun and Sun, Hao and Bai, Xu and Li, Yangyang and Wang, Shuhai",,2022 International Joint Conference on Neural Networks (IJCNN),2022,10.1109/IJCNN55064.2022.9892366,,ieee.bib,2024-02-25 11:35:40,Unclassified
10343391,Integrating Cloud-Based AI in Software Engineers' Professional Training and Development,"Artificial Intelligence (AI) has recently gained immense popularity. With impressive capabilities and versatility, large language models have quickly become a valuable tool for a wide range of applications, from chatbots and language translation to content creation and research. Generative AI can aid in the creation of computer code and provide information on a wide range of technical topics. This work-in-progress brings AI to vocational training by incorporating Cloud Computing (CC) services into a professional training and development program for software engineers, concentrating on practical skills development, hands-on experience and job-specific competencies. The approach is evaluated in the context of action research, with an emphasis on the potential benefits and challenges of code generation.","Wolfschwenger, Patrick and Sabitzer, Barbara and Lavicza, Zsolt",,2023 IEEE Frontiers in Education Conference (FIE),2023,10.1109/FIE58773.2023.10343391,,ieee.bib,2024-02-25 11:35:40,Unclassified
10062984,A Threat modeling approach to analyze and mitigate WhatsApp attacks: A Review,"One of the most popularly used features on smart-phones is WhatsApp. It is a free messaging app available for An-droid, IOS, and all other smartphones. A WhatsApp vulnerability is a hole or a weakness in the app, which can be a design flaw or an implementation bug. Through bug, an attacker can enter into the app and cause harm to the database of an application. A database contains private information like backup files, chatting information, contacts, etc. The most dangerous vulnerability in WhatsApp are Authentication, Account Hijacking, and Message Manipulation. In these vulnerabilities, an attacker can manip-ulate the message but not hijack the entire account. There are some basic requirements for a secure and privacy-preserving chat service, database backup, encrypted database, etc. The awareness about the vulnerability of WhatsApp and its security settings in new versions of WhatsApp. Use WhatsApp security features and secure the services of the application. This paper aims to be aware of the risks and vulnerabilities of WhatsApp and use the Threat modeling method to mitigate its vulnerability. It used threat Modelling steps to help organizations to quantify risks and vulnerabilities, ensuring those that need the most attention and resources do so to minimize their attack surface in a purposeful way.","Patidar, Pawan Kumar and Tomar, Deepak Singh and Pateriya, R.K. and Sharma, Yogesh Kumar",,"2023 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS)",2023,10.1109/SCEECS57921.2023.10062984,,ieee.bib,2024-02-25 11:35:40,Unclassified
10225801,ChatGPT in Education: SWOT analysis approach,"The evolution of ChatGPT is one of the major advances in the history of artificial intelligence that could add value to the education sector. However, if ChatGPT is to fulfill its potential, there must be a clear understanding of the various issues involved. There is an urgent need for understanding issues surrounding ChatGPT especially in the education sector. This study conducted a SWOT analysis for ChatGPT strategic management and technology enablement in the education sector. Based on SWOT analysis results, various issues that will affect the different stakeholders of ChatGPT in education are identified. In addition, a set of recommendations for the practitioners from the education sector who intend to use this technology are issued. Besides, different areas of research that need attention in the near future are outlined.","Alabool, Hamzeh Mohammad",,2023 International Conference on Information Technology (ICIT),2023,10.1109/ICIT58056.2023.10225801,,ieee.bib,2024-02-25 11:35:40,Unclassified
10207613,AI Forensics,"Artificial intelligence is now a daily topic of public discussion. Not only are intelligent systems such as autonomous vehicles taking the streets, but recommendation algorithms are shaping human behavior. While AI offers a significant increase in efficiency, it can also indirectly cause harm to humans by replacing jobs, violating privacy and even threatening autonomy. To keep track of these cases in which AI has negative implications on a human, databases of AI incidents have been created. We extend this idea of AI incidents to not only include times whereby an AI system caused a real-world harm, but also when it introduces a benefit. Prior work in adjacent fields has defined taxonomies and standard procedures for root cause analysis, digital forensics, AI risk management, and more. Despite these frameworks, there is no means to investigate an AI system to discover the root cause of an incident. We aim to evaluate the body of knowledge that leads to introducing the field of AI Forensics. AI forensics can serve as a postmortem analysis of AI incidents to discover the primary harm catalyst.","Lefcourt, Samuel and Falco, Gregory",,2023 IEEE International Conference on Assured Autonomy (ICAA),2023,10.1109/ICAA58325.2023.00023,,ieee.bib,2024-02-25 11:35:40,Unclassified
9751981,Application of Artificial Intelligence in Indian Banks,"Artificial Intelligence (AI) and Machine Learning (ML) have emerged as the most significant technologies of our times and are increasingly being used across businesses and industry sectors. Agaist this backdrop, banks and financial institutions are exploring tools based on AI to transform various facets of their business. These tools are expected to bring in process automation, cost efficiencies, improved decision making, product innovations, and enhanced customer experiences. This paper discusses various banking use cases and techniques, including the AI initiatives being pursued by Indian banks. Major focus areas for application of AI/ML in banking are — financial crime and compliance management, customer insight and relationship management, credit risk, and customer service.","Tiwari, Ashok Kumar and Saxena, Deepak",,2021 International Conference on Computational Performance Evaluation (ComPE),2021,10.1109/ComPE53109.2021.9751981,,ieee.bib,2024-02-25 11:35:40,Unclassified
9308962,"Towards Learning-Based, Content-Agnostic Detection of Social Bot Traffic","With the fast-growing popularity of online social networks (OSNs), the security and privacy of OSN ecosystems becomes essential for the public. Among threats OSNs face, malicious social bots have become the most common and detrimental. They are often employed to violate users’ privacy, distribute spam, and disturb the financial market, posing a compelling need for effective social bot detection solutions. Unlike traditional social bot detection approaches that have strict requirements on data sources (e.g., private payload information, social relationships, or activity histories), this article proposes a method called BotFlowMon that relies only on content-agnostic flow-level data as input to identify OSN bot traffic. BotFlowMon introduces several new algorithms and techniques to classify social bot traffic from real OSN user traffic, including aggregating network flow records to obtain OSN transaction data, fusing transaction data to extract features and visualize flows, and an innovative density-valley-based clustering algorithm to subdivide each transaction into individual actions. The evaluation shows BotFlowMon can identify the traffic from social bots with a 96.1 percent accuracy, which, based on the worst case study on a testing machine, only takes no more than 0.71 seconds on average after it sees the traffic.","Feng, Yebo and Li, Jun and Jiao, Lei and Wu, Xintao",IEEE Transactions on Dependable and Secure Computing,,2021,10.1109/TDSC.2020.3047399,,ieee.bib,2024-02-25 11:35:40,Unclassified
9994166,A Proposed Framework for Early Detection IoT Botnet,"The Internet of Things (IoT) is an overgrowing technology in both consumer and business use. This technology can significantly affect people's daily lives by changing how people drink coffee and how smart things interact with different industries. IoT could be useful in a lot of different ways. It can give businesses more information about their business, which can help them become more efficient and save money. The sheer amount of data that is created, the size and variety of networks, and the security and privacy issues that come up all slow down development and implementation. In the past few decades, distributed denial-of-service (DDoS) attacks on Internet of Things (IoT) networks have been seen as one of the most critical and urgent problems. DDoS attacks use the limited resources of IoT devices, like storage space and network bandwidth, to cause problems in IoT applications. This study looks at the different attacks that can lead to DDoS, hurting systems already in place. In this paper, we examine the potential countermeasures to these types of attacks from the perspective of a restricted device.","Mashaleh, Ashraf S and Binti Ibrahim, Noor Farizah and Alauthman, Mohammad and Almomani, Ammar",,2022 International Arab Conference on Information Technology (ACIT),2022,10.1109/ACIT57182.2022.9994166,,ieee.bib,2024-02-25 11:35:40,Unclassified
9253137,Applications of AI in cybersecurity,"Issues related to digital security are, there is no doubt for this, of utmost importance in the development of methods and support measures for organisations to successfully prepare for as well as realise their digital transformation. While big organisations and businesses may afford to buy services or develop their own in-house know-how and tools, small and medium-sized businesses are not having the means for this, be them financial resources, human resources or technology itself. This dystopic situation may on the other hand offer an unexpected and – as of today – yet unprecedented chance for innovations in terms of bridging the gap and addressing the need with use of AI technologies and services. In the paper we elaborate on a scenario that we have been developing as part of a European project that is part of the European Horizons 2020 project CS-AWARE.","Hofstetter, Matthias and Riedl, Reinhard and Gees, Thomas and Koumpis, Adamantios and Schaberreiter, Thomas",,2020 Second International Conference on Transdisciplinary AI (TransAI),2020,10.1109/TransAI49837.2020.00031,,ieee.bib,2024-02-25 11:35:40,Unclassified
9570253,Artificial Intelligence for Futuristic Banking,"Artificial Intelligence (AI) has become an essential resource for large banks that deal with regulatory changes, new Anti-Money Laundering (AML) obligations and vulnerable fraud-prone clients. Cybersecurity has thus become a hot topic due to security failures using traditional methods and concerns about how companies use the personal data collected from clients or their regular users. The most obvious apparent reason why cybersecurity is critical in banking sector transactions is to protect client assets with a high level of data privacy. The main approaches in the front office conventional banking such as AI chatbots, smart virtual assistants and biometric user authentication are discovered to answer security challenges and to enhance prosperity in the field. Concurrently, advanced AI applications in fraud detection, fraud risk monitoring, anti-money laundering techniques and cross-border payments handling are observed under the back-office operations. The paper reviews the conceptualizations of privacy concerns and the antecedents and consequences of using AI-power in the banking sector. Moreover, overlooked limitations of AI such as scarcity of quality data, a rise of hidden-bias in suggestions and obliviousness of lacking knowledge are discussed with several thriving solutions.","Thisarani, Moksha and Fernando, Subha",,"2021 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)",2021,10.1109/ICE/ITMC52061.2021.9570253,,ieee.bib,2024-02-25 11:35:40,Unclassified
10234394,Uncovering the Risks and Drawbacks Associated With the Use of Synthetic Data for Grammatical Error Correction,"In a Data-Centric AI paradigm, the model performance is enhanced without altering the model architecture, as evidenced by real-world and benchmark dataset demonstrations. With the advancements of large language models (LLM), it has become increasingly feasible to generate high-quality synthetic data, while considering the need to construct fully synthetic datasets for real-world data containing numerous personal information. However, in-depth validation of the solely synthetic data setting has yet to be conducted, despite the increased possibility of models trained exclusively on fully synthetic data emerging in the future. Therefore, we examined the question, “Do data quality control techniques (known to positively impact data-centric AI) consistently aid models trained exclusively on synthetic datasets?”. To explore this query, we performed detailed analyses using synthetic datasets generated for speech recognition postprocessing using the BackTranScription (BTS) approach. Our study primarily addressed the potential adverse effects of data quality control measures (e.g., noise injection and balanced data) and training strategies in the context of synthetic-only experiments. As a result of the experiment, we observed the negative effect that the data-centric methodology drops by a maximum of 44.03 points in the fully synthetic data setting.","Koo, Seonmin and Park, Chanjun and Lee, Seolhwa and Seo, Jaehyung and Eo, Sugyeong and Moon, Hyeonseok and Lim, Heuiseok",IEEE Access,,2023,10.1109/ACCESS.2023.3310257,,ieee.bib,2024-02-25 11:35:40,Unclassified
10221755,"A Survey on ChatGPT: AI–Generated Contents, Challenges, and Solutions","With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC technologies. Furthermore, we review the state-of-the-art AIGC watermarking approaches for regulatable AIGC paradigms regarding the AIGC model and its produced content. Finally, we identify future challenges and open research directions related to AIGC.","Wang, Yuntao and Pan, Yanghe and Yan, Miao and Su, Zhou and Luan, Tom H.",IEEE Open Journal of the Computer Society,,2023,10.1109/OJCS.2023.3300321,,ieee.bib,2024-02-25 11:35:40,Unclassified
10150620,Mining Twitter for Insights into ChatGPT Sentiment: A Machine Learning Approach,"In the past few years, ChatGPT has evolved into a powerful N.L.P. technology, with applications ranging from text generation to question resolution. However, there is still relatively little research on how the public perceives this technology. In this research, we use sentiment analysis techniques to assess the sentiment of tweets regarding ChatGPT. Users manually categorized a dataset of tweets mentioning ChatGPT as positive, negative, or indifferent based on their attitude. The overall sentiment of the tweets was therefore directly determined utilizing machine learning models including logistic regression and support vector machines. Our results show that the majority of tweets related to ChatGPT are neutral, while a smaller proportion are positive or negative. We also found that certain words and phrases, such as ""AI"" and ""language model"", are strongly associated with positive sentiment, while others, such as ""bias"" and ""privacy"", are associated with negative sentiment. These findings have important implications for the development and deployment of ChatGPT and other NLP technologies, as they suggest that public perception is influenced by factors such as trust, transparency, and ethical considerations. Overall, this paper highlights the importance of understanding public sentiment towards emerging technologies like ChatGPT, and the potential of sentiment analysis techniques to shed light on these issues","Sharma, Shivam and Aggarwal, Rahul and Kumar, Manoj",,2023 International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE),2023,10.1109/ICDCECE57866.2023.10150620,,ieee.bib,2024-02-25 11:35:40,Unclassified
10404552,GPT Based Malware: Unveiling Vulnerabilities and Creating a Way Forward in Digital Space,"The rise and development of AI-based solutions like ChatGPT have significantly changed the functioning of many enterprises, organizations, and domains including cybersecurity. The public’s open access to ChatGPT and its resources does, however, present significant security challenges. This review study aims to shed light on the emergence of GPT-based malware. As traditional malware detection systems, have advanced to mitigate many sophisticated malware attacks, threat actors are now aiming to utilize GPT and other Large Language Models (LLMs) to create sophisticated tactics to infect systems with new malware. Furthermore, this study seeks to present a select number of methods that may be utilized to reduce the hazards posed by malware developed with ChatGPT and other LLM-based tools.","Shandilya, Shishir Kumar and Prharsha, Gsv and Datta, Agni and Choudhary, Gaurav and Park, Hoonyong and You, Ilsun",,2023 International Conference on Data Security and Privacy Protection (DSPP),2023,10.1109/DSPP58763.2023.10404552,,ieee.bib,2024-02-25 11:35:40,Unclassified
10431878,ChatGPT: An Artificial Intelligence-Based Approach to Enhance Medical Applications,"The rapid advancement of generative artificial intelligence (AI) has initiated transformative changes in diverse sectors, the medical field being a prominent beneficiary. This article provides a comprehensive exploration of the impact of AI in medicine, delineating the range of opportunities and challenges that accompany its adoption. Many existing medical algorithms, while valuable, exhibit a propensity for singular-task orientation, potentially leading to suboptimal interactions and systemic disruption. This paper examines the potential of large language models (LLMs), such as ChatGPT, to improve medical algorithms. It discusses the basic principles of LLM and provides a detailed analysis of ChatGPT, highlighting its exceptional interactive capabilities. Additionally, the study evaluates the real-world applications of ChatGPT in the medical domain, comparing its performance with other leading LLMs through clinically relevant experiments and rigorous analysis. Although ChatGPT is still in its basic versions, this work emphasizes the need to explore and improve its capabilities for medical applications to improve interaction and reduce human costs in the future.","Chaddad, Ahmad and He, Changhong and Jiang, Yuchen",,2023 IEEE 23rd International Conference on Bioinformatics and Bioengineering (BIBE),2023,10.1109/BIBE60311.2023.00078,,ieee.bib,2024-02-25 11:35:40,Unclassified
10375413,Cyber Fusion: Exploring the Synergy of Social Media and Artificial Intelligence in the Digital Age,"This research paper delves into the profound and transformative synergy between social media and artificial intelligence (AI) in the digital age, exploring its multifaceted implications. It investigates how AI algorithms are harnessed to mine and decipher the vast reservoirs of data continuously generated by social media users, impacting various dimensions of our digital lives. From personalized content recommendations to content moderation, sentiment analysis, and chatbots, we uncover the far-reaching effects of this collaboration. However, as this partnership's power grows, concerns related to data privacy, ethics, and responsible AI usage rise. The study's objective is to investigate how AI is integrated into social media platforms, its applications, and its influence on businesses, government policies, and society. The overarching issue is to understand and navigate this dynamic synergy, ensuring responsible and ethical utilization while optimizing the benefits and mitigating challenges. The paper also reviews existing literature, presents real-world examples, and offers recommendations to address the evolving landscape of AI in social media. Striking a balance between innovation and user protection is essential, emphasizing ethical frameworks and empowering users to control their online experiences. This exploration highlights the intricate relationship between AI and social media, reflecting the broader challenges of our data-driven world. Ensuring ethical AI practices, effective regulation, and innovation will be critical to maintaining a positive impact on our digital society.","Qaruty, Suha Al and AL-Tkhayneh, Khawlah M. and Hadi, Samer Abdel and Qaruty, Reema Al and Kamel Ellala, Ziyad",,"2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)",2023,10.1109/SNAMS60348.2023.10375413,,ieee.bib,2024-02-25 11:35:40,Unclassified
10431645,The Effect of Human v/s Synthetic Test Data and Round-Tripping on Assessment of Sentiment Analysis Systems for Bias,"Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that output polarity and emotional intensity when given a piece of text as input. Like other AIs, SASs are also known to have unstable behavior when subjected to changes in data which can make them problematic to trust out of concerns like bias when AI works with humans and data has protected attributes like gender, race, and age. Recently, an approach was introduced to assess SASs in a blackbox setting without training data or code, and rating them for bias using synthetic English data. We augment it by introducing two human-generated chatbot datasets and also considering a round-trip setting of translating the data from one language to the same through an intermediate language. We find that these settings show SASs performance in a more realistic light. Specifically, we find that rating SASs on the chatbot data showed more bias compared to the synthetic data, and round-tripping using Spanish and Danish as intermediate languages reduces the bias (up to 68% reduction) in human-generated data while, in synthetic data, it takes a surprising turn by increasing the bias! Our findings will help researchers and practitioners refine their SAS testing strategies and foster trust as SASs are considered part of more mission-critical applications for global use.","Lakkaraju, Kausik and Gupta, Aniket and Srivastava, Biplav and Valtorta, Marco and Wu, Dezhi",,"2023 5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)",2023,10.1109/TPS-ISA58951.2023.00053,,ieee.bib,2024-02-25 11:35:40,Unclassified
10417867,Factors Influencing Perceived Switching Cost and User Switching Behavior Towards AI-Based Solutions and Technologies - A Systematic Review,"The swift progress of artificial intelligence (AI), deep learning, and natural language processing brought massive changes across diverse domains. A substantial body of research underscored the advantages of AI technologies for consumers and identified motivational factors for their adoption. Current systematic literature reviews usually examined the traditional Technology Acceptance Model (TAM), Unified Theory of Acceptance and Use of Technology (UTAUT), and AI Device Use Acceptance (AIDUA), focused on a single solution or technology. On the other hand, the importance of perceived switching cost and measurement of switching behavior is an essential part of well-established and widely used theories (Push-Pull-Mooring (PPM) framework, Status Quo Bias theory, Lazy User Theory, etc.). By following the PRISMA 2020 guidelines, this literature review highlights studies that observe switching costs and switching behavior towards AI-based solutions. $\mathrm{N} = 2,739$ articles were initially identified in prominent databases (IEEE Xplore, Scopus, Web of Science, and EBSCO Host). After screening, $n = 7$ articles were deemed suitable for inclusion, and most of them relied on the Dual-factor framework and PPM framework. In many cases, these frameworks were integrated with theories and models such as the Status Quo Bias theory, UTAUT, TAM, and TAM3 to provide an understanding of underlying factors affecting user behavior and decision-making. Positive factors influencing switching behavior towards AI adoption include recognizing human limitations, while simultaneously perceiving advantages of AI technology, such as ease of use, efficiency, and personalized experiences. Negative factors, which hinder AI acceptance, encompass privacy risks, inertia, uncertainty, regret avoidance, and cognitive biases.","Đerić, Elena and Frank, Domagoj and Tomić, Zoran",,2023 IEEE 21st Jubilee International Symposium on Intelligent Systems and Informatics (SISY),2023,10.1109/SISY60376.2023.10417867,,ieee.bib,2024-02-25 11:35:40,Unclassified
10284878,A Dimensional Perspective Analysis on the Cybersecurity Risks and Opportunities of ChatGPT-Like Information Systems,"As a recent breakthrough in generative artificial intelligence, ChatGPT is capable of creating new data, images, audio, or text content based on user context. In the field of cybersecurity, it provides generative automated AI services such as network detection, malware protection, and privacy compliance monitoring. However, it also faces significant security risks during its design, training, and operation phases, including privacy breaches, content abuse, prompt word attacks, model stealing attacks, abnormal structure attacks, data poisoning attacks, model hijacking attacks, and sponge attacks. This paper starts from the risks and events that ChatGPT has recently faced, proposes a framework for analyzing cybersecurity in cyberspace, and envisions adversarial models and systems. It puts forward a new evolutionary relationship between attackers and defenders using ChatGPT to enhance their own capabilities in a changing environment and predicts the future development of ChatGPT from a security perspective.","Hu, Chunhui and Chen, Jianfeng",,2023 International Conference on Networking and Network Applications (NaNA),2023,10.1109/NaNA60121.2023.00061,,ieee.bib,2024-02-25 11:35:40,Unclassified
10200060,Alumni Management and Networking System,"The Alumni Management and Networking System aims to address the challenges of alumni disconnection and facilitate effective communication and engagement between educational institutions and their alumni. The system provides a platform for institutes to create profiles, connect with fellow alumni and offers opportunities for alumni to contribute to the institution's success through mentorship, volunteering, and other forms of support. This paper reviews existing research on alumni management systems, highlighting their strengths, limitations, and gaps. It evaluates different approaches such as centralized systems, data collection methods, interactive questionnaires, secure messaging, and tag recommendation systems. The proposed Alumni Network Management System incorporates content-based tagging, utilizing a fine-tuned BERT model trained on a dataset of 10,000 Twitter posts. This approach generates relevant tags for new social media posts, enhancing content visibility and discoverability. Additionally, it employs end-to-end encryption for secure messaging, ensuring privacy and confidentiality. The system's implementation has been tested successfully, showcasing its user-friendliness and effectiveness in managing alumni databases. The results indicate that the system provides a convenient platform for alumni to update their information, stay connected, and engage with their alma mater.","S, Rajini and B, Hari Prasad and A, Upendrasingh",,"2023 2nd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)",2023,10.1109/ICAECA56562.2023.10200060,,ieee.bib,2024-02-25 11:35:40,Unclassified
10402441,Everything is Just Beginning: ChatGPT in the Educational and Scientific Space of Ukrainian Universities,"The article presents research on using artificial intelligence in education and science in Ukraine, using Berdyansk State Pedagogical University as an example. A survey of 135 teachers and 428 students was conducted regarding their experience with ChatGPT. The survey results showed that students are more inclined to use artificial intelligence than teachers. The research results confirm the potential of artificial intelligence to improve the quality of education and scientific research in Ukraine but also highlight the need for a cautious approach to its use, considering possible risks and costs.","Tsybuliak, Natalia and Popova, Anastasia and Lopatina, Hanna and Suchikova, Yana and Kovachov, Sergii and Popov, Filip",,2023 IEEE 5th International Conference on Modern Electrical and Energy System (MEES),2023,10.1109/MEES61502.2023.10402441,,ieee.bib,2024-02-25 11:35:40,Unclassified
10068744,HiVeGPT: Human-Machine-Augmented Intelligent Vehicles With Generative Pre-Trained Transformer,"Recently, a chat generative pre-trained transformer (ChatGPT) attracts widespread attention in the academies and industries because of its powerful conversational ability with human and its astonishing emergence ability such as admit mistakes, reject inappropriate problems. However, it is not easy to generalize ChatGPT into the field of intelligent vehicles because of its high computational cost, uncertain answers and decisions, and the difficulty of scenario generation for intelligent vehicles. To address these issues, we propose a novel framework, human-machine-augmented intelligent vehicles with generative pre-trained transformer. Under this framework, we discuss the potential, prospects, limitations and several typical applications of HiVeGPT in the domain of intelligent vehicles.","Zhang, Junping and Pu, Jian and Xue, Jianru and Yang, Ming and Xu, Xin and Wang, Xiao and Wang, Fei-Yue",IEEE Transactions on Intelligent Vehicles,,2023,10.1109/TIV.2023.3256982,,ieee.bib,2024-02-25 11:35:40,Unclassified
10268594,An Overview on Generative AI at Scale With Edge–Cloud Computing,"As a specific category of artificial intelligence (AI), generative artificial intelligence (GenAI) generates new content that resembles what humans create. The rapid development of GenAI systems has created a huge amount of new data on the Internet, posing new challenges to current computing and communication frameworks. Currently, GenAI services rely on the traditional cloud computing framework due to the need for large computation resources. However, such services will encounter high latency because of data transmission and a high volume of user requests. On the other hand, edge-cloud computing can provide adequate computation power and low latency at the same time through the collaboration between edges and the cloud. Thus, it is attractive to build GenAI systems at scale by leveraging the edge-cloud computing paradigm. In this overview paper, we review recent developments in GenAI and edge-cloud computing, respectively. Then, we use two exemplary GenAI applications to discuss technical challenges in scaling up their solutions using edge-cloud collaborative systems. Finally, we list design considerations for training and deploying GenAI systems at scale and point out future research directions.","Wang, Yun-Cheng and Xue, Jintang and Wei, Chengwei and Kuo, C. -C. Jay",IEEE Open Journal of the Communications Society,,2023,10.1109/OJCOMS.2023.3320646,,ieee.bib,2024-02-25 11:35:40,Unclassified
9793412,Working Alongside Non-Human Agents,"We coexist with non-human AI agents, and we now must plan for human and non-human-agent teaming, for cooperation and collaboration, as a means to expand collaborative intelligence in our ongoing quest for user advocacy. For practice and experimentation, we provide links to current non-human agents. We then distinguish automation and autonomy, and discuss humanness design, teaming. A deeper understanding of usability and ethical considerations for working alongside these systems, deploying robots and building bonds and trust with nonhuman agents, begins with differentiation of automation and autonomy, human-autonomy teaming, and a humanness design approach as a means to prevent undesirable autonomy. While TPC scholarship attends to privacy, accountability, safety and security, and transparency and explainability, we need additional vigilance regarding fairness and non-discrimination, human control of technology, TPC professional responsibility, and continued promotion of human values as we work alongside non-human agents.","Duin, Ann Hill and Pedersen, Isabel",,2021 IEEE International Professional Communication Conference (ProComm),2021,10.1109/ProComm52174.2021.00005,,ieee.bib,2024-02-25 11:35:40,Unclassified
10398369,"ChatGPT and Moodle Walk into a Bar: Capabilities, Integration, Use Cases, and Challenges","Are you ready to explore the next frontier in e-learning with ChatGPT? This innovative artificial intelligence technology will revolutionize the way we teach and learn in Moodle, the world-renowned Learning Management System. This article draws attention to five powerful capabilities of ChatGPT: contextual conversing, feedback response, analytical power, adaptive tutoring, and multilingual capabilities. It explains a three-step technical procedure of integrating ChatGPT in Moodle using a publicly accessible Moodle instance at ResearchIC.com. A follow-up of eight use cases provides a user manual for the system, prompting for information, performing calculations on numerical data, interpreting data analysis results, generating data for educational purposes, supporting course design activities, providing emotional support, and supporting extended learning. The article concludes with a discussion of six challenges that may arise, but overall maintains an optimistic view of the future of applying ChatGPT to enhance teaching and learning. This research has the potential to inform and inspire multiple stakeholders in higher education institutions (e.g., students, teachers, system admins) to experiment with ChatGPT in their online teaching and learning environments.","Lin, Jingjing",,"2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)",2023,10.1109/TALE56641.2023.10398369,,ieee.bib,2024-02-25 11:35:40,Unclassified
10420194,Language AI in Programming: A Case Study of ChatGPT in Higher Eduation Using Natural Language Processing,"ChatGPT is an emerging technology used in education. It provides promising support to enhance teaching and learning activities. However, there is lacking understanding of its use to programming courses in computing programs. This study investigates the benefits, issues, and challenges of using ChatGPT, a language AI model, in programming tasks. Data was collected through surveys administered to undergraduate students in computing programs across various National Capital Region (NCR) universities. The collected data was analyzed using Natural Language Processing (NLP) and Latent Dirichlet Allocation (LDA) techniques to gain insights from the students responses. A word intrusion test assessed theme coherence, and evaluators demonstrated moderate agreement (Fleiss Kappa score: 0.62). The study reveals the benefits of employing ChatGPT for programming, including efficient coding, understanding complex codes, and its capability to be used as a problem-solving tool. However, it highlights critical issues and challenges, such as data privacy and ethical concerns, plagiarism tendencies, and contextual understanding limitations. The findings contribute valuable insights for developers, educators, and researchers interested in leveraging language AI models like ChatGPT to enhance programming workflows while effectively addressing associated challenges.","Padilla, Jay Rhald C. and Montefalcon, Myron Darrel L. and Hernandez, Alexander A.",,"2023 IEEE 11th Conference on Systems, Process & Control (ICSPC)",2023,10.1109/ICSPC59664.2023.10420194,,ieee.bib,2024-02-25 11:35:40,Unclassified
10126086,"Bias Detection for Customer Interaction Data: A Survey on Datasets, Methods, and Tools","With the increase in usage of machine learning models within many different aspects of customer interactions, it has become very clear that bias detection within associated customer interaction datasets has led to a critical focus on issues such as the identification of bias prior to model building, lack of understanding and transparency within models, and ultimately the prevention of biased predictions or classifications. This has never been more important since the introduction of the EU General Data Protection Regulation (GDPR) and the associated rule of “right of explanation”. In this paper, we survey the state of the art for bias detection, avoidance and mitigation within datasets, and the associated methods and tools available. Our purpose is to establish an understanding of how established customer interaction-based use cases can utilise these techniques. The focus is primarily on tackling the bias in unstructured text data as a pre-process prior to the machine learning model training phase. We hope that this research encourages the further establishment of responsible usage of customer interaction datasets to allow the prevention of bias being introduced into machine learning pipelines and to also allow greater awareness of the potential for further research in this area.","Donald, Andy and Galanopoulos, Apostolos and Curry, Edward and Muñoz, Emir and Ullah, Ihsan and Waskow, M. A. and Dabrowski, Maciej and Kalra, Manan",IEEE Access,,2023,10.1109/ACCESS.2023.3276757,,ieee.bib,2024-02-25 11:35:40,Unclassified
9967663,Mental Health Mobile Apps to Empower Psychotherapy: A Narrative Review,"Mental health care has been enriched with progressive use of technology during the last ten years, contributing to create new paradigms and methodologies. Mobile apps and smartphones have become the most widespread access point for many people who look for self-help in the psychological domain. In this paper, we focused on a narrative review of the state of the art of mobile apps for mental health, focusing on the blending of apps with psychotherapy contexts in what can be called “blended psychotherapy’. Research shows many hints that this might be a winning combination in many scenarios, but at the same time, many issues must still be faced in this yet emerging scientific field. In conclusion, we try to put together some major guidelines for mental health mobile app development in the context of psychological treatments.","Diano, Federico and Ponticorvo, Michela and Sica, Luigia Simona",,"2022 IEEE International Conference on Metrology for Extended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)",2022,10.1109/MetroXRAINE54828.2022.9967663,,ieee.bib,2024-02-25 11:35:40,Unclassified
10353398,Audio-based CAPTCHA Verification to Secure Web Applications,"With the progression of internet era, the number of web robots checking on any web application is increasing exponentially. Manifold malfunction activities have been used by adversaries to breach the security of web applications. Therefore, securing a web application has become a prime aspect to protect any application from spammers. The technology of CAPTCHA emerged as a common security measure that can easily detect any bot spammer by differentiating them from common users. In literature, various CAPTCHA verification techniques have been proposed and adopted to ensure the security of web applications like text-based, image-based, audio-based verification etc. This research work presents an effective audio-based CAPTCHA verification technique which basically involves two steps security process. Thus, enhances security aspects compared to the other CAPTCHA techniques.","Sharma, Avani and Agrawal, Aayushi and Mitra, Priyanka and Singh, Harkirat",,2023 4th IEEE Global Conference for Advancement in Technology (GCAT),2023,10.1109/GCAT59970.2023.10353398,,ieee.bib,2024-02-25 11:35:40,Unclassified
9939282,Ethical and Sustainability Considerations for Knowledge Graph based Machine Learning,"Artificial Intelligence (AI) and Machine Learning (ML) are becoming common in our daily lives. The AI-driven processes significantly affect us as individuals and as a society, spanning across ethical dimensions like discrimination, misinformation, and fraud. Several of these AI & ML approaches rely on Knowledge Graph (KG) data. Due to the large volume and complexity of today's KG-driven approaches, enormous resources are spent to utilize the complex AI approaches. Efficient usage of the resources like hardware and power consumption is essential for sustainable KG-based ML technologies. This paper introduces the ethical and sustainability considerations, challenges, and optimizations in the context of KG-based ML. We have grouped the ethical and sustainability aspects according to the typical Research & Development (R&D) lifecycle: an initial investigation of the AI approach's responsibility dimensions; technical system setup; central KG data analytics and curating; model selection, training, and evaluation; and final technology deployment. We also describe significant trade-offs and alternative options for dedicated scenarios enriched through existing and reported ethical and sustainability issues in AI-driven approaches and research. These include, e.g., efficient hardware usage guidelines; or the trade-off between transparency and accessibility compared to the risk of manipulability and privacy-related data disclosure. In addition, we propose how biased data and barely explainable AI can result in discriminating ML predictions. This work supports researchers and developers in reflecting, evaluating, and optimizing dedicated KG-based ML approaches in the dimensions of ethics and sustainability.","Draschner, Carsten Felix and Jabeen, Hajira and Lehmann, Jens",,2022 IEEE Fifth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),2022,10.1109/AIKE55402.2022.00015,,ieee.bib,2024-02-25 11:35:40,Unclassified
10398064,Revolutionizing Tourism and Hospitality Services: Integrating AI in the Metaverse,"The purpose of the study is to examine the integration of AI into the metaverse for exploring the potential benefits and issues in the hospitality and tourism industry. The study highlights the structure of integration through a conceptual model and fragmenting each parameter included separately and covers a comprehensive analysis of the structural formulation of a metaverse in the industry. Additionally, elaborates on security issues and countermeasures. The paper provides a framework for businesses in exploring and revolutionizing the industry with innovative ideas. However, the analysis is constrained to a conceptual model, creating a real-time virtual environment will be the future agenda.","Nair, Arjun J and Manohar, Sridhar and Mittal, Amit and Khanna, Vandana",,2023 6th International Conference on Contemporary Computing and Informatics (IC3I),2023,10.1109/IC3I59117.2023.10398064,,ieee.bib,2024-02-25 11:35:40,Unclassified
10261002,Vision: Requirements Engineering for Software Development in Aged Care,"Technology can play a key role in enabling the aged care system to provide better care for the older adults. In the past few years we have collaborated with several industry partners working in the field of aged care. Some of these operate and maintain aged care facilities, and some provide technological solutions to aged care providers. These collaborations involved extensive requirements elicitation to identify the needs of aged care residents, carers, clinical staff and facility administrators, on projects including mobile apps, data analysis, workforce training, and smart homes. Based on these, we have come up with a vision on a number of opportunities, and exposed many significant challenges, for requirements engineering in the aged care software domain that must be addressed. We summarise some of these requirements engineering challenges and a propose a vision with a framework to help address them in next-generation aged care software projects.","Grundy, John and Madugalla, Anuradha and McIntosh, Jennifer and Tran, Truyen",,2023 IEEE 31st International Requirements Engineering Conference Workshops (REW),2023,10.1109/REW57809.2023.00083,,ieee.bib,2024-02-25 11:35:40,Unclassified
10388962,"AīCare: An Affordable, Reliable, and Intelligent Senior Care Ecosystem","Global population aging has become an issue nowadays, which will eventually lead to a huge senior care market in the future. Currently, with the current senior care services and product, several critical issues exist which prevents seniors from getting care. The top reported problem includes the lack of professionals, overpriced services or products, insufficient attention to seniors’ mental needs, and insufficient government regulations. In this paper, a senior care ecosystem, named AīCare, was proposed to revolutionize the future senior care industry. The AīCare senior care ecosystem combined exponential technologies, such as IoT, robotics, and AI, to deliver affordable, reliable, and intelligent senior care services and products. The project was systematically planned and designed utilizing the Purpose Launchpad, coupled with business development tools provided by the Purpose Alliance. A low-fidelity prototype of this ecosystem was conceptualized as part of the innovation process. To substantiate the proposed hypotheses, two experimental cycles were implemented across China and Canada. The feedback acquired from these experiments continuously refines our ideas and directs the way for future development in this crucial sector. Our senior care ecosystem is not designed to entirely supplant the existing workforce of senior care professionals. Rather, our objective is to provide dependable and effective aids to complement their efforts, thereby enhancing their capability to cater to individuals requiring additional attention. This innovative approach intends to amplify the efficacy of current systems and contributes significantly towards the evolution of senior care, ultimately augmenting the quality-of-care provision.","Wu, Yuqi and Huang, Wenshan and Ye, Xuanjie and Chen, Jie",,2023 IEEE Biomedical Circuits and Systems Conference (BioCAS),2023,10.1109/BioCAS58349.2023.10388962,,ieee.bib,2024-02-25 11:35:40,Unclassified
10260937,Based on Past Experience: Highlighting Potential Human Value Issues in Domain Modelling,"In this technologically evolving era, important human values such as freedom and social responsibility are frequently overlooked in software systems, which can have significant negative social consequences as can be seen by recent examples involving Facebook or Delta Airlines. Therefore, it is important to help software developers incorporate human values considerations throughout the software development process. In this paper, we focus on domain modelling with class diagrams, an important technique for requirements engineering and early design activities. We propose a domain-specific language called HVT (Human Value Trigger) that enables the collection of human value issues including how to mitigate them. Practitioners may utilize this language to contribute more such examples to grow a catalogue of these past experiences over time. As a motivating example, we analyze the domain model of WhatsApp through the lens of Schwartz's taxonomy of human values to compile a list of issues concerning human values (i.e., model elements that may affect various human values). Furthermore as proof-of-concept, a prototype implementation addresses the need for human values to be integrated in domain models with the help of these collected past experiences by providing suggestions based on the model element type, name, and semantics based on synonyms. An analysis of eight synonym services is performed to find the optimal synonym service or combination of synonym services to use with the implementation.","Kaur, Jasneet and Mussbacher, Gunter",,2023 IEEE 31st International Requirements Engineering Conference Workshops (REW),2023,10.1109/REW57809.2023.00054,,ieee.bib,2024-02-25 11:35:40,Unclassified
10121440,"Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models","The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across several case studies and contrasts the performances with prior studies.","Maddigan, Paula and Susnjak, Teo",IEEE Access,,2023,10.1109/ACCESS.2023.3274199,,ieee.bib,2024-02-25 11:35:40,Unclassified
5958029,Inference of Expressive Declassification Policies,"We explore the inference of expressive human-readable declassification policies as a step towards providing practical tools and techniques for strong language-based information security. Security-type systems can enforce expressive information-security policies, but can require enormous programmer effort before any security benefit is realized. To reduce the burden on the programmer, we focus on inference of expressive yet intuitive information-security policies from programs with few programmer annotations. We define a novel security policy language that can express what information a program may release, under what conditions (or, when) such release may occur, and which procedures are involved with the release (or, where in the code the release occur). We describe a dataflow analysis for precisely inferring these policies, and build a tool that instantiates this analysis for the Java programming language. We validate the policies, analysis, and our implementation by applying the tool to a collection of simple Java programs.","Vaughan, Jeffrey A. and Chong, Stephen",,2011 IEEE Symposium on Security and Privacy,2011,10.1109/SP.2011.20,,ieee.bib,2024-02-25 11:35:40,Unclassified
9216065,"Artificial Intelligence Security Threat, Crime, and Forensics: Taxonomy and Open Issues","Advances in Artificial Intelligence (AI) have influenced almost every field including computer science, robotics, social engineering, psychology, criminology and so on. Although AI has solved various challenges, potential security threats of AI algorithms and training data have been stressed by AI researchers. As AI system inherits security threats of traditional computer system, the concern about novel cyberattack enhanced by AI is also growing. In addition, AI is deeply connected to physical space (e.g. autonomous vehicle, intelligent virtual assistant), so AI-related crime can harm people physically, beyond the cyberspace. In this context, we represent a literature review of security threats and AI-related crime. Based on the literature review, this article defines the term AI crime and classifies AI crime into 2 categories: AI as tool crime and AI as target crime, inspired by a taxonomy of cybercrime: Computer as tool crime and Computer as tool crime. Through the proposed taxonomy, foreseeable AI crimes are systematically studied and related forensic techniques are also addressed. We also analyze the characteristics of the AI crimes and present challenges that are difficult to be solved with the traditional forensic techniques. Finally, open issues are presented, with emphasis on the need to establish novel strategies for AI forensics.","Jeong, Doowon",IEEE Access,,2020,10.1109/ACCESS.2020.3029280,,ieee.bib,2024-02-25 11:35:40,Unclassified
10025250,Oxygen: A Distributed Health Care Framework for Patient Health Record Management and Pharmaceutical Diagnosis,"With the COVID-19 pandemic, the world is confronting various healthcare issues, and healthcare automation is more crucial than ever. The pandemic has revealed the limitations of existing digital healthcare systems to manage public health emergencies. There is no registered population for many healthcare institutions in Sri Lanka, as a result, there is a communication gap. Electronic Health Record systems (EHRs) are becoming popular to share patient details but accessing scattered data across several EHRs while safeguarding patient privacy remains a challenge. Most of these medical records are in printed format and manually entering those into EHR systems is time-consuming and error prone. Not only that pharmaceutical error is a critical healthcare problem, but it is even riskier to visit doctors for pharmaceutical diagnosis during a pandemic. This research introduces a Blockchain-based patient health record system, an Optical Character Recognition (OCR) and Natural Language Processing (NLP) based Medical Document Scanner, a Drug Identifier based on Image Processing and a Medical Chatbot powered by NLP as four novel approaches to address these issues. Altogether with the results, this research aims at introducing a solution for the limitations in healthcare while providing a distributed healthcare framework for the healthcare community worldwide.","Wickramarathna, Maleesha and De Silva, Kithmini and Lekamalage, Vihanga and Senanayake, Janith and Perera, Jeewaka and Ruggahakotuwa, Laneesha",,2022 4th International Conference on Advancements in Computing (ICAC),2022,10.1109/ICAC57685.2022.10025250,,ieee.bib,2024-02-25 11:35:40,Unclassified
10128125,Detecting and Mitigating Botnet Attacks in Software-Defined Networks Using Deep Learning Techniques,"Software-Defined Networking (SDN) is an emerging architecture that enables flexible and easy management and communication of large-scale networks. It offers programmable and centralized interfaces for making complex network decisions dynamically and seamlessly. However, SDN provides opportunities for businesses and individuals to build network applications based on their demands and improve their services. In contrast, it started to face a new array of security and privacy challenges and simultaneously introduced the threats of a single point of failure. Usually, attackers launch malicious attacks such as botnets and Distributed Denial of Service (DDoS) to the controller through OpenFlow switches. Deep learning (DL)-based security applications are trending, effectively detecting and mitigating potential threats with fast response. In this article, we analyze and show the performance of the DL methods to detect botnet-based DDoS attacks in an SDN-supported environment. A newly self-generated dataset is used for the evaluation. We also used feature weighting and tuning methods to select the best subset of features. We verify the measurements and simulation outcomes over a self-generated dataset and real testbed settings. The main aim of this study is to find a lightweight DL method with baseline hyper-parameters to detect botnet-based DDoS attacks with features and data that can be easily acquired. We observed that the best subset of features influences the performance of the DL method, and the prediction accuracy of the same method could be variated with a different set of features. Finally, based on empirical results, we found that the CNN method outperforms the dataset and real testbed settings. The detection rate of CNN reaches 99% for normal flows and 97% for attack flows.","Nadeem, Muhammad Waqas and Goh, Hock Guan and Aun, Yichiet and Ponnusamy, Vasaki",IEEE Access,,2023,10.1109/ACCESS.2023.3277397,,ieee.bib,2024-02-25 11:35:40,Unclassified
10411395,PockEngine: Sparse and Efficient Fine-tuning in a Pocket,"On-device learning and efficient fine-tuning enable continuous and privacy-preserving customization (e.g., locally fine-tuning large language models on personalized data). However, existing training frameworks are designed for cloud servers with powerful accelerators (e.g., GPUs, TPUs) and lack the optimizations for learning on the edge, which faces challenges of resource limitations and edge hardware diversity. We introduce PockEngine: a tiny, sparse and efficient engine to enable fine-tuning on various edge devices. PockEngine supports sparse backpropagation: it prunes the backward graph and sparsely updates the model with measured memory saving and latency reduction while maintaining the model quality. Secondly, PockEngine is compilation first: the entire training graph (including forward, backward and optimization steps) is derived at compile-time, which reduces the runtime overhead and brings opportunities for graph transformations. PockEngine also integrates a rich set of training graph optimizations, thus can further accelerate the training cost, including operator reordering and backend switching. PockEngine supports diverse applications, frontends and hardware backends: it flexibly compiles and tunes models defined in PyTorch/TensorFlow/Jax and deploys binaries to mobile CPU/GPU/DSPs. We evaluated PockEngine on both vision models and large language models. PockEngine achieves up to 15 × speedup over off-the-shelf TensorFlow (Raspberry Pi), 5.6 memory saving back-propagation (Jetson AGX Orin). Remarkabl×y, PockEngine enables fine-tuning LLaMav2-7B on NVIDIA Jetson AGX Orin at 550 tokens/s, 7.9× faster than the PyTorch.CCS CONCEPTS• Computer systems organization → Neural networks.","Zhu, Ligeng and Hu, Lanxiang and Lin, Ji and Wang, Wei-Chen and Chen, Wei-Ming and Gan, Chuang and Han, Song",,2023 56th IEEE/ACM International Symposium on Microarchitecture (MICRO),2023,,,ieee.bib,2024-02-25 11:35:40,Unclassified
10354236,Advancing Mental Health Diagnostics: GPT-Based Method for Depression Detection,"In this paper, we present a novel artificial intelligence (AI) application for depression detection, using advanced transformer networks to analyse clinical interviews. By incorporating simulated data to enhance traditional datasets, we overcome limitations in data protection and privacy, consequently improving the model’s performance. Our methodology employs BERT-based models, GPT-3.5, and ChatGPT-4, demonstrating state-of-the-art results in detecting depression from linguistic patterns and contextual information that significantly outperform previous approaches. Utilising the DAIC-WOZ and Extended-DAIC datasets, our study showcases the potential of the proposed application in revolutionising mental health care through early depression detection and intervention. Empirical results from various experiments highlight the efficacy of our approach and its suitability for real-world implementation. Furthermore, we acknowledge the ethical, legal, and social implications of AI in mental health diagnostics. Ultimately, our study underscores the transformative potential of AI in mental health diagnostics, paving the way for innovative solutions that can facilitate early intervention and improve patient outcomes.","Danner, Michael and Hadzic, Bakir and Gerhardt, Sophie and Ludwig, Simon and Uslu, Irem and Shao, Peng and Weber, Thomas and Shiban, Youssef and Ratsch, Matthias",,2023 62nd Annual Conference of the Society of Instrument and Control Engineers (SICE),2023,10.23919/SICE59929.2023.10354236,,ieee.bib,2024-02-25 11:35:40,Unclassified
9823891,An Empirical Analysis in Measuring the Impact of Artificial Intelligence for Better Marketing Communication to the End-Users Effectively in the Digital Era,"“Artificial Intelligence or AI” has allowed businesses to have a deeper understanding of their clients and address them more accurately with customized digital messaging. As a result, a growing number of financial service companies are incorporating AI into their operations. “Artificial Intelligence Marketing (AIM)” is a strategy for improving customer satisfaction by maximising the use of information and technology. “Big Data Analytics”, “deep learning”, and collecting intelligence about the functional analysis of clients are some of the approaches employed to achieve this goal. As a result of these actions, this period has been dubbed “The AI Marketing Concept,” which needs a fundamental transformation in the way marketers interact with their customers and develop strategies to achieve their objectives. Examining some of the ways that “artificial intelligence (AI)” can assist merchants to alter marketing techniques and achievements in the future. Based on the primary and secondary analysis, researchers have collected data regarding the impact of artificial intelligence for creating better communication to end users.","Malviya, Bindoo and Othman, Bestoon and Saxena, Komal and Shailmadhur and Vikas and Almashaqbeh, Hashem Ali",,2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),2022,10.1109/ICACITE53722.2022.9823891,,ieee.bib,2024-02-25 11:35:40,Unclassified
10390207,The Rise of Virtual Health Assistants: Chatbot-Based Healthcare Support and Counseling Using Recurrent Neural Networks (RNNs),"Health Assistant Bot is an advanced AI-powered virtual health assistant to enhances patients' ability to receive more individualized care. Health Assistant Bot's capabilities in symptom recognition, physician recommendation, and essential health information provision are discussed in this study, along with its creation and evaluation. Extensive testing and analysis have shown that the system is accurate, effective, and user-friendly. The problems of false information and data privacy are addressed by Health Assistant Bot, guaranteeing its ethical and responsible use in healthcare settings. By harnessing technology, Health Assistant Bot supplements human caretakers and gives patients more agency in their treatment. By invisibly integrating state-of-the-art technology into healthcare practices, the virtual assistant paves the way for care centered on the patient. The proposed model of RNN gave an accuracy of 90.20%, precision of 88.50%, recall of 88% and Fl Score of 89.20%. Embrace the transformative potential of the Health Assistant Bot, which encourages better healthcare outcomes through co-production and gives people more agencies.","Burri, Srinivasa Rao and Ghorpade, Vasundhara Vijay and Dutt, Vishal and Lipi, Kumari",,2023 3rd International Conference on Technological Advancements in Computational Sciences (ICTACS),2023,10.1109/ICTACS59847.2023.10390207,,ieee.bib,2024-02-25 11:35:40,Unclassified
10425000,Enhancing Digital Investigation: Leveraging ChatGPT for Evidence Identification and Analysis in Digital Forensics,"The potential value of ChatGPT, more specifically GPT 3.5 and GPT 4, is assessed in locating evidence for digital investigation. Investigators can benefit from ChatGPT as a tool. With the help of ChatGPT, various evidence identification tasks, including evidence evaluation, interpretation of the language, conceptual comprehension, phrase and word extraction, criminal examination of communication patterns can be analysed. The research highlights how AI models can process enormous volumes of data, improving investigators speed and accuracy. Furthermore, it examines the advantages and consequences of employing ChatGPT and other artificial intelligence (AI) tools to find evidence, including the potential for efficiency and scalability. The findings shed light on ChatGPT's game-changing potential in the realm of digital forensics and offer suggestions for its responsible future growth. To ascertain the efficacy and efficiency of AI-based methods in this area, several articles that concentrate on ChatGPT Forensics Analysis Evidence Identification (CFA-EI) framework have been evaluated and reviewed.","K, Sreya E and Sakshi and Wadhwa, Manisha",,"2023 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)",2023,10.1109/ICCCIS60361.2023.10425000,,ieee.bib,2024-02-25 11:35:40,Unclassified
10402380,Educational Potential of ChatGPT: Teaching Tool for Students’ Competencies Development,"The article has characterized ChatGPT as widespread application in various aspects of higher education and considered some potential benefits of ChatGPT as well as the challenges and barriers that may arise from its integration in education. Utilizing SWOT-analysis the authors have assessed strengths, weaknesses, opportunities, and threats of ChatGPT in the context of its application in education. The article proves that ChatGPT can be used as a tool to spur students’ inner feedback and aid their learning and professional skills development. The authors point out that the use of Chat GPT in teaching electrical engineering students may raise ethical issues, such as privacy and data security concerns. It is emphasized that integration of ChatGPT in the educational process should be accompanied by appropriate pedagogical strategies, human oversight, and a balanced approach to ensure its effective and responsible usage. Using the interview method, the perception of ChatGPT by electrical engineering students of Kremenchuk Mykhailo Ostrohradskyi National University has been analysed. The authors have also presented recommendations on how ChatGPT can be used during practical classes in Ukrainian Language for Specific Purposes to electrical engineering students.","Shabunina, Viktoriia and Sarancha, Viktor and Maslak, Volodymyr and Shevchenko, Olena and Tur, Oksana",,2023 IEEE 5th International Conference on Modern Electrical and Energy System (MEES),2023,10.1109/MEES61502.2023.10402380,,ieee.bib,2024-02-25 11:35:40,Unclassified
10401723,"Deepfakes, Misinformation, and Disinformation in the Era of Frontier AI, Generative AI, and Large AI Models","With the advent of sophisticated artificial intelligence (AI) technologies, the proliferation of deepfakes and the spread of m/disinformation have emerged as formidable threats to the integrity of information ecosystems worldwide. This paper provides an overview of the current literature. Within the frontier AI’s crucial application in developing defense mechanisms for detecting deepfakes, we highlight the mechanisms through which generative AI based on large models (LM-based GenAI) craft seemingly convincing yet fabricated contents. We explore the multifaceted implications of LM-based GenAI on society, politics, and individual privacy violations, underscoring the urgent need for robust defense strategies. To address these challenges, in this study, we introduce an integrated framework that combines advanced detection algorithms, cross-platform collaboration, and policy-driven initiatives to mitigate the risks associated with AI-Generated Content (AIGC). By leveraging multi-modal analysis, digital watermarking, and machine learning-based authentication techniques, we propose a defense mechanism adaptable to AI capabilities of ever-evolving nature. Furthermore, the paper advocates for a global consensus on the ethical usage of GenAI and implementing cyber-wellness educational programs to enhance public awareness and resilience against m/disinformation. Our findings suggest that a proactive and collaborative approach involving technological innovation and regulatory oversight is essential for safeguarding netizens while interacting with cyberspace against the insidious effects of deepfakes and GenAI-enabled m/disinformation campaigns.","Shoaib, Mohamed R. and Wang, Zefan and Ahvanooey, Milad Taleby and Zhao, Jun",,2023 International Conference on Computer and Applications (ICCA),2023,10.1109/ICCA59364.2023.10401723,,ieee.bib,2024-02-25 11:35:40,Unclassified
8379703,Smart IoT and Soft AI,"Soft artificial intelligence (AI) is defined as non-sentient AI designed to perform close to human level in one specific domain. This is in contrast to “Artificial General Intelligence” (AGI) which solves the problem for human level intelligence across all domains. Soft AI is a reality now in the new generation of smart Internet of Things devices like Amazon's Alexa, Apple's Siri or Microsoft's Cortana, giving rise to concerns about privacy and how the technology is being used. This research is based around an experiment in “AI as a service” where fifteen chatbot agents using Google's “Dialogflow” are deployed around the Queen Elizabeth Olympic Park in London for the general public to interact with. The physical devices are 3D printed representations of creatures living in the park, designed to fit with the park's biodiversity remit. Park visitors interact with the creatures via their mobile phones, engaging in a conversation where the creature offers to tell them a memory in exchange for one of their own, while warning them that anything they say might be repeated to others. The scope of the work presented here is as follows. After explaining the details of the deployment and three month study, the conversational data collected from visitors is then analysed. Following a review of the current literature, techniques for working with the unstructured natural language data are developed, leading to recommendations for the design of future conversational “chatbot” agents. The results show distinct patterns of conversation, from simple and direct “verb plus noun” commands to complex sentence structure. How users interact with the agents, given that they are conversing with a mechanism, is discussed and contrasted with the memories that they have agreed to share. The conclusion drawn from this work is that, while the current generation of devices only listen for commands from users, there is a danger that smart IoT devices in the future can be used as active information probes unless properly understood and regulated. We finish with observations on privacy and security based on our experiences here.","Milton, R and Hay, D and Gray, S and Buyuklieva, B and Hudson-Smith, A",,Living in the Internet of Things: Cybersecurity of the IoT - 2018,2018,10.1049/cp.2018.0016,,ieee.bib,2024-02-25 11:35:40,Unclassified
10272618,The Extent of AI Applications in EFL Learning and Teaching,"Foreign language teaching, like almost all other aspects of human existence, has been substantially influenced by recent advances in modern information and communication technologies, such as augmented reality, virtual reality, and artificial intelligence (AI). Although AI has been in use for almost 30 years, educators remain skeptical toward the use of AI-technology in the education field more broadly, and how its use might meaningfully affect English language skills. Through a systematic review, this work seeks to provide a summary of the available literature with regard to the applications of AI in English as a foreign language (EFL) education. This review considers a wide range of AI technologies and methodologies, with a specific focus on the integration of AI into the realm of EFL education. The review then delineates the possible effects of AI in terms of developing students' language skills, students' and teachers' perceptions of using AI applications, and the difficulties and challenges inherent to implementing AI applications. The discussion culminates by identifying research gaps.","Alshumaimeri, Yousif A. and Alshememry, Abdulrahman K.",IEEE Transactions on Learning Technologies,,2024,10.1109/TLT.2023.3322128,,ieee.bib,2024-02-25 11:35:40,Unclassified
8990763,Enabling IoT in Education 4.0 with BioSensors from Wearables and Artificial Intelligence,"A major challenge for Education 4.0 is to make use of wearable devices for helping students in monitoring their learning behavior and their activities (steps, heart rate variability, and heart rate) in real-time. The first aim of this paper is to present our implementation of adaptivity and Artificial Intelligence (AI) methods within the Education 4.0 process. In this work, we investigate embedded biosensors (noninvasive, low-cost, and distraction-free) used in smartphones and smartwatches. The next objective is to enable IoT for Higher Education, i.e. a novel system assisted by AI that takes embedded biosensor data and environmental data into account in order to estimate students' wellbeing and health. In this regard, we propose a framework that uses wearable devices to collect data with biofeedback methods to support students' academic success.","Ciolacu, Monica Ionita and Binder, Leon and Popp, Heribert",,2019 IEEE 25th International Symposium for Design and Technology in Electronic Packaging (SIITME),2019,10.1109/SIITME47687.2019.8990763,,ieee.bib,2024-02-25 11:35:40,Unclassified
10096983,Federated Self-Learning with Weak Supervision for Speech Recognition,"Automatic speech recognition (ASR) models with low-footprint are increasingly being deployed on edge devices for conversational agents, which enhances privacy. We study the problem of federated continual incremental learning for recurrent neural network-transducer (RNN-T) ASR models in the privacy-enhancing scheme of learning on-device, without access to ground truth human transcripts or machine transcriptions from a stronger ASR model. In particular, we study the performance of a self-learning based scheme, with a paired teacher model updated through an exponential moving average of ASR models. Further, we propose using possibly noisy weak-supervision signals such as feedback scores and natural language understanding semantics determined from user behavior across multiple turns in a session of interactions with the conversational agent. These signals are leveraged in a multitask policy-gradient training approach to improve the performance of self-learning for ASR. Finally, we show how catastrophic forgetting can be mitigated by combining on-device learning with a memory-replay approach using selected historical datasets. These innovations allow for 10% relative improvement in WER on new use cases with minimal degradation on other test sets in the absence of strong-supervision signals such as ground-truth transcriptions.","Rao, Milind and Chennupati, Gopinath and Tiwari, Gautam and Kumar Sahu, Anit and Raju, Anirudh and Rastrow, Ariya and Droppo, Jasha",,"ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",2023,10.1109/ICASSP49357.2023.10096983,,ieee.bib,2024-02-25 11:35:40,Unclassified
9961853,Deep-Learning-Based COVID-19 Detection: Challenges and Future Directions,"Coronavirus disease 2019 (COVID-19) is an ecumenical pandemic that has affected the whole world drastically by raising a global calamitous situation. Owing to this pernicious disease, millions of people have lost their lives. The scientists are still far from knowing how to tackle the coronavirus due to its multiple mutations found around the globe. The standard testing technique called polymerase chain reaction for the clinical diagnosis of COVID-19 is expensive and time consuming. However, to assist specialists and radiologists in COVID-19 detection and diagnosis, deep learning plays an important role. Many research efforts have been done that leverage deep learning techniques and technologies for the identification or categorization of COVID-19-positive patients, and these techniques are proved to be a powerful tool that can automatically detect or diagnose COVID-19 cases. In this article, we identify significant challenges regarding deep-learning-based systems and techniques that use different medical imaging modalities, including cough and breadth, chest X-ray, and computed tomography, to combat COVID-19 outbreak. We also pinpoint important research questions for each category of challenges.","Arshad, Qurat-ul-Ain and Khan, Wazir Zada and Azam, Faisal and Khan, Muhammad Khurram",IEEE Transactions on Artificial Intelligence,,2023,10.1109/TAI.2022.3224097,,ieee.bib,2024-02-25 11:35:40,Unclassified
10235949,ChatGPT Empowered Long-Step Robot Control in Various Environments: A Case Application,"This paper introduces a novel method for translating natural-language instructions into executable robot actions using OpenAI’s ChatGPT in a few-shot setting. We propose customizable input prompts for ChatGPT that can easily integrate with robot execution systems or visual recognition programs, adapt to various environments, and create multi-step task plans while mitigating the impact of token limit imposed on ChatGPT. In our approach, ChatGPT receives both instructions and textual environmental data, and outputs a task plan and an updated environment. These environmental data are reused in subsequent task planning, thus eliminating the extensive record-keeping of prior task plans within the prompts of ChatGPT. Experimental results demonstrated the effectiveness of these prompts across various domestic environments, such as manipulations in front of a shelf, a fridge, and a drawer. The conversational capability of ChatGPT allows users to adjust the output via natural-language feedback. Additionally, a quantitative evaluation using VirtualHome showed that our results are comparable to previous studies. Specifically, 36% of task planning met both executability and correctness, and the rate approached 100% after several rounds of feedback. Our experiments revealed that ChatGPT can reasonably plan tasks and estimate post-operation environments without actual experience in object manipulation. Despite the allure of ChatGPT-based task planning in robotics, a standardized methodology remains elusive, making our work a substantial contribution. These prompts can serve as customizable templates, offering practical resources for the robotics research community. Our prompts and source code are open source and publicly available at https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts.","Wake, Naoki and Kanehira, Atsushi and Sasabuchi, Kazuhiro and Takamatsu, Jun and Ikeuchi, Katsushi",IEEE Access,,2023,10.1109/ACCESS.2023.3310935,,ieee.bib,2024-02-25 11:35:40,Unclassified
9581469,"The role of Internet of Things, Blockchain, Artificial Intelligence, and Big Data Technologies in Healthcare to Prevent the Spread of the COVID-19","The spread of new coronavirus pandemic (COVID-19) has led to a major crisis in the economic and health sector, which required prompt response by medical personnel, health organizations, scientists, as well as the government sector. Globally, health care institutions have been affected greatly and unexpectedly by this COVID-19 pandemic put the current systems of healthcare under tremendous pressures, and at their maximum capabilities and resources in order to provide medical services to those infected. In this global health emergency situation and given the current limited healthcare resources, the necessity of finding quick and innovative solutions has been required. As a result, using new technologies to struggle COVID-19 and meeting the pandemic's specified requirements, such as detecting, monitoring, diagnosing, screening, surveillance, tracking, and raising awareness, has become unavoidable. The focus of this research is to understand how the healthcare system use these new technologies to fight against the pandemic. This paper provides a guideline to practitioners on the benefits and application areas of Artificial Intelligence, Internet of things, Blockchain, and Big data technologies in the healthcare industry to face the crisis caused by this pandemic. A detailed analysis of strengths, weaknesses, opportunities, and threats for the thorough implementation of these technologies has been conducted. Also, the paper addresses the obstacles to adopt these technologies in the healthcare systems and make some recommendations for future studies. The paper assists researchers, experts, and readers in recognizing how the use of technology is aiding in the management of the coronavirus infection in a synergistic manner, as well as encourage the need for these techniques in existing and potential times of emergency","Bazel, Mahmood A. and Mohammed, Fathey and Alsabaiy, Mogeeb and Abualrejal, Hussein Mohammed",,"2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)",2021,10.1109/3ICT53449.2021.9581469,,ieee.bib,2024-02-25 11:35:40,Unclassified
9117023,A Systematic Review of the Digital Interventions for Fighting COVID-19: The Bangladesh Perspective,"The objective of this paper is to synthesize the digital interventions initiatives to fight against COVID-19 in Bangladesh and compare with other countries. In order to obtain our research objective, we conducted a systematic review of the online content. We first reviewed the digital interventions that have been used to fight against COVID-19 across the globe. We then reviewed the initiatives that have been taken place in Bangladesh. Thereafter, we present a comparative analysis between the initiatives taken in Bangladesh and the other countries. Our findings show that while Bangladesh is capable to take benefits of the digital intervention approaches, tighter cooperation between government and private organizations as well as universities would be needed to get the most benefits. Furthermore, the government needs to make sure that the privacy of its citizens are protected.","Islam, Muhammad Nazrul and Islam, A. K. M. Najmul",IEEE Access,,2020,10.1109/ACCESS.2020.3002445,,ieee.bib,2024-02-25 11:35:40,Unclassified
9162435,Beyond Mobile Apps: A Survey of Technologies for Mental Well-Being,"Mental health problems are on the rise globally and strain national health systems worldwide. Mental disorders are closely associated with fear of stigma, structural barriers such as financial burden, and lack of available services and resources which often prohibit the delivery of frequent clinical advice and monitoring. Technologies for mental well-being exhibit a range of attractive properties, which facilitate the delivery of state-of-the-art clinical monitoring. This review article provides an overview of traditional techniques followed by their technological alternatives, sensing devices, behaviour changing tools, and feedback interfaces. The challenges presented by these technologies are then discussed with data collection, privacy, and battery life being some of the key issues which need to be carefully considered for the successful deployment of mental health toolkits. Finally, the opportunities this growing research area presents are discussed including the use of portable tangible interfaces combining sensing and feedback technologies. Capitalising on the data these ubiquitous devices can record, state of the art machine learning algorithms can lead to the development of robust clinical decision support tools towards diagnosis and improvement of mental well-being delivery in real-time.","Woodward, Kieran and Kanjo, Eiman and Brown, David J. and McGinnity, T. M. and Inkster, Becky and Macintyre, Donald J. and Tsanas, Athanasios",IEEE Transactions on Affective Computing,,2022,10.1109/TAFFC.2020.3015018,,ieee.bib,2024-02-25 11:35:40,Unclassified
10307203,The Exploitation of Artificial Intelligence in Developing English Language Learner's Communication Skills,"Today the world run only with the English language. To learn English there are many reputed applications for the peoples to make use of it. But most of it are paid, if it is of free then the content provided is not a satisfiable one to get the language entirely. In order to provide a useful and beneficial learning for free of cost we proposed a way with the utilization of Artificial Intelligence. A website is developed with the Artificial Intelligence to monitor the performance of the peoples who enrolled in it. Website is developed on game based for bringing interest to learn the language. There are multiple levels to be unlocked with interesting challenges and question solving. By this, peoples start to develop their English knowledge with cracking the levels. Here the Artificial Intelligence play a major role in building the question set and the level difficulty for each individual while crossing each level. This is done by analysing the marks obtained in each level. The database is stored and then fed into the Artificial Intelligence model to make evaluation of the individual performance. According the analysis made by the intelligence the level difficulty is set up. So, by this the individual stats to understand the meaning and usage of the word in each scenario. Compare to the proposed methodologies of existing website there is no such involvement of Artificial Intelligence for the analysis making and for building the levels. This era has a lot of development in the technologies with the Artificial Intelligence. Working with Artificial Intelligence make each individual to be strong and confident in their domain. This website will develop the individual to become confident person on speaking with the English language.","R D, Gomathi and S, Maheswaran and M, Mythili and S, Nandita and S, Sathesh and G, Murugesan and Duraisamy, Prakash",,2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT),2023,10.1109/ICCCNT56998.2023.10307203,,ieee.bib,2024-02-25 11:35:40,Unclassified
9995430,Psychosis iREACH: Reach for Psychosis Treatment using Artificial Intelligence,"Psychosis iREACH aims to optimize the delivery of evidence-based cognitive behavioral therapy to family caregivers who have a loved one with psychosis. It is an accessible digital platform that can utilize the user’s intent and entities to determine the appropriate response. The platform is implemented based on an artificial intelligence and natural language understanding (NLU) framework, RASA. We developed the web application of the platform, and the chatbot has been integrated into the platform to collect data and evaluate the performance. The results showed that the NLU model’s accuracy, precision, recall, and F1- score of the intent prediction are 88.31%, 89.80%, 88.22%, and 88.65% respectively. The link to the website is https://psychosisireach.uw.edu/.","Lee, Jonathan and Kopelovich, Sarah and Cheng, Sunny Chieh and Si, Dong",,2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),2022,10.1109/BIBM55620.2022.9995430,,ieee.bib,2024-02-25 11:35:40,Unclassified
9759038,How Artificial Intelligence Is Promoting Financial Inclusion? A Study On Barriers Of Financial Inclusion,"Financial inclusion has received wider attention from policymakers worldwide, as it is considered a strong pillar for human development also. Traditional financial systems of countries are not able enough to attract all segments of society. There are various barriers to the legacy system which hinder the involvement of privileged members of society in the financial sector. This study is intended to provide theoretical insights on the role of Artificial Intelligence (AI) in promoting financial inclusion. The study supports the argument by providing realtime examples of AI applications being deployed by various countries in removing barriers to financial inclusion. AI implementation for promoting financial inclusion can be made possible by supporting regulatory framework and infrastructure.","Yasir, Anam and Ahmad, Alia and Abbas, Sagheer and Inairat, Mohammad and Al-Kassem, Amer Hani and Rasool, Atta",,2022 International Conference on Business Analytics for Technology and Security (ICBATS),2022,10.1109/ICBATS54253.2022.9759038,,ieee.bib,2024-02-25 11:35:40,Unclassified
10346472,The Automated Future: How AI and Automation Are Revolutionizing Online Services,"Artificial intelligence (AI) and automation are rapidly transforming the landscape of online services. From intelligent chatbots to hyper-personalized recommendations, AI-driven technologies are enabling online providers to deliver more customized, streamlined, and human-like digital experiences. This paper examines the growing role and impacts of AI and automation across a range of online industries, products, and interactions. It analyzes key applications like natural language processing, computer vision, predictive analytics, and robotic process automation that are automating everything from customer service to supply chain logistics. The benefits of these technologies, including 24/7 availability, scalability, and cost savings, are discussed along with challenges around data privacy, transparency, and workforce impacts. The paper underscores how AI and automation will shape the future of how companies engage and serve digital consumers. As online providers continue to collect more data and refine predictive algorithms, they edge closer to delivering truly individualized services tailored to customers' ever-evolving preferences and needs. However, realizing the promise of AI will require addressing critical issues around bias, ethics, and accountability. This paper provides a comprehensive look at the current landscape and future trajectory of AI and automation in online services.","Desmal, Abdulla Jaafar and Alsaeed, Mohamed and Hamid, Suraya and Zulait, Ali Hussain",,2023 IEEE 8th International Conference on Engineering Technologies and Applied Sciences (ICETAS),2023,10.1109/ICETAS59148.2023.10346472,,ieee.bib,2024-02-25 11:35:40,Unclassified
10105236,Exploring Students’ Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey,"ChatGPT has sparked both excitement and skepticism in education. To analyze its impact on teaching and learning it is crucial to understand how students perceive ChatGPT and assess its potential and challenges. Toward this, we conducted a two-stage study with senior students in a computer engineering program ( $n=56$ ). In the first stage, we asked the students to evaluate ChatGPT using their own words after they used it to complete one learning activity. The returned responses (3136 words) were analyzed by coding and theme building (36 codes and 15 themes). In the second stage, we used the derived codes and themes to create a 27-item questionnaire. The students responded to this questionnaire three weeks later after completing other activities with the help of ChatGPT. The results show that the students admire the capabilities of ChatGPT and find it interesting, motivating, and helpful for study and work. They find it easy to use and appreciate its human-like interface that provides well-structured responses and good explanations. However, many students feel that ChatGPT’s answers are not always accurate and most of them believe that it requires good background knowledge to work with since it does not replace human intelligence. So, most students think that ChatGPT needs to be improved but are optimistic that this will happen soon. When it comes to the negative impact of ChatGPT on learning, academic integrity, jobs, and life, the students are divided. We conclude that ChatGPT can and should be used for learning. However, students should be aware of its limitations. Educators should try using ChatGPT and guide students on effective prompting techniques and how to assess generated responses. The developers should improve their models to enhance the accuracy of given answers. The study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.","Shoufan, Abdulhadi",IEEE Access,,2023,10.1109/ACCESS.2023.3268224,,ieee.bib,2024-02-25 11:35:40,Unclassified
10154472,TI-16 DNS Labeled Dataset for Detecting Botnets,"Botnets continue to evolve despite many efforts by law enforcement agencies and security researchers. As a result, there is an increase in the number of cybercrimes. This has led to a greater research focus on botnet detection. Among the reasons for growth in botnet and cybercrimes despite greater research focus are that significant number of the proposed techniques are not reproducible (unavailability of source code), do not contain a detailed description for effective comparison, and the absence of a real world labeled dataset for effective comparison. There is a grave problem of the unavailability of the labeled real-world dataset for bot infection detection. This paper aims to create a public labeled real-world Domain Name System (DNS) dataset for bot infection detection. The dataset contains real world DNS traffic of benign and malicious hosts. The dataset containing 24 features is labeled to list infected Domain Generation Algorithms (DGA) hosts along with the botnet family name and the DGA domains used for C&C communication. A total of 7644 hosts were found infected with nine different botnets namely modpack, virut, necurs, conficker, ud3, suppobox, nymain, tofsee and pitou. Finally, a machine learning classifier is developed to distinguish DGA bots from normal hosts using these features with an accuracy of 99.59%.","Singh, Manmeet and Singh, Maninder and Kaur, Sanmeet",IEEE Access,,2023,10.1109/ACCESS.2023.3287141,,ieee.bib,2024-02-25 11:35:40,Unclassified
8802706,"BotFlowMon: Learning-based, Content-Agnostic Identification of Social Bot Traffic Flows","With the fast-growing popularity of online social networks (OSN), maintaining the security of OSN ecosystems becomes essential for the public. Among all the security threats facing OSN, malicious social bots have become the most common and detrimental. These bot programs are often employed to violate users' privacy, distribute spam, and disturb the financial market, posing a compelling need for effective social bot detection solutions. Unlike traditional bot detection approaches that have strict requirements on data sources (e.g., private payload information, social relationships, or activity histories), this paper proposes a detection method called BotFlowMon that relies only on NetFlow data as input to identify OSN bot traffic, where every NetFlow record is a summary of a traffic flow on the Internet and contains no payload content. BotFlowMon introduces several new algorithms and techniques to help use machine learning to classify the social bot traffic from the real OSN user traffic, including aggregating NetFlow records to obtain transaction data, fusing transaction data to extract features and visualize flows, as well as subdividing transactions into basic actions. Our evaluation shows that with 535GB raw NetFlow records as input, BotFlowMon can efficiently classify the traffic from social bots, including chatbot, amplification bot, post bot, crawler bot, and hybrid bot, with 92.33-93.61 % accuracy.","Feng, Yebo and Li, Jun and Jiao, Lei and Wu, Xintao",,2019 IEEE Conference on Communications and Network Security (CNS),2019,10.1109/CNS.2019.8802706,,ieee.bib,2024-02-25 11:35:40,Unclassified
10265976,"Artificial Intelligence Enhanced Content Management Systems: Integration, Considerations, and Useful Examples","This research study analyzes how content management systems (CMS) can incorporate artificial intelligence (AI). At the outset, the idea of a CMS and its significance in managing digital material are introduced. The research paper goes on to discuss various methods for incorporating AI into CMS, such as content recommendations, natural language processing, image and video analysis, chatbots and virtual assistants, content generation and optimization, data analytics and insights, intelligent search and tagging, and content moderation. The following important considerations must be made when integrating AI into CMS: defining objectives, data accessibility, data privacy and security, AI expertise, scalability and performance, user experience, ethical considerations, testing and assessment, maintenance, and upgrades. The suggested method offers real-world examples, such integrating AI services or creating unique AI modules for well-known CMS choices like Strapi. In order to achieve a successful integration that improves user experiences and content management procedures, the essay emphasizes the significance of careful planning, moral implementation, and continuing maintenance.","Yadav, Ayush.R. and Yadav, Snehal. S. and Kamoji, Supriya",,2023 3rd International Conference on Pervasive Computing and Social Networking (ICPCSN),2023,10.1109/ICPCSN58827.2023.00053,,ieee.bib,2024-02-25 11:35:40,Unclassified
9422858,Anonymous Communication Strategy in Telegram: Toward Comparative Analysis of Russia and Belarus,"This paper aims to study anonymous communication strategy in the Telegram. Telegram is a new cloud-messenger that is highly popular among bloggers and media in Russia and Belarus. Established by Pavel Durov in 2013, it offers secure and anonymous communication features. Anonymous communication has been studied by many scholars (Choudhury, Sharon, Watt, Zhang, etc), but it seems that more questions are left unanswered. This paper starts distinguishing anonymity from related notions of confidentiality and secrecy, privacy, and publicity. We provide some vocabulary to talk about anonymization and identification efforts by message sources and receivers. The paper highlights some of the limitations of current communication scholarship in this area such as anonymous communication strategy. The growing role of the Telegram messenger in the mass communications systems of Russia and Belarus indicates new opportunities for anonymous communication strategy in the digital society. The research methodology is based on a comparative analysis of statistical data on the audience of the leading Telegram news channels. The authors argue that the anonymous communication strategy has taken an important share of the market in both countries. In a comparative aspect, the indicators of the involvement of Telegram channels were analyzed. The main results of the study show that the use of various Telegram features both as a messenger and as a full-fledged media is constantly increasing. The intensity of the use of the messenger has increased and the variety of functions it performs has also increased. It has been established that the Telegram platform contributes to strengthening feedback from the audience. Chatbots have become a new opportunity to receive information from readers. The authors conclude that alternative Telegram channels play an important role in the digital environment.","Bykov, Ilya A. and Medvedeva, Mariia V. and Hradziushka, Aleksandr A.",,2021 Communication Strategies in Digital Society Seminar (ComSDS),2021,10.1109/ComSDS52473.2021.9422858,,ieee.bib,2024-02-25 11:35:40,Unclassified
10182715,Text Analytics in Modern Healthcare using NLP,"The healthcare industry is facing a major shift in how patient care is administered. Data-driven decisions are becoming increasingly important to reduce costs and improve patient outcomes. Text analytics is one of the tools being used to help make sense of unstructured data, such as medical notes and records. This paper provides an overview of sources of health data, current work that employs text analytics and the challenges of text analytics. Text analytics has the potential to revolutionize the way healthcare is administered. It can provide a better understanding of patient health, yield more accurate diagnoses and treatments, and ultimately, improve patient results. The use of text analytics can also improve the accuracy of patient records for data-driven decisions and reduce costs. However, there are many challenges associated with the implementation of text analytics in healthcare. These include issues related to data privacy, accuracy, and data collection. The implications of using text analytics in modern healthcare are far-reaching. With the right implementation and data-driven decisions, the healthcare industry can improve the treatment experience and reduce costs. Text analytics has the potential to provide meaningful insights into patient health, yield more accurate diagnoses and treatments, and ultimately revolutionize the way healthcare is delivered.","Kaur, Kawaljit and Suman, Suman and Jaswal, Reeti",,2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),2023,10.1109/ICACITE57410.2023.10182715,,ieee.bib,2024-02-25 11:35:40,Unclassified
10151849,SHAP Interpretations of Tree and Neural Network DNS Classifiers for Analyzing DGA Family Characteristics,"Domain Generation Algorithms (DGA’s) have been employed by botnet orchestrators for controlling infected hosts (bots), while evading detection by performing multiple DNS requests, mostly for non-existing domain names. With blacklists ineffective, modern DGA filtering methods rely on Machine Learning (ML). Emerging needs for higher intrusion detection accuracy lead to complex, non-interpretable black-box classifiers, thus requiring eXplainable Artificial Intelligence (XAI) techniques. In this paper, we utilize SHapley Additive exPlanation (SHAP) to derive model-agnostic, post-hoc interpretations on DGA name classifiers. This method is applied to binary supervised tree-based classifiers (e.g. eXtreme Gradient Boosting - XGBoost) and deep neural networks (Multi-Layer Perceptron - MLP) to assess domain name feature importance. SHAP visualization tools (summary, dependence, force plots) are used to rank features, investigate their effect on model decisions and determine their interactions. Specific interpretations are detailed for identifying names belonging to common DGA families pertaining to arithmetic, wordlist, hash and permutation based schemes. Learning and interpretations are based on up-to-date datasets, such as Tranco for benign and DGArchive for malicious names. Domain name features are extracted from dataset instances, thus limiting time-consuming and privacy-invasive database operations on historical data. Our experimental results demonstrate that SHAP enables explanations of XGBoost (the most accurate tree-based model) and MLP classifiers and indicates the characteristics of specific DGA schemes, commonly employed in attacks. In conclusion, we envision that XAI methods will expedite ML deployment in networking environments where justifications for black-box models are required.","Kostopoulos, Nikos and Kalogeras, Dimitris and Pantazatos, Dimitris and Grammatikou, Maria and Maglaris, Vasilis",IEEE Access,,2023,10.1109/ACCESS.2023.3286313,,ieee.bib,2024-02-25 11:35:40,Unclassified
10245676,Impact of AI on Social Marketing and its Usage in Social Media: A Review Analysis,"The primary goal of the paper is to examine the applications and integration of artificial intelligence (AI) in the realm of social media. AI has greatly influenced how organizations approach their marketing efforts on social platforms. By analyzing large volumes of data and making predictions, AI enables companies to target their advertising and content more effectively towards specific audiences. This utilization of AI in social media allows businesses to understand consumers' perspectives, emotions, and reactions to brands and products, ultimately reaching a larger number of people. Moreover, the adoption of AI has improved companies' efficiency, logistical networks, reduced expenses, and increased revenues by 10%. Additionally, AI plays a crucial role in safeguarding user data privacy and contributes to the profitability of businesses utilizing social media marketing with AI. Nevertheless, while AI simplifies various tasks in the social media domain, relying solely on AI for these functions may not be advisable. Hence, this study suggests thoroughly examining the implications of AI in digital marketing and social media advertising, covering all aspects. One key area where AI has a significant impact is personalization. By analyzing customer data, AI algorithms can identify patterns and preferences, allowing marketers to customize their messaging to specific target audiences. This leads to higher engagement rates and more successful social media campaigns. However, the increasing use of successfully showcase by distinguishing designs and trends. AI chatbots can moreover be utilized for client bolster and social engagement, whereas AI-generated substance can be custom-made to particular audiences for social media creation and detailing. In spite of the benefits of AI within the promoting industry, there are concerns almost security, security and straightforwardness. Pundits say the utilize of AI in social media can lead to “bubbles” in which clients display data that as it were underpins their convictions and opinions. The reason of this audit is to look at the affect of commerce insights in trade and its applications within the media, centering on the strengths and impediments of past investigate in this region. Particularly, we are going investigate the current applications of AI within the publicizing industry and the dangers and benefits related with the technology.We have moreover looked into existing investigate on this subject, highlighting the most discoveries and impedimentsof past considers. At last, based on the investigation of the current circumstance, we make suggestions for assist inquire about in this range. Fake insights (AI) incorporates the improvement of brilliantly computers that can perform errands already saved for people (Smith, 2018), [1]. Its fundamental reason is to utilize machines to perform errands that require considering, perception, examination, choice making and basic artificial intelligence in the business sector also raises ethical questions. There is a risk that AI algorithms may promote or create biases that can lead to discrimination or exclusion of certain groups.","Milan, Ankush and Sahu, Rakesh and Sandhu, Jasminder Kaur",,2023 International Conference on Circuit Power and Computing Technologies (ICCPCT),2023,10.1109/ICCPCT58313.2023.10245676,,ieee.bib,2024-02-25 11:35:40,Unclassified
Macdonald2023,Can ChatGPT draft a research article? An example of population-level vaccine effectiveness analysis,"We reflect on our experiences of using Generative Pre-trained Transformer ChatGPT, a chatbot launched by OpenAI in November 2022, to draft a research article. We aim to demonstrate how ChatGPT could help researchers to accelerate drafting their papers. We created a simulated data set of 100 000 health care workers with varying ages, Body Mass Index (BMI), and risk profiles. Simulation data allow analysts to test statistical analysis techniques, such as machine-learning based approaches, without compromising patient privacy. Infections were simulated with a randomized probability of hospitalisation. A subset of these fictitious people was vaccinated with a fictional vaccine that reduced this probability of hospitalisation after infection. We then used ChatGPT to help us decide how to handle the simulated data in order to determine vaccine effectiveness and draft a related research paper. AI-based language models in data analysis and scientific writing are an area of growing interest, and this exemplar analysis aims to contribute to the understanding of how ChatGPT can be used to facilitate these tasks © 2023 THE AUTHOR(S)","Macdonald, Calum and Adeloye, Davies and Sheikh, Aziz and Rudan, Igor",Journal of Global Health,,2023,10.7189/JOGH.13.01003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148258728&doi=10.7189%2fJOGH.13.01003&partnerID=40&md5=c23fae3c463e3087a61de2c24bde1f93,scopus.bib,2024-02-25 11:35:41,Unclassified
Foosherian202356,Enhancing Pipeline-Based Conversational Agents with Large Language Models,"The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT- 4. However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation. This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations. In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design. In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities. We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example. Companies may be hesitant to replace their pipeline-based agents with LLMs entirely due to privacy concerns and the need for deep integration within their existing ecosystems. A hybrid approach in which LLMs' are integrated into the pipeline-based agents allows them to save time and costs of building and running agents by capitalizing on the capabilities of LLMs while retaining the integration and privacy safeguards of their existing systems.  © 2023 Association for Computational Linguistics.","Foosherian, Mina and Purwins, Hendrik and Rathnayake, Purna and Alam, Touhidul and Teimao, Rui and Thoben, Klaus-Dieter","Proceedings of the 1st Workshop on Taming Large Language Models: Controllability in the Era of Interactive Assistants!, TLLM 2023",,2023,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180830503&partnerID=40&md5=4d9348d8aef9d698b88b98f659f035c3,scopus.bib,2024-02-25 11:35:41,Unclassified
Zheng2022,UX Research on Conversational Human-AI Interaction: A Literature Review of the ACM Digital Library,"Early conversational agents (CAs) focused on dyadic human-AI interaction between humans and the CAs, followed by the increasing popularity of polyadic human-AI interaction, in which CAs are designed to mediate human-human interactions. CAs for polyadic interactions are unique because they encompass hybrid social interactions, i.e., human-CA, human-to-human, and human-to-group behaviors. However, research on polyadic CAs is scattered across different fields, making it challenging to identify, compare, and accumulate existing knowledge. To promote the future design of CA systems, we conducted a literature review of ACM publications and identified a set of works that conducted UX (user experience) research. We qualitatively synthesized the effects of polyadic CAs into four aspects of human-human interactions, i.e., communication, engagement, connection, and relationship maintenance. Through a mixed-method analysis of the selected polyadic and dyadic CA studies, we developed a suite of evaluation measurements on the effects. Our findings show that designing with social boundaries, such as privacy, disclosure, and identification, is crucial for ethical polyadic CAs. Future research should also advance usability testing methods and trust-building guidelines for conversational AI. © 2022 ACM.","Zheng, Qingxiao and Tang, Yiliu and Liu, Yiren and Liu, Weizi and Huang, Yun",Conference on Human Factors in Computing Systems - Proceedings,,2022,10.1145/3491102.3501855,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130572358&doi=10.1145%2f3491102.3501855&partnerID=40&md5=eb84b38295ceed7d799a491b95120418,scopus.bib,2024-02-25 11:35:41,Unclassified
Contu2021,AI-based analysis of policies and images for privacy-conscious content sharing,"Thanks to the popularity of personal mobile devices, more and more of the different types of private content, such as images and videos, are shared on social networking applications. While content sharing may be an effective practice to enhance social relationships, it is also a source of relevant privacy issues. Unfortunately, users find it difficult to understanding the terms and implications of the privacy policies of apps and services. Moreover, taking privacy decisions about content sharing on social networks is cumbersome and prone to errors that could determine privacy leaks. In this paper, we propose two techniques aimed at supporting the user in taking privacy choices about sharing personal content online. Our techniques are based on machine learning and natural language processing to analyze privacy policies, and on computer vision to assist the user in the privacy-conscious sharing of multimedia content. Experiments with real-world data show the potential of our solutions. We also present ongoing work on a system prototype and chatbot for natural language user assistance. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Contu, Francesco and Demontis, Andrea and Dessì, Stefano and Muscas, Marco and Riboni, Daniele",Future Internet,,2021,10.3390/fi13060139,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116072033&doi=10.3390%2ffi13060139&partnerID=40&md5=06e9aaa53bdcb0c5edb534c03cb114c2,scopus.bib,2024-02-25 11:35:41,Unclassified
May2024123,Conversational Agents in Healthcare: A Variability Perspective,"Conversational agents in healthcare are gaining popularity, for example, in the context of eliciting medical histories. Furthermore, due to the growing diversity of use cases and stakeholders, they are becoming increasingly configurable and are often based on variability mechanisms. In this paper, we present a high-level perspective on typical variability aspects and describe common challenges based on our research and practical experience in developing and evaluating conversational agents in the healthcare domain. We introduce variability aspects that are classified into technology-related (e.g., intelligence framework, input/output mode) and user-related aspects (e.g., careflow integration, health literacy). Moreover, these aspects are described in a case study on the Digital Medical Interview Assistant (DMIA) for radiology. We highlight main challenges that arise in the context of evolution, verification, input processing, privacy and security compliance, as well as ethical considerations. Our findings are intended to help developers, researchers, and healthcare professionals understand the importance and impact of configurability and to spur further discussions on variability aspects of conversational agents.  © 2024 ACM.","May, Richard and Denecke, Kerstin",ACM International Conference Proceeding Series,,2024,10.1145/3634713.3634717,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184279614&doi=10.1145%2f3634713.3634717&partnerID=40&md5=fda32355b30697cdab050af19b545d32,scopus.bib,2024-02-25 11:35:41,Unclassified
Augusma2023750,Multimodal Group Emotion Recognition In-the-wild Using Privacy-Compliant Features,"This paper explores privacy-compliant group-level emotion recognition ""in-the-wild""within the EmotiW Challenge 2023. Group-level emotion recognition can be useful in many fields including social robotics, conversational agents, e-coaching and learning analytics. This research imposes itself using only global features avoiding individual ones, i.e. all features that can be used to identify or track people in videos (facial landmarks, body poses, audio diarization, etc.). The proposed multimodal model is composed of a video and an audio branches with a cross-attention between modalities. The video branch is based on a fine-tuned ViT architecture. The audio branch extracts Mel-spectrograms and feed them through CNN blocks into a transformer encoder. Our training paradigm includes a generated synthetic dataset to increase the sensitivity of our model on facial expression within the image in a data-driven way. The extensive experiments show the significance of our methodology. Our privacy-compliant proposal performs fairly on the EmotiW challenge, with 79.24% and 75.13% of accuracy respectively on validation and test set for the best models. Noticeably, our findings highlight that it is possible to reach this accuracy level with privacy-compliant features using only 5 frames uniformly distributed on the video.  © 2023 ACM.","Augusma, Anderson and Vaufreydaz, Dominique and Letué, Frédérique",ACM International Conference Proceeding Series,,2023,10.1145/3577190.3616546,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175837394&doi=10.1145%2f3577190.3616546&partnerID=40&md5=ff0997c06e2749420cc3465ddf1433ea,scopus.bib,2024-02-25 11:35:41,Unclassified
Pedrosa2021391,Risk Assessment of Non-Compliance with General Data Protection Law (LGPD): A Necessary Adjustment for Healthcare Companies That Use Chatbots For Automated Care,"With the publication of the General Data Protection Law-(LGPD) many companies having their headquarters in Brazil need to work on adapting their processes. Most companies are seeking for compliance, however, many still do not know how to proceed. The risk of legal and financial issues related to non-compliance is high. This study reviews the current percentage of companies that use a Chatbot service and are compliant with the LGPD. It also reviews the steps to adjust the Chatbot service used by companies in the European Union to be compliant with the General Data Protection Regulation-(GDPR). As a methodological approach, a search in the state-of-the-art literature was conducted to identify the most recent published related content. A survey was conducted with several companies based in the Rio de Janeiro city which use a Chatbot service and are compliant with the LGPD. As a result, a flowchart showing the steps for adapting a Chatbot service to the LGPD is presented. The risks of non-compliance are also presented. This study addresses a gap observed in the literature since no specific previous work has been found covering this topic. Many companies may benefit from this study by knowing the steps to adapt their Chatbot service to the LGPD requirements, and avoid the risks associated to non-compliance. © ESREL 2021. Published by Research Publishing, Singapore.","Pedrosa, Antonio de Paula and Pereira, José Cristiano and Póvoas, Marcelo and Marinato, Davi da Fonseca Vieira Junior and Bastos, Matheus Bastos de Almeida and da Costa, Jose Luís Corrêa","Proceedings of the 31st European Safety and Reliability Conference, ESREL 2021",,2021,10.3850/978-981-18-2016-8_221-cd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135490917&doi=10.3850%2f978-981-18-2016-8_221-cd&partnerID=40&md5=ae977d496e9998d9241751a3bec23d81,scopus.bib,2024-02-25 11:35:41,Unclassified
Følstad20212915,Future directions for chatbot research: an interdisciplinary research agenda,"Chatbots are increasingly becoming important gateways to digital services and information—taken up within domains such as customer service, health, education, and work support. However, there is only limited knowledge concerning the impact of chatbots at the individual, group, and societal level. Furthermore, a number of challenges remain to be resolved before the potential of chatbots can be fully realized. In response, chatbots have emerged as a substantial research area in recent years. To help advance knowledge in this emerging research area, we propose a research agenda in the form of future directions and challenges to be addressed by chatbot research. This proposal consolidates years of discussions at the CONVERSATIONS workshop series on chatbot research. Following a deliberative research analysis process among the workshop participants, we explore future directions within six topics of interest: (a) users and implications, (b) user experience and design, (c) frameworks and platforms, (d) chatbots for collaboration, (e) democratizing chatbots, and (f) ethics and privacy. For each of these topics, we provide a brief overview of the state of the art, discuss key research challenges, and suggest promising directions for future research. The six topics are detailed with a 5-year perspective in mind and are to be considered items of an interdisciplinary research agenda produced collaboratively by avid researchers in the field. © 2021, The Author(s).","Følstad, Asbjørn and Araujo, Theo and Law, Effie Lai-Chong and Brandtzaeg, Petter Bae and Papadopoulos, Symeon and Reis, Lea and Baez, Marcos and Laban, Guy and McAllister, Patrick and Ischen, Carolin and Wald, Rebecca and Catania, Fabio and Meyer von Wolff, Raphael and Hobert, Sebastian and Luger, Ewa",Computing,,2021,10.1007/s00607-021-01016-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117326888&doi=10.1007%2fs00607-021-01016-7&partnerID=40&md5=ad4cf045204dac3a2701bf5e852b01be,scopus.bib,2024-02-25 11:35:41,Unclassified
Abdulquadri2021258,Digital transformation in financial services provision: a Nigerian perspective to the adoption of chatbot,"Purpose: Recognising the high numbers of unbanked and financially excluded adults in Nigeria, this study aims to position chatbot as a digital transformation tool to radically change business model, improve customer experience and enhance financial inclusion in emerging markets. Design/methodology/approach: The Search-Access-Test (S-A-T) model was adopted to understand how Nigerian banks are adopting chatbots. Findings: A majority of Nigerian banks now have chatbots that enhance customer engagement and financial inclusion. WhatsApp was the most frequently used platform. Chatbots were often branded and presented with female gender identification. The chatbots were less responsive beyond their predefined path. While Nigeria is a multilingual country with English being the original language, none of the chatbots used any of the Nigerian’s local languages. Practical implications: Brands need to re-evaluate their chatbots with regard to responsiveness, predefined questions, verification and privacy. There are also possibilities of branding the chatbot and developing content creation strategies for proper engagement. Beyond English, the integration of African languages into chatbot is essential for digital transformation. Digital literacy and skills, particularly in the field of science, technology, engineering and mathematics, should be supported to equip future developers and create more jobs. Originality/value: While many theoretically based models for investigating the adoption of digital technologies have often placed focus on users’ ability to engage, this study takes an alternative perspective; by using the S-A-T model, it lays the responsibilities on the banks and chatbot developer to ensure that their chatbots are secure, responsive and able to meet the needs of the customers. © 2021, Emerald Publishing Limited.","Abdulquadri, Abdulazeez and Mogaji, Emmanuel and Kieu, Tai Anh and Nguyen, Nguyen Phong",Journal of Enterprising Communities,,2021,10.1108/JEC-06-2020-0126,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101505207&doi=10.1108%2fJEC-06-2020-0126&partnerID=40&md5=016d3b8dd34e7ccbd5c814db173caf13,scopus.bib,2024-02-25 11:35:41,Unclassified
Galatzer-Levy2023228,Can Mental Health Care Become More Human by Becoming More Digital?,"Over the past two decades, advances in digital technologies have begun to transform three aspects of mental health care. The use of sensors and artificial intelligence (AI) have provided new, objective measures of how we think, feel, and behave. The ease of connecting and communicating remotely has transformed the brick-and-mortar practice of mental health care into a telehealth service, increasing access and convenience for both patients and providers. And the advent of digital therapeutics, from virtual reality for treating phobias to conversational agents for delivering structured therapies, promises to alter how treatments will be delivered in the future. These digital transformations can help to solve many of the key challenges facing mental health care, including access, quality, and accountability. But digital technology introduces a new set of challenges around trust, privacy, and equity. Despite high levels of investment and promotion, there remain profound questions about efficacy and safety of digital mental health technologies. We share our experiences from the front lines creating digital innovations for mental health, with a focus on what a digital transformation of care could deliver for millions with a serious mental illness. © 2023 by Isaac R. Galatzer-Levy, Gabriel J. Aranovich & Thomas R. Insel.","Galatzer-Levy, Isaac R. and Aranovich, Gabriel J. and Insel, Thomas R.",Daedalus,,2023,10.1162/daed_a_02040,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177866983&doi=10.1162%2fdaed_a_02040&partnerID=40&md5=0419313127c1469c872c4f5ed531d115,scopus.bib,2024-02-25 11:35:41,Unclassified
Sun2023,VCAs as partners or servants? The effects of information sensitivity and anthropomorphism roles on privacy concerns,"Advances in machine learning and natural language processing have driven the growing popularity of virtual conversational agents (VCAs). This anthropomorphic communication approach relies on user information sharing and real-time feedback from VCAs, and has raised privacy concerns while affecting various social interactions and relationships. Previous research on reducing user privacy concerns has mainly focused on user information mining, sensitive user information requests and privacy policies, while little is known about the anthropomorphic roles of partners and servants at the human-machine social hierarchy level. Therefore, this study, based on human-computer interaction (service) anthropomorphism at social level, develops a framework to investigate the impact of information sensitivity and VCAs' anthropomorphic roles, including partner and servant, on users' privacy concerns, as well as the mediating effects of competence- and integrity-based trust. The results show that when highly sensitive information is requested, user privacy concerns are greater for a partner VCA than a servant VCA, and vice-versa. Meanwhile, when a VCA requests highly sensitive information, integrity-based trust mediates the relationship between servant VCAs and privacy concerns, and when a VCA requests low-sensitivity information, competence-based trust mediates the same relationship. These insights provide actionable implications for managers. © 2023 Elsevier Inc.","Sun, Zhuo and Zang, Guoquan and Wang, ZongShui and Zhao, Hong and Liu, Wei",Technological Forecasting and Social Change,,2023,10.1016/j.techfore.2023.122560,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152229604&doi=10.1016%2fj.techfore.2023.122560&partnerID=40&md5=c63fd49e6c829e7d3387a2d514634c80,scopus.bib,2024-02-25 11:35:41,Unclassified
Toache202385,"ETHICAL CONCERNS IN THE USE OF ARTIFICIAL INTELLIGENCE, TRANSPARENCY, AND THE RIGHT OF ACCESS TO INFORMATION. THE CASE OF CHATBOTS IN THE MEXICAN GOVERNMENT, IN THE CONTEXT OF COVID-19; [PREOCUPACIONES ÉTICAS EN EL USO DE INTELIGENCIA ARTIFICIAL, TRANSPARENCIA Y DERECHO DE ACCESO A LA INFORMACIÓN. EL CASO DE LOS CHATBOTS EN EL GOBIERNO DE MÉXICO, EN EL CONTEXTO DE LA COVID-19]","The use of artificial intelligence in governments has increased in the last decade in several countries, acquiring greater importance in the context of the COVID-19 pandemic. Chatbots are one of the main tools that work based on artificial intelligence and have been used by governments to provide information and ser-vices to citizens, as well as for the follow-up, monitoring, and control of COVID-19. The use of these tools has generated ethical debates on the use of personal data, privacy, transparency, accountability, and the right of access to information. The objective of this work is to identify and analyze the main ethical concerns that emerge around the chatbots implemented in the mexican government in the context of COVID-19; the cases of Susana Distancia and Dr. Armando Vaccuno are analyzed. The methodology consists of an open survey of citizen perception. The results show that the main ethical concerns are transparency, accountability, and privacy, which have generated a lack of trust on the part of citizens towards chatbots, that have resulted in a low level of use. To remedy this, it is necessary to eliminate the regulatory gaps around transparency and data protection involved in these modern technologies. © 2023, Universidad Nacional Autonoma de Mexico. All rights reserved.","Toache, Eugenio Arguelles and Rosales, Marcela Amaro",Revista de Estudios en Derecho a la Informacion,,2023,10.22201/iij.25940082e.2023.15.17472,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183169288&doi=10.22201%2fiij.25940082e.2023.15.17472&partnerID=40&md5=36129b3ca94ec379f3a2c46392e56722,scopus.bib,2024-02-25 11:35:41,Unclassified
Adetayo2023,Revitalizing reference services and fostering information literacy: Google Bard’s dynamic role in contemporary libraries,"Purpose: This paper aims to explore the transformative potential of Google Bard, an artificial intelligence (AI)-powered chatbot, in reshaping contemporary library reference services and advancing information literacy. Design/methodology/approach: In this perspective piece, a qualitative research approach is used to explore the capabilities of Google Bard within library contexts. Real-world case studies and insights are used to critically examine Bard’s evolving role as a virtual assistant, its impact on enhancing information literacy and the multifaceted challenges it introduces, including biases and privacy concerns. Findings: The research reveals that Google Bard, leveraging natural language processing and machine learning, engages users in dynamic conversational interactions. It provides contextually relevant responses and personalized guidance, leading to an enriched library experience. The symbiotic relationship between AI-driven technology and traditional librarian expertise is highlighted, contributing to interactive knowledge exploration and collaborative learning. Originality/value: This study contributes to the literature by exploring the multifaceted impact of Google Bard on library services and information literacy. It uncovers novel insights into the integration of AI-powered chatbots in traditional library settings. © 2023, Emerald Publishing Limited.","Adetayo, Adebowale Jeremy and Oyeniyi, Wosilat Omolara",Library Hi Tech News,,2023,10.1108/LHTN-08-2023-0137,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168317354&doi=10.1108%2fLHTN-08-2023-0137&partnerID=40&md5=849b1b0d0b73a5e15d121b5f8d8708e8,scopus.bib,2024-02-25 11:35:41,Unclassified
Fan2022967,How AI chatbots have reshaped the frontline interface in China: examining the role of sales–service ambidexterity and the personalization–privacy paradox,"Purpose: This study serves two purposes: (1) to evaluate the effects of organizational ambidexterity by examining how the balanced and the combined sales–service configurations of chatbots differ in their abilities to enhance customer experience and patronage and (2) to apply information boundary theory to assess the contingent role that chatbot sales–service ambidexterity can play in adapting to customers' personalization–privacy paradox. Design/methodology/approach: An online survey of artificial intelligence chatbots users was conducted, and a mixed-methods research design involving response surface analysis and polynomial regression was adopted to address the research aim. Findings: The results of polynomial regressions on survey data from 507 online customers indicated that as the benefits of personalization decreased and the risk to privacy increased, the inherently negative (positive) effects of imbalanced (combined) chatbots' sales–service ambidexterity had an increasing (decreasing) influence on customer experience. Furthermore, customer experience fully mediated the association of chatbots' sales–service ambidexterity with customer patronage. Originality/value: First, this study enriches the literature on frontline ambidexterity and extends it to the setting of human–machine interaction. Second, the study contributes to the literature on the personalization–privacy paradox by demonstrating the importance of frontline ambidexterity for adapting to customer concerns. Third, the study examines the conduit between artificial intelligence (AI) chatbots' ambidexterity and sales performance, thereby helping to reconcile the previously inconsistent evidence regarding this relationship. © 2022, Emerald Publishing Limited.","Fan, Hua and Han, Bing and Gao, Wei and Li, Wenqian",International Journal of Emerging Markets,,2022,10.1108/IJOEM-04-2021-0532,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122748717&doi=10.1108%2fIJOEM-04-2021-0532&partnerID=40&md5=f85c4217a247f7d015bb796bd7009586,scopus.bib,2024-02-25 11:35:41,Unclassified
Kronemann20232,"How AI encourages consumers to share their secrets? The role of anthropomorphism, personalisation, and privacy concerns and avenues for future research","Purpose: This paper aims to explore the overall research question “How can artificial intelligence (AI) influence consumer information disclosure?”. It considers how anthropomorphism of AI, personalisation and privacy concerns influence consumers’ attitudes and encourage disclosure of their private information. Design/methodology/approach: This research draws upon the personalisation-privacy paradox (PPP) and privacy calculus theory (PCT) to address the research question and examine how AI can influence consumer information disclosure. It is proposed that anthropomorphism of AI and personalisation positively influence consumer attitudes and intentions to disclose personal information to a digital assistant, while privacy concerns negatively affect attitude and information disclosure. Findings: This paper develops a conceptual model based on and presents seven research propositions (RPs) for future research. Originality/value: Building upon PPP and PCT, this paper presents a view on the benefits and drawbacks of AI from a consumer perspective. This paper contributes to literature by critically reflecting upon on the question how consumer information disclosure is influenced by AI. In addition, seven RPs and future research areas are outlined in relation to privacy and consumer information disclosure in relation to AI. © 2022, Bianca Kronemann, Hatice Kizgin, Nripendra Rana and Yogesh K. Dwivedi.","Kronemann, Bianca and Kizgin, Hatice and Rana, Nripendra and K. Dwivedi, Yogesh",Spanish Journal of Marketing - ESIC,,2023,10.1108/SJME-10-2022-0213,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146279636&doi=10.1108%2fSJME-10-2022-0213&partnerID=40&md5=87514f4c8e81c76e1b831a607d0ef16a,scopus.bib,2024-02-25 11:35:41,Unclassified
Wang2023339,Artificial intelligence changes the way we work: A close look at innovating with chatbots,"An enhanced understanding of the innovative use of artificial intelligence (AI) is essential for organizations to improve work design and daily business operations. This study's purpose is to offer insights into how AI can transform organizations' work practices through diving deeply into its innovative use in the context of a primary AI tool, a chatbot, and examining the antecedents of innovative use by conceptualizing employee trust as a multidimensional construct and exploring employees' perceived benefits. In particular, we have conceptualized employee trust in chatbots as a second-order construct, including three first-order variables: trust in functionality, trust in reliability, and trust in data protection. We collected data from 202 employees. The results supported our conceptualization of trust in chatbots and showed that three dimensions of first-order trust beliefs have relatively the same level of importance. Further, both knowledge support and work–life balance enhance trust in chatbots, which in turn leads to innovative use of chatbots. Our study contributes to the existing literature by introducing the new conceptualization of trust in chatbots and examining its antecedents and outcomes. The results can provide important practical insights regarding how to support innovative use of chatbots as the new way we organize work. © 2022 Association for Information Science and Technology.","Wang, Xuequn and Lin, Xiaolin and Shao, Bin",Journal of the Association for Information Science and Technology,,2023,10.1002/asi.24621,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123950868&doi=10.1002%2fasi.24621&partnerID=40&md5=a8a26a3a9d8e2353efd50bdb7b8c3d0b,scopus.bib,2024-02-25 11:35:41,Unclassified
Vervier2023213,Perception of Privacy and Willingness to Share Personal Data in the Smart Factory,"By optimising data-driven processes and improving automation, the digital transformation in production aims to increase effectiveness, efficiency and improve the working conditions of employees. In such a networked working environment, the performance and actions of workers need to be captured in form of digital data. However, the collection of personal data is a sensitive issue. More research, not only from a techno-centric but also from a human-centric perspective, is needed. Using a multi-method approach, this study examines the motives, barriers and acceptance of technologies that use personal data in a production context. A qualitative pre-study (n= 7 ) identified motives (e.g. data offering personal benefit) and barriers (e.g. privacy concerns) of personal data disclosure. In the subsequent quantitative main study (n= 152 ), these key elements were operationalised in a scenario-based online survey, and two different working scenarios – cobot and chatbot – were additionally assessed using the Technology Acceptance Model (TAM and UTAUT2). The results show: The more fun it is to use and the higher the expected performance, the higher the acceptance of technology using personal data. Trust in automation followed by expected effort were important. Views on the disclosure of personal data and the expected benefit to the organisation varied widely. Out of seven categories, work-related and demographic data were considered to be disclosable, while five categories were considered important to the organisation. The article concludes with actionable recommendations on how the collection and use of personal data can be well aligned with stakeholder interests. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Vervier, Luisa and Brauner, Philipp and Ziefle, Martina",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2023,10.1007/978-3-031-35822-7_15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171420795&doi=10.1007%2f978-3-031-35822-7_15&partnerID=40&md5=5461603947048cddf4ccdf4866f2b0f3,scopus.bib,2024-02-25 11:35:41,Unclassified
Limna202364,The use of ChatGPT in the digital era: Perspectives on chatbot implementation,"The rapid advancement of technology has led to the integration of ChatGPT, an artificial intelligence (AI)-powered chatbot, in various sectors, including education. This research aims to explore the perceptions of educators and students on the use of ChatGPT in education during the digital era. This study adopted a qualitative research approach, using in-depth interviews to gather data. A purposive sampling technique was used to select ten educators and 15 students from different academic institutions in Krabi, Thailand. The data collected was analysed using content analysis and NVivo. The findings revealed that educators and students generally have a positive perception of using ChatGPT in education. The chatbot was perceived to be a helpful tool for providing immediate feedback, answering questions, and providing support to students. Educators noted that ChatGPT could reduce their workload by answering routine questions and enabling them to focus on higher-order tasks. However, the findings also showed some concerns regarding the use of ChatGPT in education. Participants were worried about the accuracy of information provided by the chatbot and the potential loss of personal interaction with teachers. The need for privacy and data security was also raised as a significant concern. The results of this study could help educators and policymakers make informed decisions about using ChatGPT in education. © 2023. Pongsakorn Limna, Tanpat Kraiwanit, Kris Jangjarat, Prapasiri Klayklung and Piyawatjana Chocksathaporn.","Limna, Pongsakorn and Kraiwanit, Tanpat and Jangjarat, Kris and Klayklung, Prapasiri and Chocksathaporn, Piyawatjana",Journal of Applied Learning and Teaching,,2023,10.37074/jalt.2023.6.1.32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162975175&doi=10.37074%2fjalt.2023.6.1.32&partnerID=40&md5=f66ca072652a80d33decf88547c88ffc,scopus.bib,2024-02-25 11:35:41,Unclassified
Moore2022,Designing Virtual Reality-Based Conversational Agents to Train Clinicians in Verbal De-escalation Skills: Exploratory Usability Study,"Background: Violence and aggression are significant workplace challenges faced by clinicians worldwide. Traditional methods of training consist of “on-the-job learning” and role-play simulations. Although both approaches can result in improved skill levels, they are not without limitation. Interactive simulations using virtual reality (VR) can complement traditional training processes as a cost-effective, engaging, easily accessible, and flexible training tool. Objective: In this exploratory study, we aimed to determine the feasibility of and barriers to verbal engagement with a virtual agent in the context of the Code Black VR application. Code Black VR is a new interactive VR-based verbal de-escalation trainer that we developed based on the Clinical Training Through VR Design Framework. Methods: In total, 28 participants with varying clinical expertise from 4 local hospitals enrolled in the Western Sydney Local Health District Clinical Initiative Nurse program and Transition to Emergency Nursing Programs and participated in 1 of 5 workshops. They completed multiple playthroughs of the Code Black VR verbal de-escalation trainer application and verbally interacted with a virtual agent. We documented observations and poststudy reflection notes. After the playthroughs, the users completed the System Usability Scale and provided written comments on their experience. A thematic analysis was conducted on the results. Data were also obtained through the application itself, which also recorded the total interactions and successfully completed interactions. Results: The Code Black VR verbal de-escalation training application was well received. The findings reinforced the factors in the existing design framework and identified 3 new factors-motion sickness, perceived value, and privacy-to be considered for future application development. Conclusions: Verbal interaction with a virtual agent is feasible for training staff in verbal de-escalation skills. It is an effective medium to supplement clinician training in verbal de-escalation skills. We provide broader design considerations to guide further developments in this area. © Nathan Moore, Naseem Ahmadpour, Martin Brown, Philip Poronnik, Jennifer Davids. Originally published in JMIR Serious Games (https://games.jmir.org), 06.07.2022.","Moore, Nathan and Ahmadpour, Naseem and Brown, Martin and Poronnik, Philip and Davids, Jennifer",JMIR Serious Games,,2022,10.2196/38669,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134403821&doi=10.2196%2f38669&partnerID=40&md5=966aaef5bd2482e1ee9c39e11e1f1197,scopus.bib,2024-02-25 11:35:41,Unclassified
Liu2023,Can chatbots satisfy me? A mixed-method comparative study of satisfaction with task-oriented chatbots in mainland China and Hong Kong,"Task-oriented chatbots are gradually being used across the globe. Most notably, while chatbots have for a long time penetrated users’ daily lives in mainland China, Hong Kong is still struggling to improve and promote its chatbot services. To determine whether antecedents of satisfaction and usage intention differ based on different stages of chatbot adoption and development, we conduct a comparative study based on a research model that integrates the Delone and McLean Information System success model and privacy concerns. The model is developed and examined using a mixed-method approach. After conducting focus group interviews (N = 15) in both regions, online surveys were conducted in mainland China (N = 637) and Hong Kong (N = 647), respectively. Based on qualitative exploration, we identified critical factors of perceived quality and privacy concerns. The quantitative findings further illuminate the different roles of the antecedents in the two regions. The results show that usage intention can be positively influenced by satisfaction, and satisfaction can be increased by relevance, completeness, pleasure and assurance in both regions. However, response time and empathy are factors influencing satisfaction only in mainland China. Privacy concerns cannot influence satisfaction in both regions. © 2023 Elsevier Ltd","Liu, Yu-li and Hu, Bo and Yan, Wenjia and Lin, Zhi",Computers in Human Behavior,,2023,10.1016/j.chb.2023.107716,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150767976&doi=10.1016%2fj.chb.2023.107716&partnerID=40&md5=c9cf512ad105a11edcd8d2426371daf6,scopus.bib,2024-02-25 11:35:41,Unclassified
Miao2023,A Future of Smarter Digital Health Empowered by Generative Pretrained Transformer,"Generative pretrained transformer (GPT) tools have been thriving, as ignited by the remarkable success of OpenAI’s recent chatbot product. GPT technology offers countless opportunities to significantly improve or renovate current health care research and practice paradigms, especially digital health interventions and digital health–enabled clinical care, and a future of smarter digital health can thus be expected. In particular, GPT technology can be incorporated through various digital health platforms in homes and hospitals embedded with numerous sensors, wearables, and remote monitoring devices. In this viewpoint paper, we highlight recent research progress that depicts the future picture of a smarter digital health ecosystem through GPT-facilitated centralized communications, automated analytics, personalized health care, and instant decision-making. © 2023 Journal of Medical Internet Research. All rights reserved.","Miao, Hongyu and Li, Chengdong and Wang, Jing",Journal of Medical Internet Research,,2023,10.2196/49963,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172204717&doi=10.2196%2f49963&partnerID=40&md5=ed0550ce64050ecdd722ef7cd0c4d01e,scopus.bib,2024-02-25 11:35:41,Unclassified
Leschanowsky2023296,Privacy Strategies for Conversational AI and their Influence on Users' Perceptions and Decision-Making,"Conversational AI (CAI) systems are on the rise and have been widely adopted in homes, cars and public spaces. Yet, people report privacy concerns and mistrust in these systems. Current data protection regulations ask providers to communicate data practices transparently and provide users with options to control their data. However, even if users are given control, their decisions can be subject to heuristics and biases leaving people frustrated and regretful. Based on the idea of conversational privacy and debiasing, we design three privacy strategies for CAI that allow people to have their data deleted while at the same time promoting rational decision-making. We conduct a user study to test our strategies in two widespread scenarios using a text-based CAI system and evaluate their impact on peoples' privacy perception, usability and attitude-behaviour alignment. We find that our strategies can significantly change people's behaviour, but do not influence peoples' privacy perception. Finally, we discuss evaluation metrics and future research directions to investigate privacy controls in Conversational AI systems. © 2023 Owner/Author.","Leschanowsky, Anna and Popp, Birgit and Peters, Nils",ACM International Conference Proceeding Series,,2023,10.1145/3617072.3617106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175400905&doi=10.1145%2f3617072.3617106&partnerID=40&md5=4de3c303d16c8fada2fa816b4931b0ea,scopus.bib,2024-02-25 11:35:41,Unclassified
Li2023,"The Influence of Anthropomorphic Cues on Patients’ Perceived Anthropomorphism, Social Presence, Trust Building, and Acceptance of Health Care Conversational Agents: Within-Subject Web-Based Experiment","Background: The last decade has witnessed the rapid development of health care conversational agents (CAs); however, there are still great challenges in making health care CAs trustworthy and acceptable to patients. Objective: Focusing on intelligent guidance CAs, a type of health care CA for web-based patient triage, this study aims to investigate how anthropomorphic cues influence patients’ perceived anthropomorphism and social presence of such CAs and evaluate how these perceptions facilitate their trust-building process and acceptance behavior. Methods: To test the research hypotheses, the video vignette methodology was used to evaluate patients’ perceptions and acceptance of various intelligent guidance CAs. The anthropomorphic cues of CAs were manipulated in a 3×2 within-subject factorial experiment with 103 participants, with the factors of agent appearance (high, medium, and low anthropomorphic levels) and verbal cues (humanlike and machine-like verbal cues) as the within-subject variables. Results: The 2-way repeated measures ANOVA analysis indicated that the higher anthropomorphic level of agent appearance significantly increased mindful anthropomorphism (high level>medium level: 4.57 vs 4.27; P=.01; high level>low level: 4.57 vs 4.04; P<.001; medium level>low level: 4.27 vs 4.04; P=.04), mindless anthropomorphism (high level>medium level: 5.39 vs 5.01; P<.001; high level>low level: 5.39 vs 4.85; P<.001), and social presence (high level>medium level: 5.19 vs 4.83; P<.001; high level>low level: 5.19 vs 4.72; P<.001), and the higher anthropomorphic level of verbal cues significantly increased mindful anthropomorphism (4.83 vs 3.76; P<.001), mindless anthropomorphism (5.60 vs 4.57; P<.001), and social presence (5.41 vs 4.41; P<.001). Meanwhile, a significant interaction between agent appearance and verbal cues (.004) was revealed. Second, the partial least squares results indicated that privacy concerns were negatively influenced by social presence (β=−.375; t312=4.494) and mindful anthropomorphism (β=−.112; t312=1.970). Privacy concerns (β=−.273; t312=9.558), social presence (β=.265; t312=4.314), and mindless anthropomorphism (β=.405; t312=7.145) predicted the trust in CAs, which further promoted the intention to disclose information (β=.675; t312=21.163), the intention to continuously use CAs (β=.190; t312=4.874), and satisfaction (β=.818; t312=46.783). Conclusions: The findings show that a high anthropomorphic level of agent appearance and verbal cues could improve the perceptions of mindful anthropomorphism and mindless anthropomorphism as well as social presence. Furthermore, mindless anthropomorphism and social presence significantly promoted patients’ trust in CAs, and mindful anthropomorphism and social presence decreased privacy concerns. It is also worth noting that trust was an important antecedent and determinant of patients’ acceptance of CAs, including their satisfaction, intention to disclose information, and intention to continuously use CAs. © 2023 Journal of Medical Internet Research. All rights reserved.","Li, Qingchuan and Luximon, Yan and Zhang, Jiaxin",Journal of Medical Internet Research,,2023,10.2196/44479,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167532440&doi=10.2196%2f44479&partnerID=40&md5=4a322c9dafd65a54dee3814ad16b43d8,scopus.bib,2024-02-25 11:35:41,Unclassified
Lian202398,CAPTAIN: An AI-Based Chatbot for Cyberbullying Prevention and Intervention,"Cyberbullying is a widespread and growing problem that can cause various psychological and health well-being outcomes in youth and is considered a serious public health threat. Cutting-edge informatics technology would enable us to identify and stop cyberbullying to prevent harm, death, and privacy violations. However, current cyberbullying prevention approaches offer limited interactions, individualized education, and in-time intervention. With the current emerging technologies in Artificial Intelligence (AI), the use of chatbots have become increasingly popular in health promotion. However, there are current technological challenges that need to be addressed, such as detecting and preventing cyberbullying in real-time, providing personalized responses and intervention, as well as developing the chatbot with a user-friendly interface. This paper introduces CAPTAIN (Cyberbullying Awareness and Prevention Through Artificial INtelligence), an AI-based chatbot for cyberbullying prevention that can provide anytime interaction for personalized intervention. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Lian, Andrew T. and Costilla Reyes, Alfredo and Hu, Xia",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2023,10.1007/978-3-031-35894-4_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173015942&doi=10.1007%2f978-3-031-35894-4_7&partnerID=40&md5=e9ea6590c9ed57e59f5471b6cd770c0e,scopus.bib,2024-02-25 11:35:41,Unclassified
Aslam20233781,Chatbots in the frontline: drivers of acceptance,"Purpose: By extending the service robot acceptance model (sRAM), this study aims to explore and enhance the acceptance of chatbots. The study considered functional, relational, social, user and gratification elements in determining the acceptance of chatbots. Design/methodology/approach: By using the purposive sampling technique, data of 321 service customers, gathered from millennials through a questionnaire and subsequent PLS-SEM modeling, was applied for hypotheses testing. Findings: Findings revealed that the functional elements, perceived usefulness and perceived ease of use affect acceptance of chatbots. However, in social elements, only perceived social interactivity affects the acceptance of chatbots. Moreover, both user and gratification elements (hedonic motivation and symbolic motivation) significantly influence the acceptance of chatbots. Lastly, trust is the only contributing factor for the acceptance of chatbots in the relational elements. Practical implications: The study extends the literature related to chatbots and offers several guidelines to the service industry to effectively employ chatbots. Originality/value: This is one of the first studies that used newly developed sRAM in determining chatbot acceptance. Moreover, the study extended the sRAM by adding user and gratification elements and privacy concerns as originally sRAM model was limited to functional, relational and social elements. © 2022, Emerald Publishing Limited.","Aslam, Wajeeha and Ahmed Siddiqui, Danish and Arif, Imtiaz and Farhat, Kashif",Kybernetes,,2023,10.1108/K-11-2021-1119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132678993&doi=10.1108%2fK-11-2021-1119&partnerID=40&md5=1bfa8169e67e5bcd4d8732f5bb314dd0,scopus.bib,2024-02-25 11:35:41,Unclassified
Levantino2023,Generative and AI-powered oracles: “What will they say about you?”,"In less than one year from its launch, the chatbot ChatGPT has captured widespread public attention, thanks to its ease of use and remarkable performance. However, part of this interest is due to its involvement in some data protection and data security issues. In the context of the ongoing debate surrounding similar technologies, such as generative AI, this contribution will first introduce the ""ChatGPT phenomenon"" (Sections 1 and 2). Then, it will analyse the various positions taken by some key stakeholders on the issues of above and the regulation of the design and use of such technologies, examining these perspectives through the lenses of “Digital Constitutionalism”. Particularly, this paper will emphasise the role that civil society can play in such dynamics (Section 3). Subsequently, it will further promote an active and forward-looking approach in addressing the looming threats these and other AI-based technologies could pose to fundamental rights and society as a whole (Section 4). As we already approach the next AI era without even noticing, the question worth asking ourselves is: “What will generative and AI-powered oracles reveal about us?” (Section 5). © 2023 Elsevier Ltd","Levantino, Francesco Paolo",Computer Law and Security Review,,2023,10.1016/j.clsr.2023.105898,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174621599&doi=10.1016%2fj.clsr.2023.105898&partnerID=40&md5=92c747b525c659a28b8c3e5c94bb8308,scopus.bib,2024-02-25 11:35:41,Unclassified
Guleria20231292,ChatGPT: ethical concerns and challenges in academics and research,"Introduction: The emergence of artificial intelligence (AI) has presented several opportunities to ease human work. AI applications are available for almost every domain of life. A new technology, Chat Generative Pre-Trained Transformer (ChatGPT), was introduced by OpenAI in November 2022, and has become a topic of discussion across the world. ChatGPT-3 has brought many opportunities, as well as ethical and privacy considerations. ChatGPT is a large language model (LLM) which has been trained on the events that happened until 2021. The use of AI and its assisted technologies in scientific writing is against research and publication ethics. Therefore, policies and guidelines need to be developed over the use of such tools in scientific writing. The main objective of the present study was to highlight the use of AI and AI assisted technologies such as the ChatGPT and other chatbots in the scientific writing and in the research domain resulting in bias, spread of inaccurate information and plagiarism. Methodology: Experiments were designed to test the accuracy of ChatGPT when used in research and academic writing. Results: The information provided by ChatGPT was inaccurate and may have far-reaching implications in the field of medical science and engineering. Critical thinking should be encouraged among researchers to raise awareness about the associated privacy and ethical risks. Conclusions: Regulations for ethical and privacy concerns related to the use of ChatGPT in academics and research need to be developed. Copyright © 2023 Guleria et al.","Guleria, Ankita and Krishan, Kewal and Sharma, Vishal and Kanchan, Tanuj",Journal of Infection in Developing Countries,,2023,10.3855/jidc.18738,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174233915&doi=10.3855%2fjidc.18738&partnerID=40&md5=0f14c5ffe000c5e2808759c9ccaa9173,scopus.bib,2024-02-25 11:35:41,Unclassified
Mirbabaie2021365,Hybrid intelligence in hospitals: towards a research agenda for collaboration,"Successful collaboration between clinicians is particularly relevant regarding the quality of care process. In this context, the utilization of hybrid intelligence, such as conversational agents (CAs), is a reasonable approach for the coordination of diverse tasks. While there is a great deal of literature involving collaboration, little effort has been made to integrate previous findings and evaluate research when applying CAs in hospitals. By conducting an extended and systematic literature review and semi-structured expert interviews, we identified four major challenges and derived propositions where in-depth research is needed: 1) audience and interdependency; 2) connectivity and embodiment; 3) trust and transparency; and 4) security, privacy, and ethics. The results are helpful for researchers as we discuss directions for future research on CAs for collaboration in a hospital setting enhancing team performance. Practitioners will be able to understand which difficulties must be considered before the actual application of CAs. © 2021, The Author(s).","Mirbabaie, Milad and Stieglitz, Stefan and Frick, Nicholas R. J.",Electronic Markets,,2021,10.1007/s12525-021-00457-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100249142&doi=10.1007%2fs12525-021-00457-4&partnerID=40&md5=54413627acf4e6f1ba641f6fea97b0e9,scopus.bib,2024-02-25 11:35:41,Unclassified
Fan2021,Utilization of self-diagnosis health chatbots in real-world settings: Case study,"Background: Artificial intelligence (AI)-driven chatbots are increasingly being used in health care, but most chatbots are designed for a specific population and evaluated in controlled settings. There is little research documenting how health consumers (eg, patients and caregivers) use chatbots for self-diagnosis purposes in real-world scenarios. Objective: The aim of this research was to understand how health chatbots are used in a real-world context, what issues and barriers exist in their usage, and how the user experience of this novel technology can be improved. Methods: We employed a data-driven approach to analyze the system log of a widely deployed self-diagnosis chatbot in China. Our data set consisted of 47,684 consultation sessions initiated by 16,519 users over 6 months. The log data included a variety of information, including users' nonidentifiable demographic information, consultation details, diagnostic reports, and user feedback. We conducted both statistical analysis and content analysis on this heterogeneous data set. Results: The chatbot users spanned all age groups, including middle-aged and older adults. Users consulted the chatbot on a wide range of medical conditions, including those that often entail considerable privacy and social stigma issues. Furthermore, we distilled 2 prominent issues in the use of the chatbot: (1) a considerable number of users dropped out in the middle of their consultation sessions, and (2) some users pretended to have health concerns and used the chatbot for nontherapeutic purposes. Finally, we identified a set of user concerns regarding the use of the chatbot, including insufficient actionable information and perceived inaccurate diagnostic suggestions. Conclusions: Although health chatbots are considered to be convenient tools for enhancing patient-centered care, there are issues and barriers impeding the optimal use of this novel technology. Designers and developers should employ user-centered approaches to address the issues and user concerns to achieve the best uptake and utilization. We conclude the paper by discussing several design implications, including making the chatbots more informative, easy-to-use, and trustworthy, as well as improving the onboarding experience to enhance user engagement. © Xiangmin Fan, Daren Chao, Zhan Zhang, Dakuo Wang, Xiaohua Li, Feng Tian.","Fan, Xiangmin and Chao, Daren and Zhang, Zhan and Wang, Dakuo and Li, Xiaohua and Tian, Feng",Journal of Medical Internet Research,,2021,10.2196/19928,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099267127&doi=10.2196%2f19928&partnerID=40&md5=099f5ac81a2627bfa35f9f2f449a14e0,scopus.bib,2024-02-25 11:35:41,Unclassified
Mazzola202262,Privacy and Customer’s Education: NLP for Information Resources Suggestions and Expert Finder Systems,"Privacy is one of the key issues for citizen’s everyday online activities, with the United Nations defining it as “a human right in the digital age”. Despite the introduction of data privacy regulations almost everywhere around the globe, the biggest barrier to effectiveness is the customer’s capacity to map the privacy statement received with the regulation in force and understand their terms. This study advocates the creation of a convenient and cost-efficient question-answering service for answering customers’ queries on data privacy. It proposes a dual step approach, allowing consumers to ask support to a conversational agent boosted by a smart knowledge base, attempting to answer the question using the most appropriate legal document. Being the self-help approach insufficient, our system enacts a second step suggesting a ranked list of legal experts for focused advice. To achieve our objective, we need large enough and specialised dataset and we plan to apply state-of-the-art Natural Language Processing (NLP) techniques in the field of open domain question answering. This paper describes the initial steps and some early results we achieved in this direction and the next steps we propose to develop a one-stop solution for consumers privacy needs. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Mazzola, Luca and Waldis, Andreas and Shankar, Atreya and Argyris, Diamantis and Denzler, Alexander and Van Roey, Michiel",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2022,10.1007/978-3-031-05563-8_5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133244714&doi=10.1007%2f978-3-031-05563-8_5&partnerID=40&md5=46ce4454eea16e04683c2ffffa641ed1,scopus.bib,2024-02-25 11:35:41,Unclassified
Hendrickx2021,Take Back Control: User Privacy and Transparency Concerns in Personalized Conversational Agents,"We reflect on user privacy concerns, transparency and informed consent for long-term interactions with personalized conversational agents. We argue that the common practice of asking users to sign an informed consent form is insufficient to accommodate the privacy concerns of the user. We propose that long-term engaging personalized conversational agents must include an explicit mechanism in their conversations to allow users to have control over their personal information and to have transparency, i.e. about what is stored and who is allowed to view the stored personal information. c 2020  Copyright for this paper by its authors.","Hendrickx, Iris and Waterschoot, Jelte Van and Khan, Arif and Bosch, Louis Ten and Cucchiarini, Catia and Strik, Helmer",CEUR Workshop Proceedings,,2021,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109210222&partnerID=40&md5=4d68a3e4e6c59a8bce9b0decdc10c184,scopus.bib,2024-02-25 11:35:41,Unclassified
Mitsuno2022,Evaluation of a Daily Interactive Chatbot That Exchanges Information about Others through Long-Term Use in a Group of Friends Investigating Dialogue Experience and Privacy Concern,"The goal of this study is to realize a non-task-oriented dialogue agent that is accepted by people in the long term. One approach is using a dialogue strategy in which an agent shares information about other users who are not participating in the current dialogue. This study aims to develop a chatbot that is capable of sharing information about others and to examine its usefulness as well as its problems such as privacy concerns using a long-term empirical experiment in a real-world environment. The result of a 14-day experiment with 120 participants suggested that the usefulness of this dialogue strategy lies in its ability to maintain users’ motivation to interact with the agent and prevent them from having the impression that the agent is mechanical. However, irrespective of the presence of this dialogue strategy, it was suggested that the users were concerned about their privacy to the agent that collected their information on a daily basis. Based on these results, we discussed the relationship between the interestingness of the shared information and the users’ privacy concerns. © 2022, Japanese Society for Artificial Intelligence. All rights reserved.","Mitsuno, Seiya and Yoshikawa, Yuichiro and Ban, Midori and Ishiguro, Hiroshi",Transactions of the Japanese Society for Artificial Intelligence,,2022,10.1527/tjsai.37-3_IDS-I,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132854367&doi=10.1527%2ftjsai.37-3_IDS-I&partnerID=40&md5=729355c35849bc1ad568bc0b63a8bb2a,scopus.bib,2024-02-25 11:35:41,Unclassified
Peng2022,Formative Evaluation of the Acceptance of HIV Prevention Artificial Intelligence Chatbots by Men Who Have Sex with Men in Malaysia: Focus Group Study,"Background: Mobile technologies are being increasingly developed to support the practice of medicine, nursing, and public health, including HIV testing and prevention. Chatbots using artificial intelligence (AI) are novel mobile health strategies that can promote HIV testing and prevention among men who have sex with men (MSM) in Malaysia, a hard-to-reach population at elevated risk of HIV, yet little is known about the features that are important to this key population. Objective: The aim of this study was to identify the barriers to and facilitators of Malaysian MSM’s acceptance of an AI chatbot designed to assist in HIV testing and prevention in relation to its perceived benefits, limitations, and preferred features among potential users. Methods: We conducted 5 structured web-based focus group interviews with 31 MSM in Malaysia between July 2021 and September 2021. The interviews were first recorded, transcribed, coded, and thematically analyzed using NVivo (version 9; QSR International). Subsequently, the unified theory of acceptance and use of technology was used to guide data analysis to map emerging themes related to the barriers to and facilitators of chatbot acceptance onto its 4 domains: performance expectancy, effort expectancy, facilitating conditions, and social influence. Results: Multiple barriers and facilitators influencing MSM’s acceptance of an AI chatbot were identified for each domain. Performance expectancy (ie, the perceived usefulness of the AI chatbot) was influenced by MSM’s concerns about the AI chatbot’s ability to deliver accurate information, its effectiveness in information dissemination and problem-solving, and its ability to provide emotional support and raise health awareness. Convenience, cost, and technical errors influenced the AI chatbot’s effort expectancy (ie, the perceived ease of use). Efficient linkage to health care professionals and HIV self-testing was reported as a facilitating condition of MSM’s receptiveness to using an AI chatbot to access HIV testing. Participants stated that social influence (ie, sociopolitical climate) factors influencing the acceptance of mobile technology that addressed HIV in Malaysia included privacy concerns, pervasive stigma against homosexuality, and the criminalization of same-sex sexual behaviors. Key design strategies that could enhance MSM’s acceptance of an HIV prevention AI chatbot included an anonymous user setting; embedding the chatbot in MSM-friendly web-based platforms; and providing user-guiding questions and options related to HIV testing, prevention, and treatment. Conclusions: This study provides important insights into key features and potential implementation strategies central to designing an AI chatbot as a culturally sensitive digital health tool to prevent stigmatized health conditions in vulnerable and systematically marginalized populations. Such features not only are crucial to designing effective user-centered and culturally situated mobile health interventions for MSM in Malaysia but also illuminate the importance of incorporating social stigma considerations into health technology implementation strategies. ©Mary L Peng, Jeffrey A Wickersham, Frederick L Altice, Roman Shrestha, Iskandar Azwa, Xin Zhou, Mohd Akbar Ab Halim, Wan Mohd Ikhtiaruddin, Vincent Tee, Adeeba Kamarulzaman, Zhao Ni.","Peng, Mary L. and Wickersham, Jeffrey A. and Altice, Frederick L. and Shrestha, Roman and Azwa, Iskandar and Zhou, Xin and Halim, Mohd Akbar Ab and Ikhtiaruddin, Wan Mohd and Tee, Vincent and Kamarulzaman, Adeeba and Ni, Zhao",JMIR Formative Research,,2022,10.2196/42055,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140263659&doi=10.2196%2f42055&partnerID=40&md5=f295f7cec4fbca5a3d082042f254a7ac,scopus.bib,2024-02-25 11:35:41,Unclassified
Duduka2022481,The Impact of Artificial Intelligence on Chatbot Design,"Artificial intelligence is transforming the way chatbots are created and used. The recent boom of artificial intelligence development is creating a whole new generation of intelligent approaches that enable a more efficient and effective design of chatbots. On the other hand, the increasing need and interest from the industry in artificial intelligence based solutions, is guaranteeing the necessary investment and applicational know-how that is pushing such solutions to a new dimension. Some relevant examples are e-commerce, health or education, which is the main focus of this work. This paper studies and analyses the impact that artificial intelligence models and solutions is having on the design and development of chatbots, when compared to the previously used approaches. Some of the most relevant current and future challenges in this domain are highlighted, which include language learning, sentiment interpretation, integration with other services, or data security and privacy issues. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Duduka, Jacint and Reis, Arsénio and Pereira, Rodrigo and Pires, Eduardo and Sousa, José and Pinto, Tiago",Communications in Computer and Information Science,,2022,10.1007/978-3-031-22918-3_39,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148035567&doi=10.1007%2f978-3-031-22918-3_39&partnerID=40&md5=4b9fb92c5295e4cf024d190bbbb0c494,scopus.bib,2024-02-25 11:35:41,Unclassified
Dhinagaran2022,"Designing, Developing, Evaluating, and Implementing a Smartphone-Delivered, Rule-Based Conversational Agent (DISCOVER): Development of a Conceptual Framework","Background: Conversational agents (CAs), also known as chatbots, are computer programs that simulate human conversations by using predetermined rule-based responses or artificial intelligence algorithms. They are increasingly used in health care, particularly via smartphones. There is, at present, no conceptual framework guiding the development of smartphone-based, rule-based CAs in health care. To fill this gap, we propose structured and tailored guidance for their design, development, evaluation, and implementation. Objective: The aim of this study was to develop a conceptual framework for the design, evaluation, and implementation of smartphone-delivered, rule-based, goal-oriented, and text-based CAs for health care. Methods: We followed the approach by Jabareen, which was based on the grounded theory method, to develop this conceptual framework. We performed 2 literature reviews focusing on health care CAs and conceptual frameworks for the development of mobile health interventions. We identified, named, categorized, integrated, and synthesized the information retrieved from the literature reviews to develop the conceptual framework. We then applied this framework by developing a CA and testing it in a feasibility study. Results: The Designing, Developing, Evaluating, and Implementing a Smartphone-Delivered, Rule-Based Conversational Agent (DISCOVER) conceptual framework includes 8 iterative steps grouped into 3 stages, as follows: design, comprising defining the goal, creating an identity, assembling the team, and selecting the delivery interface; development, including developing the content and building the conversation flow; and the evaluation and implementation of the CA. They were complemented by 2 cross-cutting considerations-user-centered design and privacy and security-that were relevant at all stages. This conceptual framework was successfully applied in the development of a CA to support lifestyle changes and prevent type 2 diabetes. Conclusions: Drawing on published evidence, the DISCOVER conceptual framework provides a step-by-step guide for developing rule-based, smartphone-delivered CAs. Further evaluation of this framework in diverse health care areas and settings and for a variety of users is needed to demonstrate its validity. Future research should aim to explore the use of CAs to deliver health care interventions, including behavior change and potential privacy and safety concerns. © 2022 JMIR Publications. All rights reserved.","Dhinagaran, Dhakshenya Ardhithy and Martinengo, Laura and Ho, Moon-Ho Ringo and Joty, Shafiq and Kowatsch, Tobias and Atun, Rifat and Car, Lorainne Tudor",JMIR mHealth and uHealth,,2022,10.2196/38740,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139572670&doi=10.2196%2f38740&partnerID=40&md5=a1475a83b0b14e62b570a1a4d92e6faa,scopus.bib,2024-02-25 11:35:41,Unclassified
Adel2022,Chatbot for construction firms using scalable blockchain network,"Information and Communication Technologies (ICT), including multimedia tools, email services, voice-based tools, and handheld computing tools, have been extensively used for automating and digitalizing different construction processes and activities. However, these technologies are subjected to single-point attacks or failures, manipulation, and lack of privacy and traceability. This study introduces a novel information exchange and management system for construction firms based on blockchain technology and chatbots. The system leverages the characteristics of blockchain technology in terms of peer-to-peer operation mode, data integrity, structuring, and privacy, and the chatbots' merits regarding ease of use and degree of automation. The system is developed for tracking work progress in construction projects as a generic use-case using a four-step approach. First, a private blockchain network is configured for data distribution and storage. Second, a smart contract is coded for regulating data writing/reading operations. Third, a chatbot is developed for data collection and retrieval through textual conversations. Fourth, serverless cloud function and cloudant database are configured to allow the linkage between the blockchain network and the chatbot. A prototype of the system is built and applied to a case study of non-residential construction project to test and verify its capabilities. Further, the system's performance is assessed in terms of the writing and reading latencies and the storage size. The system features can be extended by embedding mathematical algorithms to simultaneously analyze data and employing Inter-Planetary File System (IPFS) to maintain visuals and large-size data. © 2022 Elsevier B.V.","Adel, Kareem and Elhakeem, Ahmed and Marzouk, Mohamed",Automation in Construction,,2022,10.1016/j.autcon.2022.104390,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131422074&doi=10.1016%2fj.autcon.2022.104390&partnerID=40&md5=3b208292cf2b97c9afbed442e231ed80,scopus.bib,2024-02-25 11:35:41,Unclassified
Calvaresi20211,EREBOTS: Privacy-compliant agent-based platform for multi-scenario personalized health-assistant chatbots,"Context. Asynchronous messaging is increasingly used to support human–machine inter-actions, generally implemented through chatbots. Such virtual entities assist the users in activities of different kinds (e.g., work, leisure, and health-related) and are becoming ingrained into humans’ habits due to factors including (i) the availability of mobile devices such as smartphones and tablets, (ii) the increasingly engaging nature of chatbot interactions, (iii) the release of dedicated APIs from messaging platforms, and (iv) increasingly complex AI-based mechanisms to power the bots’ behav-iors. Nevertheless, most of the modern chatbots rely on state machines (implementing conversational rules) and one-fits-all approaches, neglecting personalization, data-stream privacy management, multi-topic management/interconnection, and multimodal interactions. Objective. This work ad-dresses the challenges above through an agent-based framework for chatbot development named EREBOTS. Methods. The foundations of the framework are based on the implementation of (i) multi-front-end connectors and interfaces (i.e., Telegram, dedicated App, and web interface), (ii) enabling the configuration of multi-scenario behaviors (i.e., preventive physical conditioning, smoking cessa-tion, and support for breast-cancer survivors), (iii) online learning, (iv) personalized conversations and recommendations (i.e., mood boost, anti-craving persuasion, and balance-preserving physical exercises), and (v) responsive multi-device monitoring interface (i.e., doctor and admin). Results. EREBOTS has been tested in the context of physical balance preservation in social confinement times (due to the ongoing pandemic). Thirteen individuals characterized by diverse age, gender, and country distribution have actively participated in the experimentation, reporting advancements in the physical balance and overall satisfaction of the interaction and exercises’ variety they have been proposed. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Calvaresi, Davide and Calbimonte, Jean-Paul and Siboni, Enrico and Eggenschwiler, Stefan and Manzo, Gaetano and Hilfiker, Roger and Schumacher, Michael",Electronics (Switzerland),,2021,10.3390/electronics10060666,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102393472&doi=10.3390%2felectronics10060666&partnerID=40&md5=54dafd673b5c9a1bc4464dbb158a4a28,scopus.bib,2024-02-25 11:35:41,Unclassified
Lu202342,Developing Responsible Chatbots for Financial Services: A Pattern-Oriented Responsible Artificial Intelligence Engineering Approach,"The recent release of ChatGPT has gained huge attention and discussion worldwide, with responsible artificial intelligence (RAI) being a crucial topic of discussion. One key question is, ""How can we ensure that AI systems, like ChatGPT, are developed and adopted in a responsible way?""To tackle RAI challenges, various ethical principles have been released by governments, organizations, and companies. However, those principles are very abstract and not practical enough. Further, significant efforts have been put on algorithm-level solutions that only address a narrow set of principles, such as fairness and privacy. To fill the gap, we adopt a pattern-oriented RAI engineering approach and build an RAI pattern catalog to operationalize RAI from a system perspective. In this article, we first summarize the major challenges in operationalizing RAI at scale and introduce how we use the RAI pattern catalog to address those challenges. We then examine the risks at each stage of the chatbot development process and recommend pattern-driven mitigations to evaluate the usefulness of the RAI pattern catalog in a real-world setting.  © 2001-2011 IEEE.","Lu, Qinghua and Luo, Yuxiu and Zhu, Liming and Tang, Mingjian and Xu, Xiwei and Whittle, Jon",IEEE Intelligent Systems,,2023,10.1109/MIS.2023.3320437,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165127803&doi=10.1109%2fMIS.2023.3320437&partnerID=40&md5=8315036640a9c833c146ede69c0be028,scopus.bib,2024-02-25 11:35:41,Unclassified
Fournier-Tombs2023,A Medical Ethics Framework for Conversational Artificial Intelligence,"The launch of OpenAI’s GPT-3 model in June 2020 began a new era for conversational chatbots. While there are chatbots that do not use artificial intelligence (AI), conversational chatbots integrate AI language models that allow for back-and-forth conversation between an AI system and a human user. GPT-3, since upgraded to GPT-4, harnesses a natural language processing technique called sentence embedding and allows for conversations with users that are more nuanced and realistic than before. The launch of this model came in the first few months of the COVID-19 pandemic, where increases in health care needs globally combined with social distancing measures made virtual medicine more relevant than ever. GPT-3 and other conversational models have been used for a wide variety of medical purposes, from providing basic COVID-19–related guidelines to personalized medical advice and even prescriptions. The line between medical professionals and conversational chatbots is somewhat blurred, notably in hard-to-reach communities where the chatbot replaced face-to-face health care. Considering these blurred lines and the circumstances accelerating the adoption of conversational chatbots globally, we analyze the use of these tools from an ethical perspective. Notably, we map out the many types of risks in the use of conversational chatbots in medicine to the principles of medical ethics. In doing so, we propose a framework for better understanding the effects of these chatbots on both patients and the medical field more broadly, with the hope of informing safe and appropriate future developments. © Eleonore Fournier-Tombs, Juliette McHardy.","Fournier-Tombs, Eleonore and McHardy, Juliette",Journal of Medical Internet Research,,2023,10.2196/43068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165788275&doi=10.2196%2f43068&partnerID=40&md5=4bab0dcf8b77bbaf4f834a1bdf405019,scopus.bib,2024-02-25 11:35:41,Unclassified
Figueroa2021,Conversational Physical Activity Coaches for Spanish and English Speaking Women: A User Design Study,"Introduction: Digital technologies, including text messaging and mobile phone apps, can be leveraged to increase people's physical activity and manage health. Chatbots, powered by artificial intelligence, can automatically interact with individuals through natural conversation. They may be more engaging than one-way messaging interventions. To our knowledge, physical activity chatbots have not been developed with low-income participants, nor in Spanish—the second most dominant language in the U.S. We recommend best practices for physical activity chatbots in English and Spanish for low-income women. Methods: We designed a prototype physical activity text-message based conversational agent based on various psychotherapeutic techniques. We recruited participants through SNAP-Ed (Supplemental Nutrition Assistance Program Education) in California (Alameda County) and Tennessee (Shelby County). We conducted qualitative interviews with participants during testing of our prototype chatbot, held a Wizard of Oz study, and facilitated a co-design workshop in Spanish with a subset of our participants. Results: We included 10 Spanish- and 8 English-speaking women between 27 and 41 years old. The majority was Hispanic/Latina (n = 14), 2 were White and 2 were Black/African American. More than half were monolingual Spanish speakers, and the majority was born outside the US (>50% in Mexico). Most participants were unfamiliar with chatbots and were initially skeptical. After testing our prototype, most users felt positively about health chatbots. They desired a personalized chatbot that addresses their concerns about privacy, and stressed the need for a comprehensive system to also aid with nutrition, health information, stress, and involve family members. Differences between English and monolingual Spanish speakers were found mostly in exercise app use, digital literacy, and the wish for family inclusion. Conclusion: Low-income Spanish- and English-speaking women are interested in using chatbots to improve their physical activity and other health related aspects. Researchers developing health chatbots for this population should focus on issues of digital literacy, app familiarity, linguistic and cultural issues, privacy concerns, and personalization. Designing and testing this intervention for and with this group using co-creation techniques and involving community partners will increase the probability that it will ultimately be effective. © Copyright © 2021 Figueroa, Luo, Jacobo, Munoz, Manuel, Chan, Canny and Aguilera.","Figueroa, Caroline A. and Luo, Tiffany C. and Jacobo, Andrea and Munoz, Alan and Manuel, Minx and Chan, David and Canny, John and Aguilera, Adrian",Frontiers in Digital Health,,2021,10.3389/fdgth.2021.747153,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131227176&doi=10.3389%2ffdgth.2021.747153&partnerID=40&md5=17837b264b5c443418797030ad583d4f,scopus.bib,2024-02-25 11:35:41,Unclassified
Bouhia20221159,Drivers of privacy concerns when interacting with a chatbot in a customer service encounter,"Purpose: This study aims to examine the antecedents of privacy concerns in the era of artificial intelligence. Specifically, it focuses on the impact of various factors related to interactions with a chatbot (creepiness and perceived risk) and individual traits (familiarity with chatbots and need for privacy) in relation to privacy when interacting with a chatbot in the context of financial services. The moderating effect of gender on these relationships was also examined. Design/methodology/approach: A total of 430 Canadians responded to an online questionnaire after interacting with a chatbot in the context of a simulated auto insurance quote. A structural equation model was used to test the hypotheses. Findings: The results showed that privacy concerns are influenced primarily by creepiness, followed by perceived risk and the need for privacy. The last two relationships are moderated by gender. Conversely, familiarity with chatbots does not affect privacy concerns in this context. Originality/value: This study is the first to consider the influence of creepiness as an antecedent of privacy concerns arising from interactions with AI tools and highlight its key impacts. It also shows how gender moderates specific relationships in this context. © 2022, Emerald Publishing Limited.","Bouhia, Mariem and Rajaobelina, Lova and PromTep, Sandrine and Arcand, Manon and Ricard, Line",International Journal of Bank Marketing,,2022,10.1108/IJBM-09-2021-0442,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130135261&doi=10.1108%2fIJBM-09-2021-0442&partnerID=40&md5=67e13d769c9207a4239369d88b4bd042,scopus.bib,2024-02-25 11:35:41,Unclassified
Motger2021347,Integrating Adaptive Mechanisms into Mobile Applications Exploiting User Feedback,"Mobile applications have become a commodity in multiple daily scenarios. Their increasing complexity has led mobile software ecosystems to become heterogeneous in terms of hardware specifications, features and context of use, among others. For their users, fully exploiting their potential has become challenging. While enacting software systems with adaptation mechanisms has proven to ease this burden from users, mobile devices present specific challenges related to privacy and security concerns. Nevertheless, rather than being a limitation, users can play a proactive role in the adaptation loop by providing valuable feedback for runtime adaptation. To this end, we propose the use of chatbots to interact with users through a human-like smart conversational process. We depict a work-in-progress proposal of an end-to-end framework to integrate semi-automatic adaptation mechanisms for mobile applications. These mechanisms include the integration of both implicit and explicit user feedback for autonomous user categorization and execution of enactment action plans. We illustrate the applicability of such techniques through a set of scenarios from the Mozilla mobile applications suite. We envisage that our proposal will improve user experience by bridging the gap between users’ needs and the capabilities of their mobile devices through an intuitive and minimally invasive conversational mechanism. © 2021, Springer Nature Switzerland AG.","Motger, Quim and Franch, Xavier and Marco, Jordi",Lecture Notes in Business Information Processing,,2021,10.1007/978-3-030-75018-3_23,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111164309&doi=10.1007%2f978-3-030-75018-3_23&partnerID=40&md5=f5a523a708437fe0be1f015acfd94b75,scopus.bib,2024-02-25 11:35:41,Unclassified
Kayalı202320,Investigation of student experiences with ChatGPT-supported online learning applications in higher education,"The purpose of this study was to determine university students' experiences with the use of ChatGPT in online courses. The sample consisted of 84 associate degree students from a state university in Turkey. A multi-method approach was used in the study. Although quantitative data were collected using the Chatbot Usability Scale, qualitative data were collected using a semi-structured interview form that we developed. The data were analysed using descriptive and content analysis methods. According to the findings, ChatGPT exhibits advantages such as a user-friendly interface and fast, concise, relevant responses. Moreover, emphasizing its contribution to the learning process, the information provided was sufficient and topic-oriented. The understandability of the chatbot’s functions and the clarity of their communication were emphasized. However, there are disadvantages such as performance issues, frequency of errors and the risk of providing misleading information. Concerns have also been raised about the potential difficulties chatbots may face in ambiguous conversations and providing insufficient information on privacy issues. In conclusion, ChatGPT is recognised as a potentially valuable tool in education based on positive usability impressions; however, more research is needed for its safe use. Implications for practice or policy • Based on positive usability impressions, students and instructors can use ChatGPT to support educational activities. • ChatGPT can promote and enhance students' personalised learning experiences. • ChatGPT can be used in all higher education courses. • Users should be cautious about the accuracy and reliability of the answers provided by ChatGPT. • Decision-makers should take precautions against risks such as privacy, ethics, confidentiality and security that may arise from using artificial intelligence in education. © Articles published in the Australasian Journal of Educational Technology (AJET) are available under Creative Commons Attribution Non-Commercial No Derivatives Licence (CC BY-NC-ND 4.0). Authors retain copyright in their work and grant AJET right of first publication under CC BY-NC-ND 4.0.","Kayalı, Bünyami and Yavuz, Mehmet and Balat, Şener and Çalışan, Mücahit",Australasian Journal of Educational Technology,,2023,10.14742/ajet.8915,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184199144&doi=10.14742%2fajet.8915&partnerID=40&md5=b9dd2fa4a9cc465424d4bcb26f4ba8f3,scopus.bib,2024-02-25 11:35:41,Unclassified
Martinengo2023,"Conversational Agents in Health Care: Expert Interviews to Inform the Definition, Classification, and Conceptual Framework","Background: Conversational agents (CAs), or chatbots, are computer programs that simulate conversations with humans. The use of CAs in health care settings is recent and rapidly increasing, which often translates to poor reporting of the CA development and evaluation processes and unreliable research findings. We developed and published a conceptual framework, designing, developing, evaluating, and implementing a smartphone-delivered, rule-based conversational agent (DISCOVER), consisting of 3 iterative stages of CA design, development, and evaluation and implementation, complemented by 2 cross-cutting themes (user-centered design and data privacy and security). Objective: This study aims to perform in-depth, semistructured interviews with multidisciplinary experts in health care CAs to share their views on the definition and classification of health care CAs and evaluate and validate the DISCOVER conceptual framework. Methods: We conducted one-on-one semistructured interviews via Zoom (Zoom Video Communications) with 12 multidisciplinary CA experts using an interview guide based on our framework. The interviews were audio recorded, transcribed by the research team, and analyzed using thematic analysis. Results: Following participants’ input, we defined CAs as digital interfaces that use natural language to engage in a synchronous dialogue using ≥1 communication modality, such as text, voice, images, or video. CAs were classified by 13 categories: response generation method, input and output modalities, CA purpose, deployment platform, CA development modality, appearance, length of interaction, type of CA-user interaction, dialogue initiation, communication style, CA personality, human support, and type of health care intervention. Experts considered that the conceptual framework could be adapted for artificial intelligence–based CAs. However, despite recent advances in artificial intelligence, including large language models, the technology is not able to ensure safety and reliability in health care settings. Finally, aligned with participants’ feedback, we present an updated iteration of the conceptual framework for health care conversational agents (CHAT) with key considerations for CA design, development, and evaluation and implementation, complemented by 3 cross-cutting themes: ethics, user involvement, and data privacy and security. Conclusions: We present an expanded, validated CHAT and aim at guiding researchers from a variety of backgrounds and with different levels of expertise in the design, development, and evaluation and implementation of rule-based CAs in health care settings. © 2023 Journal of Medical Internet Research. All rights reserved.","Martinengo, Laura and Lin, Xiaowen and Jabir, Ahmad Ishqi and Kowatsch, Tobias and Atun, Rifat and Car, Josip and Car, Lorainne Tudor",Journal of Medical Internet Research,,2023,10.2196/50767,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175877496&doi=10.2196%2f50767&partnerID=40&md5=820a29f8f0b85cb62ee627f7987646c7,scopus.bib,2024-02-25 11:35:41,Unclassified
Huallpa2023105,Exploring the ethical considerations of using Chat GPT in university education,"This study investigates the moral dilemmas that arise with incorporating Chat GPT into higher education, with a focus on the situation in Latinoamerican institutions of higher learning. The study surveyed 220 people via online questionnaire to learn more about their experiences with and motivations for using AI-powered conversational agents. An overview of the demographics of the participants was provided through descriptive statistics. This investigation of the subject at hand lays the groundwork for further research. It also reveals the hidden meanings of the observed phenomena, and it suggests possible solutions to the problems that have been uncovered. This research looks at how AI systems and chatbots can supplement human knowledge and judgment, as well as their potential drawbacks. The results showed that participants thought Chat GPT integration was moderately accessible and had moderately positive social attitudes. They understood the value and responsibility of Chat GPT in creating individualized educational opportunities. Participants stressed the necessity for explicit institutional standards regarding privacy and data security. Gender, age, sense of accessibility, social attitude, opinions, and personal experience, privacy and data security, institutional guidelines, and individualized learning were also found to affect participants' reliance on AI through regression analysis. The findings shed light on how the integration of Chat GPT into Latinoamerican higher education is complicated by factors such as individual beliefs, cultural norms, and ethical problems. The busy schedules of students may be accommodated and the resources they need to succeed can be made available thanks to this adaptability. In addition, natural language processing models can offer students instantaneous help via text chat, voice, or video. To fully grasp the ethical consequences and lead the creation of responsible implementation techniques, the research proposes that additional qualitative investigations, longitudinal studies, and comparative research across diverse contexts is required. Closing these knowledge gaps will help move the conversational AI field forward in ways that are ethical and beneficial to the classroom. © The Author 2023. This work is licensed under a Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/) that allows others to share and adapt the material for any purpose (even commercially), in any medium with an acknowledgement of the work's authorship and initial publication in this journal. All Rights Reserved.","Huallpa, Jorge Jinchuña and Flores Arocutipa, Javier Pedro and Panduro, Walker Diaz and Huete, Luis Chauca and Flores Limo, Fernando Antonio and Herrera, Edward Espinoza and Alba Callacna, Rafael Arturo and Ariza Flores, Victor Andre and Medina Romero, Miguel Ángel and Quispe, Isaac Merino and Hernández Hernández, Fredy Alberto",Periodicals of Engineering and Natural Sciences,,2023,10.21533/pen.v11i4.3770,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172990878&doi=10.21533%2fpen.v11i4.3770&partnerID=40&md5=d257b7a9f07ce86bf5112b47d7986733,scopus.bib,2024-02-25 11:35:41,Unclassified
Alt2021165,IDENTIFYING RELEVANT SEGMENTS OF POTENTIAL BANKING CHATBOT USERS BASED ON TECHNOLOGY ADOPTION BEHAVIOR; [IDENTIFICIRANJE RELEVANTNIH SEGMENATA POTENCIJALNIH KORISNIKA CHATBOTA U BANKARSTVU NA TEMELJU PONAŠANJA PRI PRIHVAĆANJU TEHNOLOGIJE],"Purpose – Chatbot technology is expected to revolution-ize customer service in financial institutions. However, the adoption of customer service chatbots in banking remains low. Therefore, the aim of this paper is to identify relevant segments of potential banking chatbot users based on technology adoption behavior. Design/Methodology/Approach – Data for the research was collected through an online questionnaire in Romania using the non-probability sampling method. The 287 questionnaires were analyzed using hierarchical and k-means cluster analysis. Findings and implications – The analysis revealed three distinct segments: Innovators (26%), consisting of highly educated young women employed in the business sec-tor; the Late Majority (55%), consisting of young women with higher education degrees who work in services-re-lated fields; and Laggards (19%), consisting of educated middle-aged men employed in the business sector. New significant differences among demographic and banking behavior variables were observed across the profiles of potential banking chatbot user segments. Limitations – The study is based on a non-probability sample collected from only one country, with a rather small sample size. Originality – Technology acceptance variables (perceived usefulness, perceived ease of use), expanded to include constructs such as awareness of service, perceived privacy risk, and perceived compatibility, were found to be appro-priate for customer segmentation purposes in the context of chatbot applications based on artificial intelligence. The study also revealed a new innovator demographic profile. © 2021, University of Zagreb, Faculty of Economics and Business Zagreb. All rights reserved.","Alt, Mónika-Anetta and Ibolya, Vizeli",Market-Trziste,,2021,10.22598/mt/2021.33.2.165,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123023220&doi=10.22598%2fmt%2f2021.33.2.165&partnerID=40&md5=da181df15bc8f67a24635f379453c7d9,scopus.bib,2024-02-25 11:35:41,Unclassified
Morsi2023156,Artificial Intelligence in Electronic Commerce: Investigating the Customers' Acceptance of Using Chatbots,"Artificial intelligence (AI) has become an important tool for companies trying to gain a competitive edge in the online market. Business to Consumer (B2C) e-commerce firms are increasingly integrating chatbots as virtual shopping assistants for providing more personalized and efficient shopping experiences to online customers. Chatbots are AI-powered software programs that can communicate with users through text or voice interfaces. However, there is a lack of research on the acceptance of chatbots in B2C e-commerce in Egypt. Therefore, this research tries to fill the gap in e-commerce chatbot literature by investigating the acceptance of the use of chatbots in online shopping among Egyptian users by applying the Use and Gratification theory. This is an exploratory study using a quantitative survey-based approach for collecting data from online Egyptian customers on their attitudes or intentions to use Chatbots in online shopping. The data were analysed by using regression analysis for identifying factors that influence user acceptance and usage of chatbots. The results revealed that both of hedonic and technology factors have positive influence on users' behavioural intention. While the risk factor which has two sub-factors namely; privacy and immature technology has negative influence on customers' behavioural intentions. The study contributes to the expanding body of literature on the acceptance and use of Chatbots among customers in B2C e-commerce context. In addition, the study's findings give significant insights for Egyptian online retailers looking to implement Chatbots in their customer service strategy. © 2023, Success Culture Press. All rights reserved.","Morsi, Shereen",Journal of System and Management Sciences,,2023,10.33168/JSMS.2023.0311,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162777495&doi=10.33168%2fJSMS.2023.0311&partnerID=40&md5=dc55a2eed4f57fca6c72a3910b76d5c8,scopus.bib,2024-02-25 11:35:41,Unclassified
Liu2023115,FairShare: An Incentive-Based Fairness-Aware Data Sharing Framework for Federated Learning,"Federated learning protects sensitive data during AI model training, enabling collaboration without sharing raw data. Ensuring fairness and addressing un-shared decisions are crucial for reliable federated learning. This study introduces “FairShare”, an incentive mechanism enhancing reliability in applications like financial fraud detection and chatbot customer service. FairShare has two stages: stage one uses the Vickrey-Clarke-Groves (VCG) auction to estimate clients’ true costs, ensuring truthfulness, individual rationality, and computational efficiency. Stage two employs the Shapley Value method to allocate fair payments, promoting high-quality data usage. FairShare encourages clients to balance local datasets, reducing bias and increasing reliability. Theoretical proofs and experiments demonstrate FairShare’s effectiveness in ensuring fairness and protecting data privacy, leading to reliable outcomes. Experiments confirm the VCG-based mechanism’s truthfulness and Shapley Value’s fairness in payment allocation. In conclusion, FairShare addresses fairness challenges and fosters reliability in federated learning, facilitating dependable human-machine interactions. Implementing FairShare can enhance sensitive data protection, promote fairness, and improve reliability in human-machine interactions, supporting federated learning adoption across sectors. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023.","Liu, Liyuan and Kong, Ying and Li, Gaolei and Han, Meng",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2023,10.1007/978-981-99-6486-4_10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175984865&doi=10.1007%2f978-981-99-6486-4_10&partnerID=40&md5=c7f91e4a46c8ce99e503972eceafda6a,scopus.bib,2024-02-25 11:35:41,Unclassified
Følstad2020671,Communicating Service Offers in a Conversational User Interface: An Exploratory Study of User Preferences in Chatbot Interaction,"The increased interest in chatbots accentuates the importance of conversational design. A key conversational design challenge concerns how to communicate available service offers to users. We present an exploratory study, conducted in the context of financial service provision. Here, we first detailed four alternative approaches to communicate available service offers, reflecting different levels of proactivity. We then gathered feedback on user preference through interviews with 17 users following their interactions with prototypes representing the four approaches. Proactivity in the communication of service offers was found to be potentially valuable, provided that the offer is relevant to the conversation, do not compromise conversational efficiency, and is easy to discard. However, proactive communication of service offers may also entail challenges concerning perceptions of privacy and invasiveness, and, hence, needs to be designed with great care. Based on our findings, we summarize implications for theory and practice and propose directions for future research.  © 2020 Owner/Author.","Følstad, Asbjørn and Halvorsrud, Ragnhild",ACM International Conference Proceeding Series,,2020,10.1145/3441000.3441046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101734030&doi=10.1145%2f3441000.3441046&partnerID=40&md5=0aa3188c5e7fb2197ee6f07be5dde0c4,scopus.bib,2024-02-25 11:35:41,Unclassified
Siemon2022,Requirements and Solution Approaches to Personality-Adaptive Conversational Agents in Mental Health Care,"Artificial intelligence (AI) technologies enable Conversational Agents (CAs) to perform highly complex tasks in a human-like manner and may help people cope with anxiety to improve their mental health and well-being. To support patients with their mental well-being in an authentic way, CAs need to be imbued with human-like behavior, such as personality. In this paper we cover an innovative form of CA, so-called Personality-Adaptive Conversational Agents (PACAs) that automatically infer users’ personality traits and adapt accordingly to their personality. We empirically investigate their benefits and caveats in mental health care. The results of our study show that PACAs can be beneficial for mental health support, but they also raise concerns about trust and privacy issues. We present a set of relevant requirements for designing PACAs and provide solution approaches that can be followed when designing and implementing PACAs for mental health care. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Siemon, Dominik and Ahmad, Rangina and Harms, Henrik and de Vreede, Triparna",Sustainability (Switzerland),,2022,10.3390/su14073832,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127554480&doi=10.3390%2fsu14073832&partnerID=40&md5=582917541399e326caf1a183aa6bbbb2,scopus.bib,2024-02-25 11:35:41,Unclassified
Pizzi20231372,"I, chatbot! the impact of anthropomorphism and gaze direction on willingness to disclose personal information and behavioral intentions","The present research focuses on the interplay between two common features of the customer service chatbot experience: gaze direction and anthropomorphism. Although the dominant approach in marketing theory and practice is to make chatbots as human-like as possible, the current study, built on the humanness-value-loyalty model, addresses the chain of effects through which chatbots' nonverbal behaviors affect customers' willingness to disclose personal information and purchase intentions. By means of two experiments that adopt a real chatbot in a simulated shopping environment (i.e., car rental and travel insurance), the present work allows us to understand how to reduce individuals' tendency to see conversational agents as less knowledgeable and empathetic compared with humans. The results show that warmth perceptions are affected by gaze direction, whereas competence perceptions are affected by anthropomorphism. Warmth and competence perceptions are found to be key drivers of consumers’ skepticism toward the chatbot, which, in turn, affects consumers’ trust toward the service provider hosting the chatbot, ultimately leading consumers to be more willing to disclose their personal information and to repatronize the e-tailer in the future. Building on the Theory of Mind, our results show that perceiving competence from a chatbot makes individuals less skeptical as long as they feel they are good at detecting others’ ultimate intentions. © 2023 The Authors. Psychology & Marketing published by Wiley Periodicals LLC.","Pizzi, Gabriele and Vannucci, Virginia and Mazzoli, Valentina and Donvito, Raffaele",Psychology and Marketing,,2023,10.1002/mar.21813,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150974118&doi=10.1002%2fmar.21813&partnerID=40&md5=7586c860885fd96262417ee9e6157c20,scopus.bib,2024-02-25 11:35:41,Unclassified
Meskó2023,The imperative for regulatory oversight of large language models (or generative AI) in healthcare,"The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality. © 2023, The Author(s).","Meskó, Bertalan and Topol, Eric J.",npj Digital Medicine,,2023,10.1038/s41746-023-00873-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164295991&doi=10.1038%2fs41746-023-00873-0&partnerID=40&md5=657da2c6a8b235b18551d0094cd60b67,scopus.bib,2024-02-25 11:35:41,Unclassified
Sanabria2023382,“A Great Way to Start the Conversation”: Evidence for the Use of an Adolescent Mental Health Chatbot Navigator for Youth at Risk of HIV and Other STIs,"Chatbot use is increasing for mobile health interventions on sensitive and stigmatized topics like mental health because of their anonymity and privacy. This anonymity provides acceptability to sexual and gendered minority youth (ages 16–24) at increased risk of HIV and other STIs with poor mental health due to higher levels of stigma, discrimination, and social isolation. This study evaluates the usability of Tabatha-YYC, a pilot chatbot navigator created to link these youth to mental health resources. Tabatha-YYC was developed using a Youth Advisory Board (n = 7). The final design underwent user testing (n = 20) through a think-aloud protocol, semi-structured interview, and a brief survey post-exposure which included the Health Information Technology Usability Evaluation Scale. The chatbot was found to be an acceptable mental health navigator by participants. This study provides important design methodology considerations and key insights into chatbot design preferences of youth at risk of STIs seeking mental health resources. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.","Sanabria, Gabriella and Greene, Karah Y. and Tran, Jennifer T. and Gilyard, Shelton and DiGiovanni, Lauren and Emmanuel, Patricia J. and Sanders, Lisa J. and Kosyluk, Kristin and Galea, Jerome T.",Journal of Technology in Behavioral Science,,2023,10.1007/s41347-023-00315-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159115973&doi=10.1007%2fs41347-023-00315-4&partnerID=40&md5=caecf3131f5f4bd49caa6a995119866f,scopus.bib,2024-02-25 11:35:41,Unclassified
Mohammed20231007,"A Review on Explainable Artificial Intelligence Methods, Applications, and Challenges","Explainable Artificial Intelligence (XAI) has emerged as a critical area of research and development in the field of artificial intelligence. This abstract provides an overview of XAI, covering its methods, applications, and challenges. XAI Methods: XAI methods aim to enhance the transparency and interpretability of complex machine learning models. Model-agnostic techniques like LIME and model-specific methods like SHAP have gained prominence in providing explanations for AI predictions. The field also explores interpretable deep learning architectures and approaches to make neural networks more transparent. XAI Applications: XAI finds applications across diverse domains. In healthcare, XAI assists in interpreting medical diagnoses and treatment recommendations. In finance, it aids in risk assessment and regulatory compliance. XAI is crucial in autonomous vehicles to explain decision-making processes, contributing to safety and trust. In customer service, it improves chatbot interactions by providing understandable responses. Moreover, XAI has relevance in agriculture, manufacturing, energy efficiency, education, content recommendation, and more. XAI Challenges: Despite its significance, XAI faces several challenges. Balancing model complexity with interpretability remains a fundamental trade-off. Detecting and mitigating bias in AI systems is crucial, especially in sensitive domains. Ensuring ethical considerations, data privacy, and user consent are paramount. Challenges also include providing explanations for high-stakes decisions, addressing the need for human oversight, and adapting to international and cultural norms. In conclusion, XAI plays a pivotal role in making AI systems more transparent, fair, and accountable. As it continues to evolve, it is poised to shape the future of AI by enabling users to understand and trust AI systems, fostering responsible AI development, and addressing ethical and practical challenges in various applications. © 2023 Institute of Advanced Engineering and Science. All rights reserved.","Mohammed, Belghachi",Indonesian Journal of Electrical Engineering and Informatics,,2023,10.52549/ijeei.v11i4.5151,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183189918&doi=10.52549%2fijeei.v11i4.5151&partnerID=40&md5=2f016dfe7bf6939a45cdd3a081206efe,scopus.bib,2024-02-25 11:35:41,Unclassified
Rastogi2022311,Eunoia: A Website for Self-CBT and Psychotherapy,"Cognitive behaviour therapy (CBT) is an effective treatment strategy for a variety of mental and emotional health disorders, such as anxiety and depression. CBT aims to assist you in recognising and challenging harmful ideas as well as learning practical self-help techniques. Internet technology is a viable addition to traditional therapy delivery because of its high penetration, capacity to gather and analyse data, and ability to engage with people. With the various CBT apps and websites, it is discovered that most of them required membership or hiring a therapist online in order to use CBT. They had resources added to them, but most of them lacked an appropriate structure or methodology. The objective of this paper is to achieve privacy, accessibility, and time-saving. In this paper, the online support for the delivery of Self-CBT is provided by a website called “Eunoia,” which gives numerous questionnaires to help patients identify difficult events or conditions in their lives, as well as worksheets and other resources such as chatbot for the patient’s therapy. This website focuses on interpersonal issues, emotional dysregulation, relationship issues, and workplace issues, and it can help in figuring out where the negative thoughts come from and how to utilise the worksheets as homework to work on emotions and thoughts. The questionnaire findings are calculated quite precisely. There is no correct answer in these questionnaires, thus the answer choice involves different points. Users of this Self-CBT website can complete their homework without the burden of lugging papers and worksheets around with them. Eunoia, the Self-CBT website, has yielded unexpected outcomes. Participants in this study went through stage 1 of Self-CBT, where they are required to complete questionnaires that assisted them in recognising their negative thoughts. They are quite pleased with the outcome. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Rastogi, Dhruv and Thakur, Shubhangi and Singh, Leena",Lecture Notes in Electrical Engineering,,2022,10.1007/978-981-19-4364-5_24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144560520&doi=10.1007%2f978-981-19-4364-5_24&partnerID=40&md5=f695972849919f4c931812359cd88ba4,scopus.bib,2024-02-25 11:35:41,Unclassified
Xu2022,A tool or a social being? A dynamic longitudinal investigation of functional use and relational use of AI voice assistants,"This study integrates two lines of research: technologies as tools and technologies as social beings, under the theoretical framework of dynamic systems, to investigate the reciprocal dynamics between functional use and relational use of artificial intelligence (AI) voice assistants, and the mediating roles of self-disclosure and privacy concerns. A two-wave longitudinal survey was conducted among 354 AI voice assistant users across 2 months. Factor analysis results supported the conceptualization and operationalization of functional use and relational use of voice assistants. Results from the cross-lagged panel model confirmed that functional use and relational use reinforced themselves over time, respectively. Relational use increased subsequent functional use, and relational use reinforced itself through self-disclosure. Surprisingly, functional use did not increase subsequent relational use; instead, longitudinal mediation analysis showed that functional use reduced subsequent relational use due to the lack of self-disclosure. Furthermore, while self-disclosure increased subsequent privacy concerns, privacy concerns did not reduce subsequent self-disclosure. © The Author(s) 2022.","Xu, Shan and Li, Wenbo",New Media and Society,,2022,10.1177/14614448221108112,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134288653&doi=10.1177%2f14614448221108112&partnerID=40&md5=fc64551b8d2cc48489b2e70c009f07f9,scopus.bib,2024-02-25 11:35:41,Unclassified
Sayegh-Jodehl2022,Use of Instant Messaging Software in a German Hospital—An Exploratory Investigation among Physicians,"Internationally, evidence exists that physicians use instant messaging services for communication tasks in everyday clinical practice However, there are only few data on physicians in Germany in this regard. Therefore, at the initiation of our project “DocTalk-Dialog meets Chatbot: Collaborative Learning and Teaching in the Process of Work”, we conducted a stakeholder survey with an exploratory research approach. The aim was to gain initial insights into use of instant messaging software and attitudes towards data security and advantages and disadvantages before implementing a data-secure in-house messaging platform. N = 70 physicians at Charité-Universitätsmedizin Berlin completed an exploratory questionnaire with closed and open-ended questions. Quantitative data were analyzed using descriptive statistics and qualitative data using thematic analysis. The use of messenger software was not widespread in the sample studied. Physicians most frequently used face-to-face contact for communication. On average, up to ten instant messages were exchanged per day, mainly among colleagues, to answer mutual questions, and to send pictures. With a high awareness of privacy-related restrictions among participating physicians, advantages such as fast and uncomplicated communication were also highlighted. An instant messenger solution that complies with the German data protection guidelines is needed and should be investigated in more detail. © 2022 by the authors.","Sayegh-Jodehl, Sabine and Mukowski-Kickhöfel, Rebecca and Linke, Diane and Müller-Birn, Claudia and Rose, Matthias",International Journal of Environmental Research and Public Health,,2022,10.3390/ijerph191912618,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139976639&doi=10.3390%2fijerph191912618&partnerID=40&md5=4a32a9efe61fc4cad500dd629c94a065,scopus.bib,2024-02-25 11:35:41,Unclassified
Kiuchi2023,"Psychological insights into the research and practice of embodied conversational agents, chatbots and social assistive robots: a systematic meta-review","This study presents a systematic literature search and narrative meta-review of the current state of research on conversational agents (CAs), including embodied CAs, chatbots, and social assistive robots (SARs). The investigation identifies 1,830 academic articles, of which 315 articles satisfied the inclusion criteria for the review. Systematic reviews across various fields are reported, including mental disorders, neurodevelopmental disorders, dementia/cognitive impairment, other medical conditions, elderly support, health promotion, mental health, education, industrial applications, agent characteristics, and robot characteristics. The study highlights challenges in current CA research, such as the scarcity of high-quality comparative studies and the acceptance of CAs by users and caregivers, particularly in elderly support. The article also categorises ethical discussions into nine elements: privacy, safety, innovation, user acceptance, psychological attachment, care philosophy, evaluation, social systems compatibility, and rule development. It also offers insights into the development of future guidelines. The role of CAs in fostering human relationships through their conversational function is emphasised to provide guidance for subsequent CA research and social implementation. As advancements in CA technology and research continue to progress, there is an increasing demand for sophisticated psychological investigations addressing relationships, emotions, and the self. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Kiuchi, Keita and Otsu, Kouyou and Hayashi, Yugo",Behaviour and Information Technology,,2023,10.1080/0144929X.2023.2286528,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178458126&doi=10.1080%2f0144929X.2023.2286528&partnerID=40&md5=f4775b9a3169affc79b02631e35bcfb1,scopus.bib,2024-02-25 11:35:41,Unclassified
Kopplin2022232,CHATBOTS IN THE WORKPLACE: A TECHNOLOGY ACCEPTANCE STUDY APPLYING USES AND GRATIFICATIONS IN COWORKING SPACES,"The uses and gratifications approach is used to examine chatbot acceptance in coworking spaces, identifying how coworkers perceive the technology and may use it to facilitate their tasks. To do so, potential influence factors shaping technology acceptance are explored, and a sample of 101 German coworkers is employed to confirm the framework drawing on a quantitative combination of partial least squares structural equation modeling and necessary condition analysis. Instrumental and non-instrumental gratifications, as well as social norm, influence chatbot acceptance in the form of sufficient and necessary conditions, and social norm appears to have a more substantial impact than hedonic factors in terms of sufficiency. However, social norm is not a necessary condition. A moderator analysis reveals that privacy concerns, age and gender do not affect individuals’ intention to use a chatbot. Coworking space providers thus benefit from establishing a standard chatbot solution to leverage social norm, and the chosen solution needs to fulfill hedonic expectations in addition to being useful. Software vendors may also integrate dedicated interfaces to powerful solutions such as ChatGPT. © 2023 Taylor & Francis Group, LLC.","Kopplin, Cristopher Siegfried",Journal of Organizational Computing and Electronic Commerce,,2022,10.1080/10919392.2023.2215666,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161562343&doi=10.1080%2f10919392.2023.2215666&partnerID=40&md5=9f04f1cd8875cb1c38046c238b69bc51,scopus.bib,2024-02-25 11:35:41,Unclassified
Goktas20232697,Artificial Intelligence Chatbots in Allergy and Immunology Practice: Where Have We Been and Where Are We Going?,"Artificial intelligence (AI) is rapidly becoming a valuable tool in healthcare, providing clinicians with a new AI lens perspective for patient care, diagnosis, and treatment. This article explores the potential applications, benefits, and challenges of AI chatbots in clinical settings, with a particular emphasis on ChatGPT 4.0 (OpenAI - Chat generative pretrained transformer 4.0), especially in the field of allergy and immunology. AI chatbots have shown considerable promise in various medical domains, including radiology and dermatology, by improving patient engagement, diagnostic accuracy, and personalized treatment plans. ChatGPT 4.0, developed by OpenAI, is good at understanding and replying to prompts in a way that makes sense. However, it is critical to address the potential biases, data privacy issues, ethical considerations, and the need for verification of AI-generated findings. When used responsibly, AI chatbots can significantly enhance clinical practice in allergy and immunology. However, there are still challenges in using this technology that require ongoing research and collaboration between AI developers and medical specialists. To this end, the ChatGPT 4.0 platform has the potential to enhance patient engagement, improve diagnostic accuracy, and provide personalized treatment plans in allergy and immunology practice. However, limitations and risks must be addressed to ensure their safe and effective use in clinical practice. © 2023 The Authors","Goktas, Polat and Karakaya, Gul and Kalyoncu, Ali Fuat and Damadoglu, Ebru",Journal of Allergy and Clinical Immunology: In Practice,,2023,10.1016/j.jaip.2023.05.042,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163359601&doi=10.1016%2fj.jaip.2023.05.042&partnerID=40&md5=fce2e8b92224cdb45e44351d927d1a27,scopus.bib,2024-02-25 11:35:41,Unclassified
Gallent-Iglesias202387,IVAMED: Intelligent Virtual Assistant for Medical Diagnosis,"The recent advancements in deep learning have led to a myriad of approaches for medical diagnosis and assistance. Some topics such as data labelling, data curation, human-in-the-loop, explainability or privacy-preserving methodologies are hot topics for applied machine learning in the healthcare context. In this domain, we normally expect a three-way interaction (doctor-system-patient), so that interfaces play a crucial role. Remotely managed VR (Virtual Reality) systems help us to enhance communication and feedback between doctors and patients in situations where in-person assistance is not feasible. Moreover, the recent breakthroughs with LLMs (Large Language Models) enable us to use natural language as additional interface, considering NLU (Natural Language Understanding) for intent recognition, ASR (Automatic Speech Recognition) and TTS (Text-To-Speech). In the context of the CEL.IA network, we present IVAMED (Intelligent Virtual Assistant for MEdical Diagnosis), a chatbot-oriented application in a VR environment for remote medical assistance. We tackle the situation in which face-to-face assistance is not possible. We provide the tools for remote interaction and guided diagnosis. We propose the evaluation of the MoCA (Montreal Cognitive Assessment) test for early detection of MCI (Mild Cognitive Impairment) and the BDI (Beck Depression Inventory) test for measuring characteristic attitudes and symptoms of depression.  © 2023 Copyright for this paper by its authors.","Gallent-Iglesias, Dana and Serantes-Raposo, Santiago and López-Riobóo-Botana, Iñigo and Gonzalez-Vázquez, Sonia and Fernandez-Graña, Pablo Manuel",CEUR Workshop Proceedings,,2023,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176449982&partnerID=40&md5=f13871392a1efa004ad463ee109f239f,scopus.bib,2024-02-25 11:35:41,Unclassified
Al-Shafei2024,Navigating Human-Chatbot Interactions: An Investigation into Factors Influencing User Satisfaction and Engagement,"With the increasing integration of chatbots in various customer service contexts, understanding factors that influence user interactions is of paramount importance. While chatbots bring several benefits, their efficacy largely depends on user satisfaction, loyalty, and perceived utility. This study explores the nuances of consumer interactions with chatbot services and identifies ways to enhance these interactions for successful goal achievement. Through a multiple qualitative method approach, involving reflections, interviews, and focus groups, conducted an exhaustive investigation of the consumer experiences with chatbot interactions. The study focused on elements such as anthropomorphism, communication styles, service scripts, consumer emotions, and privacy and trust concerns. Our findings highlight that the anthropomorphism and communication style of chatbots significantly affect user satisfaction. The perceived utility of chatbots was found to be a multifaceted construct that substantially influences consumer engagement. Furthermore, this study identified negative emotions and privacy concerns as key determinants of consumer-chatbot interactions. These findings necessitate meticulous attention in chatbot design and function. By using the affordance theory, this research offers insights into managing the complex dynamics of satisfaction and dissatisfaction factors within consumer-chatbot engagements, contributing crucially to the human-computer interaction literature. © 2024 The Author(s). Published with license by Taylor & Francis Group, LLC.","Al-Shafei, Mohamed",International Journal of Human-Computer Interaction,,2024,10.1080/10447318.2023.2301252,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182192946&doi=10.1080%2f10447318.2023.2301252&partnerID=40&md5=2118881e2e3d5634f7d449a663978fe2,scopus.bib,2024-02-25 11:35:41,Unclassified
Briganti20241565,How ChatGPT works: a mini review,"Objective: This paper offers a mini-review of OpenAI's language model, ChatGPT, detailing its mechanisms, applications in healthcare, and comparisons with other large language models (LLMs). Methods: The underlying technology of ChatGPT is outlined, focusing on its neural network architecture, training process, and the role of key elements such as input embedding, encoder, decoder, attention mechanism, and output projection. The advancements in GPT-4, including its capacity for internet connection and the integration of plugins for enhanced functionality are discussed. Results: ChatGPT can generate creative, coherent, and contextually relevant sentences, making it a valuable tool in healthcare for patient engagement, medical education, and clinical decision support. Yet, like other LLMs, it has limitations, including a lack of common sense knowledge, a propensity for hallucination of facts, a restricted context window, and potential privacy concerns. Conclusion: Despite the limitations, LLMs like ChatGPT offer transformative possibilities for healthcare. With ongoing research in model interpretability, common-sense reasoning, and handling of longer context windows, their potential is vast. It is crucial for healthcare professionals to remain informed about these technologies and consider their ethical integration into practice. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2023.","Briganti, Giovanni",European Archives of Oto-Rhino-Laryngology,,2024,10.1007/s00405-023-08337-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177560311&doi=10.1007%2fs00405-023-08337-7&partnerID=40&md5=82feeca8034a7ca063ec6a7b8fe4cf33,scopus.bib,2024-02-25 11:35:41,Unclassified
Xu20231113,Can ChatGPT Facilitate the Implementation of Personal Learning Environments in Tertiary Education: Benefits and Risks,"The integration of ChatGPT in Personal Learning Environments (PLEs) has emerged as a promising approach to personalized learning in tertiary education. ChatGPT is believed to have the potential to transform traditional higher education into a more personalized, quality-driven, and student-centered learning experience that fosters critical thinking, self-regulated learning, and creativity. While recent studies have highlighted the potential benefits of ChatGPT in enhancing personalized learning experiences, there are several risks and challenges that need to be addressed. This paper reviews relevant literature on ChatGPT and PLEs and identifies key risks and challenges associated with their integration, including ethical concerns, data privacy, technical issues, and user acceptance. Meanwhile, the paper also proposes ways and thoughts for the future implementation of ChatGPT in PLEs. The paper concludes that ChatGPT has significant potential to facilitate a new round of educational revolution which pushes educators to reconsider why to teach, how to teach, and what to teach. © 2023 Published by the ISTES Organization","Xu, XiaoShu and Wang, Xibing and Zhang, Yunfeng and Ma, Wenjuan",Proceedings of International Conference on Research in Education and Science,,2023,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184343527&partnerID=40&md5=e2b0d059dfb5a60e2b798c92886b0f12,scopus.bib,2024-02-25 11:35:41,Unclassified
Lappeman2023337,Trust and digital privacy: willingness to disclose personal information to banking chatbot services,"This study explored digital privacy concerns in the use of chatbots as a digital banking service. Three dimensions of trust were tested in relation to user self-disclosure in order to better understand the consumer-chatbot experience in banking. The methodology selected for this research study followed a conclusive, pre-experimental, two-group one-shot case study research design which made use of a non-probability snowballing sampling technique. Privacy concerns were found to have a significantly negative relationship with user self-disclosure in both treatment groups. Respondents exposed to their preferred banking brand experienced lower user self-disclosure and brand trust than those exposed to a fictitious banking brand within the South African context. It is recommended that companies using chatbots focus on easing privacy concerns and build foundations of trust. The gains that chatbots have made in the form of increased productivity and quality of customer service rely on relationships with users who need to disclose personal information. Through this study, we concluded that, despite its power to influence decision-making, the power of a brand is not enough for consumers to considerably increase self-disclosure. Rather, a bridge of trust (through education, communication and product development) is needed that encompasses all three elements of trust, which are brand trust, cognitive trust and emotional trust. Limited research exists on the relationship between financial services marketing and chatbot adoption. Thus, this study addressed a theoretical gap, by adding brand trust to existing studies on cognitive and emotional trust regarding user self-disclosure. © 2022, The Author(s), under exclusive licence to Springer Nature Limited.","Lappeman, James and Marlie, Siddeeqah and Johnson, Tamryn and Poggenpoel, Sloane",Journal of Financial Services Marketing,,2023,10.1057/s41264-022-00154-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128828206&doi=10.1057%2fs41264-022-00154-z&partnerID=40&md5=81143273edf753cda01ec6b7d8cb306e,scopus.bib,2024-02-25 11:35:41,Unclassified
Hendrickx2021373,Towards a New generation of Personalized Intelligent Conversational Agents,"The Personalized Intelligent Conversational Agents workshop focuses on both long-term engaging spoken dialogue systems and text-based chatbots, as well as conversational recommender systems. The goal of the workshop is to stimulate discussion around problems, challenges, possible solutions and research directions regarding the exploitation of natural language processing and machine learning techniques to learn user features and to use them to personalize the dialogue in the next generation of intelligent conversational agents.  © 2021 Owner/Author.","Hendrickx, Iris and Cena, Federica and Basar, Erkan and Di Caro, Luigi and Kunneman, Florian and Musi, Elena and Musto, Cataldo and Rapp, Amon and Van Waterschoot, Jelte","UMAP 2021 - Adjunct Publication of the 29th ACM Conference on User Modeling, Adaptation and Personalization",,2021,10.1145/3450614.3461453,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109218496&doi=10.1145%2f3450614.3461453&partnerID=40&md5=fa1895e100de96eb6ceb986363525c7c,scopus.bib,2024-02-25 11:35:41,Unclassified
Jose20221891,Latency Control for Keyword Spotting,"Conversational agents commonly utilize keyword spotting (KWS) to initiate voice interaction with the user. For user experience and privacy considerations, existing approaches to KWS largely focus on accuracy, which can often come at the expense of introduced latency. To address this tradeoff, we propose a novel approach to control KWS model latency and which generalizes to any loss function without explicit knowledge of the keyword endpoint. Through a single, tunable hyperparameter, our approach enables one to balance detection latency and accuracy for the targeted application. Empirically, we show that our approach gives superior performance under latency constraints when compared to existing methods. Namely, we make a substantial 25% relative false accepts improvement for a fixed latency target when compared to the baseline state-of-the-art. We also show that when our approach is used in conjunction with a max-pooling loss, we are able to improve relative false accepts by 25% at a fixed latency when compared to cross entropy loss. Copyright © 2022 ISCA.","Jose, Christin and Wang, Joseph and Strimel, Grant P. and Khursheed, Mohammad Omar and Mishchenko, Yuriy and Kulis, Brian","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",,2022,10.21437/Interspeech.2022-10608,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140059692&doi=10.21437%2fInterspeech.2022-10608&partnerID=40&md5=a307fb881cb744301d53b1be9edac0f4,scopus.bib,2024-02-25 11:35:41,Unclassified
Matulis20232808,"Relief in Sight? Chatbots, In-baskets, and the Overwhelmed Primary Care Clinician","The recent emergence of publically facing artificial intelligence (AI) chatbots has generated vigorous discussion in the lay public around the possibilities, liabilities, and uncertainties of the integration of such technology into everyday life. As primary care clinicians continue to struggle against ever-increasing loads of asynchronous, electronic work, the potential for AI to improve the quality and efficiency of this work looms large. In this essay, we discuss the basic premise of open-access AI chatbots such as CHATGPT, review prior applications of AI in healthcare, and preview some possible AI chatbot–assisted in-basket assistance including scenarios of communicating test results with patients, providing patient education, and clinical decision support in history taking, review of prior diagnostic test characteristics, and common management scenarios. We discuss important concerns related to the future adoption of this technology including the transparency of the training data used in developing these models, the level of oversight and trustworthiness of the information generated, and possible impacts on equity, bias, and patient privacy. A stepwise and balanced approach to simultaneously understand the capabilities and address the concerns associated with these tools will be needed before these tools can improve patient care. © 2023, The Author(s), under exclusive licence to Society of General Internal Medicine.","Matulis, John and McCoy, Rozalina",Journal of General Internal Medicine,,2023,10.1007/s11606-023-08271-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163659754&doi=10.1007%2fs11606-023-08271-8&partnerID=40&md5=446c992048766a3197cd81dee5ae7580,scopus.bib,2024-02-25 11:35:41,Unclassified
Guida2021,"Privacy policies between perception and learning through Legal Design: Ideas for an Educational Chatbot combining rights'awareness, optimized user experience and training efficacy","Legal Design is inspired by the concepts of Design Thinking and User Experience: the ultimate goal is to make citizens more aware with well-designed rules and procedures in terms of 'Proactive law', providing policies that are truly user-centered, tailored to the cognitive needs both expressed and hidden through continuous and transparent communication. Talking about privacy, there is a clear need, starting from the analysis of the texts of some documents (e.g.'information on the use of personal data' and 'consent'), to translate 'bureaucratic' requests into simpler questions, as to allow the more intuitive, usable and inclusive user experience. So, in the wake of the GDPR view too, we have been experimenting how the advantages of communicating and involving the citizens by design and by default can prove to be the right key so that the privacy documents they encounter in the everyday life can finally transmit transparency and a sense of control of the situation that are both much more substantial and immediately perceptible. The future developments of the project will be focused on enhancing access to safeguards for digital privacy, as well as citizens' awareness of their digital rights, a fortiori for the weakest subjects, with a chatbot providing personalized educational/assistance services. In the final stage I will be concepting a prototype of such an educational chatbot ranging between rights to be deployed, user experience to be exalted and training effectiveness to be ensured. © 2021 Copyright for this paper by its authors.","Guida, Sergio",CEUR Workshop Proceedings,,2021,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126392292&partnerID=40&md5=142fa04cbd4041cb5d8437e0df13b409,scopus.bib,2024-02-25 11:35:41,Unclassified
Talib2023173,Utilizing M-Technologies for AI-Driven Career Guidance in Morocco: An Innovative Mobile Approach,"In today's interconnected world, the significance of effective career guidance has been magnified. With the advent of mobile technologies, e-orientation and artificial intelligence (AI)-orientation systems offer a promising avenue for personalized career guidance. This paper delves into the potential of transitioning from traditional e-orientation to advanced AI-orientation systems in Morocco by employing large language models (LLMs) such as LLAMA2, GPT, and PaLM. These LLMs, renowned for their human-like text generation and contextual understanding, are proposed as the backbone for AI chatbots that can serve as virtual career counselors. Accessible via mobile platforms, these mobile chatbot interfaces can provide real-time insights on career paths, educational prerequisites, and job market dynamics and outlooks. Despite challenges such as Internet reliability, data privacy, and legislative regulations, the integration of AI-orientated systems into mobile platforms can revolutionize career guidance for Moroccan students. This paper presents a detailed roadmap and implementation for embedding these innovative technologies into Morocco's educational framework. © (2023) by the authors of this article. Published under CC-BY.","Talib, Abdelmoumen and Housni, Mohamed and Radid, Mohamed",International Journal of Interactive Mobile Technologies,,2023,10.3991/IJIM.V17I24.44263,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183846791&doi=10.3991%2fIJIM.V17I24.44263&partnerID=40&md5=ab34a9311e97cb6d3ca936cda1499390,scopus.bib,2024-02-25 11:35:41,Unclassified
Moore2024,Investigating the Potential of a Conversational Agent (Phyllis) to Support Adolescent Health and Overcome Barriers to Physical Activity: Co-Design Study,"Background: Conversational agents (CAs) are a promising solution to support people in improving physical activity (PA) behaviors. However, there is a lack of CAs targeted at adolescents that aim to provide support to overcome barriers to PA. This study reports the results of the co-design, development, and evaluation of a prototype CA called “Phyllis” to support adolescents in overcoming barriers to PA with the aim of improving PA behaviors. The study presents one of the first theory-driven CAs that use existing research, a theoretical framework, and a behavior change model. Objective: The aim of the study is to use a mixed methods approach to investigate the potential of a CA to support adolescents in overcoming barriers to PA and enhance their confidence and motivation to engage in PA. Methods: The methodology involved co-designing with 8 adolescents to create a relational and persuasive CA with a suitable persona and dialogue. The CA was evaluated to determine its acceptability, usability, and effectiveness, with 46 adolescents participating in the study via a web-based survey. Results: The co-design participants were students aged 11 to 13 years, with a sex distribution of 56% (5/9) female and 44% (4/9) male, representing diverse ethnic backgrounds. Participants reported 37 specific barriers to PA, and the most common barriers included a “lack of confidence,” “fear of failure,” and a “lack of motivation.” The CA’s persona, named “Phyllis,” was co-designed with input from the students, reflecting their preferences for a friendly, understanding, and intelligent personality. Users engaged in 61 conversations with Phyllis and reported a positive user experience, and 73% of them expressed a definite intention to use the fully functional CA in the future, with a net promoter score indicating a high likelihood of recommendation. Phyllis also performed well, being able to recognize a range of different barriers to PA. The CA’s persuasive capacity was evaluated in modules focusing on confidence and motivation, with a significant increase in students’ agreement in feeling confident and motivated to engage in PA after interacting with Phyllis. Adolescents also expect to have a personalized experience and be able to personalize all aspects of the CA. Conclusions: The results showed high acceptability and a positive user experience, indicating the CA’s potential. Promising outcomes were observed, with increasing confidence and motivation for PA. Further research and development are needed to create further interventions to address other barriers to PA and assess long-term behavior change. Addressing concerns regarding bias and privacy is crucial for achieving acceptability in the future. The CA’s potential extends to health care systems and multimodal support, providing valuable insights for designing digital health interventions including tackling global inactivity issues among adolescents. © 2024 JMIR Publications Inc.. All rights reserved.","Moore, Richard and Al-Tamimi, Abdel-Karim and Freeman, Elizabeth",JMIR Formative Research,,2024,10.2196/51571,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184870579&doi=10.2196%2f51571&partnerID=40&md5=2bc060c5e8d0c282dd2ed8119507c29c,scopus.bib,2024-02-25 11:35:41,Unclassified
Hasal2021,"Chatbots: Security, privacy, data protection, and social aspects","Chatbots are artificial communication systems becoming increasingly popular and not all their security questions are clearly solved. People use chatbots for assistance in shopping, bank communication, meal delivery, healthcare, cars, and many other actions. However, it brings an additional security risk and creates serious security challenges which have to be handled. Understanding the underlying problems requires defining the crucial steps in the techniques used to design chatbots related to security. There are many factors increasing security threats and vulnerabilities. All of them are comprehensively studied, and security practices to decrease security weaknesses are presented. Modern chatbots are no longer rule-based models, but they employ modern natural language and machine learning techniques. Such techniques learn from a conversation, which can contain personal information. The paper discusses circumstances under which such data can be used and how chatbots treat them. Many chatbots operate on a social/messaging platform, which has their terms and conditions about data. The paper aims to present a comprehensive study of security aspects in communication with chatbots. The article could open a discussion and highlight the problems of data storage and usage obtained from the communication user—chatbot and propose some standards to protect the user. © 2021 The Authors. Concurrency and Computation: Practice and Experience published by John Wiley & Sons Ltd.","Hasal, Martin and Nowaková, Jana and Ahmed Saghair, Khalifa and Abdulla, Hussam and Snášel, Václav and Ogiela, Lidia",Concurrency and Computation: Practice and Experience,,2021,10.1002/cpe.6426,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107027640&doi=10.1002%2fcpe.6426&partnerID=40&md5=37385e4313531804f13c98d4d46cea2a,scopus.bib,2024-02-25 11:35:41,Unclassified
Kazim2021,Systematizing audit in algorithmic recruitment,"Business psychologists study and assess relevant individual differences, such as intelligence and personality, in the context of work. Such studies have informed the development of artificial intelligence systems (AI) designed to measure individual differences. This has been capitalized on by companies who have developed AI-driven recruitment solutions that include aggregation of appropriate candidates (Hiretual), interviewing through a chatbot (Paradox), video interview assessment (MyInterview), and CV-analysis (Textio), as well as estimation of psychometric characteristics through image-(Traitify) and game-based assessments (HireVue) and video interviews (Cammio). However, driven by concern that such high-impact technology must be used responsibly due to the potential for unfair hiring to result from the algorithms used by these tools, there is an active effort towards proving mechanisms of governance for such automation. In this article, we apply a systematic algorithm audit framework in the context of the ethically critical industry of algorithmic recruitment systems, exploring how audit assessments on AI-driven systems can be used to assure that such systems are being responsibly deployed in a fair and well-governed manner. We outline sources of risk for the use of algorithmic hiring tools, suggest the most appropriate opportunities for audits to take place, recommend ways to measure bias in algorithms, and discuss the transparency of algorithms. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Kazim, Emre and Koshiyama, Adriano Soares and Hilliard, Airlie and Polle, Roseline",Journal of Intelligence,,2021,10.3390/jintelligence9030046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115781934&doi=10.3390%2fjintelligence9030046&partnerID=40&md5=6e5fff246bbd335a925680dc300655c5,scopus.bib,2024-02-25 11:35:41,Unclassified
Seckelmann20231,Artificial intelligence in administration: The draft of a European AI Regulation and the handling of information technology risks; [KüNSTLICHE INTELLIGENZ IN DER VERWALTUNG Der Entwurf einer europäischen KI-Verordnung und der Umgang mit informationstechnischen Risiken],"Applications of artificially intelligent systems have recently enjoyed increasing popularity, as demonstrated in particular by the presentation of the chatbot ""ChatGPT"" by the AI research company OpenAI. ChatGPT also demonstrates the potential of AI more generally: Such applications can already be used by private individuals, for example to get support in writing exams or theses, and it seems likely that one day similar AI systems, such as chatbots, could also be used in public administration. This does, nevertheless raise some questions in the public administrative sector: predictive decisions, involving the need for careful risk evaluation, are not new to German administrative law, as is apparent from fields like atomic energy law. Still, it is questionable how far the administration should entrust such procedures of probabilistic risk analysis to AI applications and to what extent this could be legally acceptable? The analysis in this paper is devoted to answering this question. Part II begins by clarifying some of the key concepts underpinning the notion of artificial intelligence, including 'digitalisation', 'algorithms', 'big data analytics' and 'machine learning'. The different (supervised and unsupervised) methods of machine learning are considered, as are their modes of operation and selected problems they raise, such as the possibility of bias and lack of transparency and comprehensibility. Part III then examines in detail the European Commission's draft regulation on AI (Proposal for a Regulation of the European Parliament and of the Council laying down harmonised Rules on Artificial Intelligence (Artificial Intelligence Act), COM(2021) 206 final, 2021/0106 (COD)). This legislative initiative pursues in particular the goal of regulating AI applications and harmonising the regulations on them across the Union. The regulatory scope as well as the area of application and the contents of the draft AI regulation are first shown and possible deficits are discussed. A problematic aspect is the systematic relationship of the draft regulation to other existing EU regulatory acts, such as the General Data Protection Regulation and its Art. 22 GDPR. Following on from the discussion of these problematic aspects, Part IV presents the current draft status of the AI Regulation as well as analysing the (critical) reaction, especially of the Federal Republic of Germany, to the same. PartVconcludes by assessing the implications of the above for use of AI systems in the German public administration, and provides a final evaluation of the draft AI regulation in the latter context. A key issue remains how far it is acceptable for AI-predictions, based on the behavior of a class of persons, to be applied to individual citizens. © 2023 Duncker und Humblot GmbH. All rights reserved.","Seckelmann, Margrit",Verwaltung,,2023,10.3790/verw.56.1.1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173910054&doi=10.3790%2fverw.56.1.1&partnerID=40&md5=c7b18d8d6434889dcd288cb670ea6e43,scopus.bib,2024-02-25 11:35:41,Unclassified
Dwivedi2023,"“So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy","Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts. © 2023 The Authors","Dwivedi, Yogesh K. and Kshetri, Nir and Hughes, Laurie and Slade, Emma Louise and Jeyaraj, Anand and Kar, Arpan Kumar and Baabdullah, Abdullah M. and Koohang, Alex and Raghavan, Vishnupriya and Ahuja, Manju and Albanna, Hanaa and Albashrawi, Mousa Ahmad and Al-Busaidi, Adil S. and Balakrishnan, Janarthanan and Barlette, Yves and Basu, Sriparna and Bose, Indranil and Brooks, Laurence and Buhalis, Dimitrios and Carter, Lemuria and Chowdhury, Soumyadeb and Crick, Tom and Cunningham, Scott W. and Davies, Gareth H. and Davison, Robert M. and Dé, Rahul and Dennehy, Denis and Duan, Yanqing and Dubey, Rameshwar and Dwivedi, Rohita and Edwards, John S. and Flavián, Carlos and Gauld, Robin and Grover, Varun and Hu, Mei-Chih and Janssen, Marijn and Jones, Paul and Junglas, Iris and Khorana, Sangeeta and Kraus, Sascha and Larsen, Kai R. and Latreille, Paul and Laumer, Sven and Malik, F. Tegwen and Mardani, Abbas and Mariani, Marcello and Mithas, Sunil and Mogaji, Emmanuel and Nord, Jeretta Horn and O'Connor, Siobhan and Okumus, Fevzi and Pagani, Margherita and Pandey, Neeraj and Papagiannidis, Savvas and Pappas, Ilias O. and Pathak, Nishith and Pries-Heje, Jan and Raman, Ramakrishnan and Rana, Nripendra P. and Rehm, Sven-Volker and Ribeiro-Navarrete, Samuel and Richter, Alexander and Rowe, Frantz and Sarker, Suprateek and Stahl, Bernd Carsten and Tiwari, Manoj Kumar and van der Aalst, Wil and Venkatesh, Viswanath and Viglia, Giampaolo and Wade, Michael and Walton, Paul and Wirtz, Jochen and Wright, Ryan",International Journal of Information Management,,2023,10.1016/j.ijinfomgt.2023.102642,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149886538&doi=10.1016%2fj.ijinfomgt.2023.102642&partnerID=40&md5=07a92f9d615bd212010a31ca0fe70bec,scopus.bib,2024-02-25 11:35:41,Unclassified
Adam2023,From web forms to chatbots: The roles of consistency and reciprocity for user information disclosure,"Interactive decision aids (IDAs) on websites often require users to disclose relevant information (e.g., preferences, contact information) to help users in making decisions (e.g., product choice). With technological advances in IDAs, websites increasingly switch from static, non-conversational IDAs (e.g., web forms) to conversational ones (e.g., chatbots) to boost user information disclosure that nurtures the websites' economic viability. While this novel form of IDAs is already widely employed in practice, information systems research has yet to examine the defining dialogue design features of conversational IDAs and their effects on eliciting user information. Drawing on persuasion theory and particularly on consistency and reciprocity as influence techniques, we develop a research model around two crucial dialogue design features of conversational IDAs. Specifically, we investigate the distinct and joint effects of conversational style (i.e., absence vs. presence of a conversational presentation of requests) and reciprocation triggers (i.e., absence vs. presence of reciprocity-inducing information) on user information disclosure (i.e., email addresses). By combining the complementary properties of a randomised field experiment (N = 386) and a follow-up online experiment (N = 182), we empirically provide evidence in support of the distinct and joint effects of conversational style and reciprocation triggers of IDAs on user information disclosure. Moreover, we demonstrate that these dialogue design features have indirect effects on information disclosure via perceptions of social presence and privacy concerns. Thus, our paper provides theoretical and practical insights into whether, how, and why critical IDA dialogue design features can better elicit user information for website services. © 2023 The Authors. Information Systems Journal published by John Wiley & Sons Ltd.","Adam, Martin and Benlian, Alexander",Information Systems Journal,,2023,10.1111/isj.12490,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178177566&doi=10.1111%2fisj.12490&partnerID=40&md5=e1abcec22f828125b1e4dee85a672c70,scopus.bib,2024-02-25 11:35:41,Unclassified
Semnani20232387,WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia,"This paper presents the first few-shot LLM-based chatbot that almost never hallucinates and has high conversationality and low latency. WikiChat is grounded on the English Wikipedia, the largest curated free-text corpus. WikiChat generates a response from an LLM, retains only the grounded facts, and combines them with additional information it retrieves from the corpus to form factual and engaging responses. We distill WikiChat based on GPT-4 into a 7B-parameter LLaMA model with minimal loss of quality, to significantly improve its latency, cost and privacy, and facilitate research and deployment. Using a novel hybrid human-and-LLM evaluation methodology, we show that our best system achieves 97.3% factual accuracy in simulated conversations. It significantly outperforms all retrieval-based and LLM-based baselines, and by 3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4. Compared to previous state-of-the-art retrieval-based chatbots, WikiChat is also significantly more informative and engaging, just like an LLM. WikiChat achieves 97.9% factual accuracy in conversations with human users about recent topics, 55.0% better than GPT-4, while receiving significantly higher user ratings and more favorable comments. © 2023 Association for Computational Linguistics.","Semnani, Sina J. and Yao, Violet Z. and Zhang, Heidi C. and Lam, Monica S.",Findings of the Association for Computational Linguistics: EMNLP 2023,,2023,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178631676&partnerID=40&md5=fd9d856f7fc450df8af8af07e5804e77,scopus.bib,2024-02-25 11:35:41,Unclassified
Song2022,Should the chatbot “save itself” or “be helped by others”? The influence of service recovery types on consumer perceptions of recovery satisfaction,"The application of artificial intelligence is considered essential to adapt to a new cycle of industrial transformation and technological advancements in many fields and industries. The extensive use of artificial intelligence technology is expected to improve the level and quality of services provided by companies adopting these methods. In this study, we propose a novel approach to self-recovery by chatbot systems after service failures based on social response theory. Moreover, we explore differences in consumer perceptions of different service recovery types and their impact on recovery satisfaction, and discusses whether the intelligence of the computational agent also has an effect. We present the results of three scenario-based experiments, which demonstrate the positive effect of chatbot self-recovery on consumer satisfaction, and show the mediating paths of service recovery types in terms of perceived functional value and privacy risks as well as the boundary condition of the level of robot intelligence. This work expands the range of applications of chatbots in the service industry and provides a new framework for the governance of artificial intelligence. © 2022 Elsevier B.V.","Song, Mengmeng and Du, Jingzhe and Xing, Xinyu and Mou, Jian",Electronic Commerce Research and Applications,,2022,10.1016/j.elerap.2022.101199,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138060925&doi=10.1016%2fj.elerap.2022.101199&partnerID=40&md5=2bdc113abb59c10118799e383b809033,scopus.bib,2024-02-25 11:35:41,Unclassified
Bosse2015650,Integrating conversation trees and cognitive models within an ECA for aggression de-escalation training,"Traditionally, Embodied Conversational Agents communicate with humans using dialogue systems based on conversation trees. To enhance the flexibility and variability of dialogues, this paper proposes an approach to integrate conversation trees with cognitive models. The approach is illustrated by a case study in the domain of aggression de-escalation training, and a preliminary evaluation in the context of a practical application is presented. © Springer International Publishing Switzerland 2015.","Bosse, Tibor and Provoost, Simon",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2015,10.1007/978-3-319-25524-8_48,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950336129&doi=10.1007%2f978-3-319-25524-8_48&partnerID=40&md5=e289e5b528b5a1db01513dffee4ac153,scopus.bib,2024-02-25 11:35:41,Unclassified
Luria2020,Social Boundaries for Personal Agents in the Interpersonal Space of the Home,"The presence of voice activated personal assistants (VAPAs) in people's homes rises each year [31]. Industry efforts are invested in making interactions with VAPAs more personal by leveraging information from messages and calendars, and by accessing user accounts for 3rd party services. However, the use of personal data becomes more complicated in interpersonal spaces, such as people's homes. Should a shared agent access the information of many users? If it does, how should it navigate issues of privacy and control? Designers currently lack guidelines to help them design appropriate agent behaviors. We used Speed Dating to explore inchoate social mores around agent actions within a home, including issues of proactivity, interpersonal conflict, and agent prevarication. Findings offer new insights on how more socially sophisticated agents might sense, make judgements about, and navigate social roles and individuals. We discuss how our findings might impact future research and future agent behaviors. © 2020 Owner/Author.","Luria, Michal and Zheng, Rebecca and Huffman, Bennett and Huang, Shuangni and Zimmerman, John and Forlizzi, Jodi",Conference on Human Factors in Computing Systems - Proceedings,,2020,10.1145/3313831.3376311,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090149393&doi=10.1145%2f3313831.3376311&partnerID=40&md5=1242778052df38657f5c08e3145f042b,scopus.bib,2024-02-25 11:35:41,Unclassified
Bahja202032,A User-Centric Framework for Educational Chatbots Design and Development,"Increasing frequency of epidemics, such as SARS-CoV, MERS-CoV, Ebola, and the recent COVID-19, have affected various sectors, especially education. As a result, emphasis on e-learning and distance learning has been increasing in recent years. The growing numbers of mobile users and access to the internet across the world has created more favorable conditions for adopting distance learning on a wider scale. However, lessons learnt from current experiments have highlighted poor student engagement with learning processes, hence a user-centric approach to design and develop educational chatbots is presented. A User-centric approach enables developers to consider the following: learners’ and teachers’ technological skills and competencies, attitudes, and perceptions and behaviour; conceptual concerns, such as pedagogical integration on online platforms, assessment procedures, varying learning culture and lifestyles; technical concerns, such as privacy, security, performance, ubiquity; and regulatory concerns, such as policies, frameworks, standards, ethics, roles and responsibilities have been identified in this study. To address these concerns, there is the need for user-centric design and collaborative approaches to the development of distance learning tools. Considering the abovementioned challenges and the growing emphasis on distance learning, we propose chatbot learning as an effective and efficient tool for delivering such learning. In this regard, a user-centric framework for designing chatbot learning applications and a collaborative user-centric design methodology for developing chatbot learning applications is proposed and discussed. © 2020, Springer Nature Switzerland AG.","Bahja, Mohammed and Hammad, Rawad and Butt, Gibran",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2020,10.1007/978-3-030-60117-1_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094133150&doi=10.1007%2f978-3-030-60117-1_3&partnerID=40&md5=4baee2d8c75b50a1f03bcff28e812b66,scopus.bib,2024-02-25 11:35:41,Unclassified
Sannon2020,“I just shared your responses”: Extending communication privacy management theory to interactions with conversational agents,"Conversational agents are increasingly becoming integrated into everyday technologies and can collect large amounts of data about users. As these agents mimic interpersonal interactions, we draw on communication privacy management theory to explore people's privacy expectations with conversational agents. We conducted a 3x3 factorial experiment in which we manipulated agents' social interactivity and data sharing practices to understand how these factors influence people's judgments about potential privacy violations and their evaluations of agents. Participants perceived agents that shared response data with advertisers more negatively compared to agents that shared such data with only their companies; perceptions of privacy violations did not differ between agents that shared data with their companies and agents that did not share information at all. Participants also perceived the socially interactive agent's sharing practices less negatively than those of the other agents, highlighting a potential privacy vulnerability that users are exposed to in interactions with socially interactive conversational agents. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Sannon, Shruti and Stoll, Brett and Difranzo, Dominic and Jung, Malte F. and Bazarova, Natalya N.",Proceedings of the ACM on Human-Computer Interaction,,2020,10.1145/3375188,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077779524&doi=10.1145%2f3375188&partnerID=40&md5=d2fb1e1b5b052270bcdb66dd4fb50664,scopus.bib,2024-02-25 11:35:41,Unclassified
Roussou2019,Transformation through provocation? Designing a ‘bot of conviction’ to challenge conceptions and evoke critical reflection,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically “minimal” medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a “bot of conviction”, aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely. © 2019 Association for Computing Machinery.","Roussou, Maria and Perry, Sara and Katifori, Akrivi and Vassos, Stavros and Tzouganatou, Angeliki and McKinney, Sierra",Conference on Human Factors in Computing Systems - Proceedings,,2019,10.1145/3290605.3300857,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067615313&doi=10.1145%2f3290605.3300857&partnerID=40&md5=ab8c04e96ab8576470a51ac574b70571,scopus.bib,2024-02-25 11:35:41,Unclassified
Väänänen2020143,CivicBots – Chatbots for Supporting Youth in Societal Participation,"Supporting young people to participate in societal development is an important factor in achieving sustainable future. Digital solutions can be designed to help youth participate in civic activities, such as city planning and legislation. To this end, we are using human-centered approach to study how digital tools can help youth discuss their ideas on various societal issues. Chatbots are conversational agents that have potential to trigger and support thought processes, as well as online activities. In this context, we are exploring how chatbots – which we call CivicBots – can be used to support youth (16–27 years) in societal participation. We created three scenarios for CivicBots and evaluated them with the youth in an online survey (N = 54). Positive perceptions of the youth concerning CivicBots suggest that CivicBots can advance equality and they may be able to reach youth better than a real person. On the negative side, CivicBots may cause unpleasant interactions by their over-proactive behaviour, and trustworthiness is affected by fears that the bot does not respect user’s privacy, or that it provides biased or limited information about societally important issues. © 2020, Springer Nature Switzerland AG.","Väänänen, Kaisa and Hiltunen, Aleksi and Varsaluoma, Jari and Pietilä, Iikka",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2020,10.1007/978-3-030-39540-7_10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079104131&doi=10.1007%2f978-3-030-39540-7_10&partnerID=40&md5=a770f9d26fa2addfbd3490441f0c2682,scopus.bib,2024-02-25 11:35:41,Unclassified
Prakash20201,Intelligent Conversational Agents in Mental Healthcare Services: A Thematic Analysis of User Perceptions,"Background: The emerging Artificial Intelligence (AI) based Conversational Agents (CA) capable of delivering evidence-based psychotherapy presents a unique opportunity to solve longstanding issues such as social stigma and demand-supply imbalance associated with traditional mental health care services. However, the emerging literature points to several socio-ethical challenges which may act as inhibitors to the adoption in the minds of the consumers. We also observe a paucity of research focusing on determinants of adoption and use of AI-based CAs in mental healthcare. In this setting, this study aims to understand the factors influencing the adoption and use of Intelligent CAs in mental healthcare by examining the perceptions of actual users. Method: The study followed a qualitative approach based on netnography and used a rigorous iterative thematic analysis of publicly available user reviews of popular mental health chatbots to develop a comprehensive framework of factors influencing the user’s decision to adopt mental healthcare CA. Results: We developed a comprehensive thematic map comprising of four main themes, namely, perceived risk, perceived benefits, trust, and perceived anthropomorphism, along with its 12 constituent subthemes that provides a visualization of the factors that govern the user’s adoption and use of mental healthcare CA. Conclusions: Insights from our research could guide future research on mental healthcare CA use behavior. Additionally, it could also aid designers in framing better design decisions that meet consumer expectations. Our research could also guide healthcare policymakers and regulators in integrating this technology into formal healthcare delivery systems. © 2020, Association for Information Systems. All rights reserved.","Prakash, Ashish Viswanath and Das, Saini",Pacific Asia Journal of the Association for Information Systems,,2020,10.17705/1pais.12201,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169025731&doi=10.17705%2f1pais.12201&partnerID=40&md5=2913c14d435b4efbea71c4a8a20e1cb0,scopus.bib,2024-02-25 11:35:41,Unclassified
Patil20194296,Artificial intelligence in financial services: Customer chatbot advisor adoption,"The growing sophistication technology has helped us exchange Information at our fingertips, eliminating the need for human support.” A platform designed to understand, learn and converse like a human and answer ad-hoc queries in real time is commonly referred to as a Chabot”. Chabot advisor is Artificial intelligence (AI) computer program that impersonates human communication in its natural format including text or spoken language using a technique such as NLP, image processing or video processing along with the end task completion as instructed by the user [1]. The purpose of the paper was to examine what are the drivers for Chabot advisor services adoption (CBA), focusing on financial services. This study presents the explanatory Chabot advisor services factors by extending the Technology Acceptance Model (TAM). The construct in the research are like perceived privacy, perceived security, enjoyment and social influence. This empirical study was conducted in Pune city in India by collecting primary data from 310 online financial services customers. Data collected was analyzed using structural equation modeling using PLS-SEM.The outcome of this study is vital to financial companies like banks, policymakers, technology services adoption literature and provide customer-centric financial services. ©BEIESP.","Patil, Kanchan and Kulkarni, Mugdha S.",International Journal of Innovative Technology and Exploring Engineering,,2019,10.35940/ijitee.A4928.119119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075213653&doi=10.35940%2fijitee.A4928.119119&partnerID=40&md5=8b1ee635f387a124edf722635a5757f1,scopus.bib,2024-02-25 11:35:41,Unclassified
Uohara2020361,The Essential Role of Technology in the Public Health Battle against COVID-19,"Technology has played an important role in responding to the novel coronavirus (SARS-CoV-2) and subsequent COVID-19 pandemic. The virus's blend of lethality and transmissibility have challenged officials and exposed critical limitations of the traditional public health apparatus. However, throughout this pandemic, technology has answered the call for a new form of public health that illustrates opportunities for enhanced agility, scale, and responsiveness. The authors share the Microsoft perspective and illustrate how technology has helped transform the public health landscape with new and refined capabilities - the efficacy and impact of which will be determined by history. Technologies like chatbot and virtualized patient care offer a mechanism to triage and distribute care at scale. Artificial intelligence and high-performance computing have accelerated research into understanding the virus and developing targeted therapeutics to treat infection and prevent transmission. New mobile contact tracing protocols that preserve patient privacy and civil liberties were developed in response to public concerns, creating new opportunities for privacy-sensitive technologies that aid efforts to prevent and control outbreaks. While much progress is still needed, the COVID-19 pandemic has highlighted technology's importance to public health security and pandemic preparedness. Future multi-stakeholder collaborations, including those with technology organizations, are needed to facilitate progress in overcoming the current pandemic, setting the stage for improved pandemic preparedness in the future. As lessons are assessed from the current pandemic, public officials should consider technology's role and continue to seek opportunities to supplement and improve on traditional approaches.  © Copyright 2020, Mary Ann Liebert, Inc.","Uohara, Michael Y. and Weinstein, James N. and Rhew, David C.",Population Health Management,,2020,10.1089/pop.2020.0187,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092681418&doi=10.1089%2fpop.2020.0187&partnerID=40&md5=44c125a84afaf99472ea7a6955252991,scopus.bib,2024-02-25 11:35:41,Unclassified
Gulenko20147,Chatbot for IT security training: Using motivational interviewing to improve security behaviour,"We conduct a pre-study with 25 participants on Mechanical Turk to find out which security behavioural problems are most important for online users. These questions are based on motivational interviewing (MI), an evidence-based treatment methodology that enables to train people about different kinds of behavioural changes. Based on that the chatbot is developed using Artificial Intelligence Markup Language (AIML). The chatbot is trained to speak about three topics: passwords, privacy and secure browsing. These three topics were 'most-wanted' by the users of the pre-study. With the chatbot three training sessions with people are conducted.","Gulenko, Iwan",CEUR Workshop Proceedings,,2014,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925244807&partnerID=40&md5=7e7b543484f443c7b00628529aea2784,scopus.bib,2024-02-25 11:35:41,Unclassified
Bahja202020,An Antenatal Care Awareness Prototype Chatbot Application Using a User-Centric Design Approach,"The frequency of occurrence of severe infectious diseases, such as SARS-CoV, MERS-CoV, Ebola and COVID-19, has been increasing in recent years, thus putting pressure on the delivery of healthcare services. Pregnant women are some of the most vulnerable patients, as they are more prone to infections and have limited mobility due to their health situation. In addition, preventive measures, such as social distancing and lockdowns have affected their access to healthcare services. Considering these issues, in this study, a prototype chatbot application that can provide antenatal care and support for pregnant women from the comfort of their home is proposed. A user-centric design methodology was adopted, where two midwives, one obstetrician and eleven pregnant women participated in the design and development process by providing regular reviews at various stages of the process. In addition, an online User Experience Questionnaire was employed for collecting the users’ experiences after engaging with the protype application for two weeks. The findings reveal that the proposed chatbot application (Alia) is effective in terms of attractiveness, perspicuity, efficiency, stimulation, and novelty. In addition, concerns related to dependability (privacy and security) and supportability were identified. Finally, UEQ scales of pragmatic quality (1.12) and hedonic quality (1.11) related to the chatbot application Alia, reflected good usability, reliability and quality aspects. © 2020, Springer Nature Switzerland AG.","Bahja, Mohammed and Abuhwaila, Nour and Bahja, Julia",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2020,10.1007/978-3-030-60117-1_2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094113713&doi=10.1007%2f978-3-030-60117-1_2&partnerID=40&md5=1593f2dc3e36fb4c2ea7b1167c339c38,scopus.bib,2024-02-25 11:35:41,Unclassified
Rese2020,Chatbots in retailers’ customer communication: How to measure their acceptance?,"Currently, online retailers evaluate whether chatbots—software programs that interact with users using natural languages—could improve their customers' satisfaction. In a retail context, chatbots allow humans to pose shopping-related questions and receive answers in natural language without waiting for a salesperson or using other automated communication forms. However, until now, it has been unclear which customers accept this new communication form and which factors determine their acceptance. In this paper, we contrast the well-known technology acceptance model (TAM) with the lesser known uses and gratifications (U&G) theory, applying both approaches to measure the acceptance of the text-based “Emma” chatbot by its target segment. “Emma” was developed for the prepurchase phase of online fashion retailing and integrated into Facebook Messenger by the major German online retailer Zalando. Data were collected from 205 German Millennial respondents in a usability study. The results show that both utilitarian factors such as “authenticity of conversation” and “perceived usefulness,” as well as hedonic factors such as “perceived enjoyment”, positively influence the acceptance of “Emma”. However, privacy concerns and the immaturity of the technology had a negative effect on usage intention and frequency. The predictive power of both models was similar, showing little deviation, but U&G gives alternative insights into the customers’ motivation to use “Emma” compared to the TAM. © 2020 Elsevier Ltd","Rese, Alexandra and Ganster, Lena and Baier, Daniel",Journal of Retailing and Consumer Services,,2020,10.1016/j.jretconser.2020.102176,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086591217&doi=10.1016%2fj.jretconser.2020.102176&partnerID=40&md5=af3c9259879f038ff2aed735cd169d1c,scopus.bib,2024-02-25 11:35:41,Unclassified
AlGosaibi2020260,Developing an intelligent framework for improving the quality of service in the government organizations in the Kingdom of Saudi Arabia,"—The Kingdom of Saudi Arabia is enhancing the services and applications in government organizations through the number of systems that generate a massive amount of data through Big Data technology. Recently, the Global Artificial Intelligent Summit 2020, Saudi Data and Artificial Intelligence Authority (SDAIA), NEOM have launched an Artificial Intelligence (AI) strategy that aligns with the Kingdom Vision 2030. AI opens a wide door for opportunities and new strategies that will narrow the gap in the skillset of individuals and promote research and innovation in the IT industry. Organizations lack advanced techniques to evaluate the performance of individuals and departments that supports improving the quality of service. The introduction of AI-based applications in the government and private sectors will facilitate decision-makers in tracking and optimizing the efficiency of departments and individuals. This research aims to develop an intelligent framework for government organizations to improve the quality of services rendered to customers and businesses. In addition, it highlights the importance of AI policies in archiving metadata. This paper presents a framework for an organization that contains Chatbot, Sentiment Analysis, and Key Performance Indicators to improve the services. A synthetic dataset is employed as a testbed to evaluate the performance of the framework. The outcome of this study shows that the proposed framework able to improve the performance of organizations. Using this proposed framework, organizations can build a mechanism for their workforce to retrieve meaningful information. Moreover, it provides significant features include efficient data extraction, data management, and AI-based security for effective document management. © 2020 Science and Information Organization. All rights reserved.","AlGosaibi, Abdulelah Abdallah and Sait, Abdul Rahaman Wahab and AlOthman, Abdulaziz Fahad and AlHamed, Shadan",International Journal of Advanced Computer Science and Applications,,2020,10.14569/IJACSA.2020.0111233,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101461712&doi=10.14569%2fIJACSA.2020.0111233&partnerID=40&md5=09f20888f6e6b5720dd3b91bef263b5c,scopus.bib,2024-02-25 11:35:41,Unclassified
Chi2017542,Pilot testing a digital pet avatar for older adults,"Social isolation in older adults is a major public health concern. An embodied conversational agent (ECA) has the potential to enhance older adults’ social interaction. However, little is known about older adults’ experience with an ECA. In this paper, we conducted a pilot study to examine the perceived acceptance and utility of a tablet-based conversational agent in the form of an avatar (termed “digital pet”) for older adults. We performed secondary analysis of data collected from a study that employed the use of a digital pet in ten older adults’ homes for three months. Most of the participants enjoyed the companionship, entertainment, reminders, and instant assistance from the digital pet. However, participants identified limited conversational ability and technical issues as system challenges. Privacy, dependence, and cost were major concerns. Future applications should maximize the agent's conversational ability and the system's overall usability. Our results can inform future designs of conversational agents for older adults, which need to include older adults as system co-designers to maximize usability and acceptance. © 2017 Elsevier Inc.","Chi, Nai-Ching and Sparks, Olivia and Lin, Shih-Yin and Lazar, Amanda and Thompson, Hilaire J. and Demiris, George",Geriatric Nursing,,2017,10.1016/j.gerinurse.2017.04.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018939180&doi=10.1016%2fj.gerinurse.2017.04.002&partnerID=40&md5=d3de5b51a279b2be8fdcafec5ca81f5b,scopus.bib,2024-02-25 11:35:41,Unclassified
Thomaz202043,Learning from the Dark Web: leveraging conversational agents in the era of hyper-privacy to enhance marketing,"The Web is a constantly evolving, complex system, with important implications for both marketers and consumers. In this paper, we contend that over the next five to ten years society will see a shift in the nature of the Web, as consumers, firms and regulators become increasingly concerned about privacy. In particular, we predict that, as a result of this privacy-focus, various information sharing and protection practices currently found on the Dark Web will be increasingly adapted in the overall Web, and in the process, firms will lose much of their ability to fuel a modern marketing machinery that relies on abundant, rich, and timely consumer data. In this type of controlled information-sharing environment, we foresee the emersion of two distinct types of consumers: (1) those generally willing to share their information with marketers (Buffs), and (2) those who generally deny access to their personal information (Ghosts). We argue that one way marketers can navigate this new environment is by effectively designing and deploying conversational agents (CAs), often referred to as “chatbots.” In particular, we propose that CAs may be used to understand and engage both types of consumers, while providing personalization, and serving both as a form of differentiation and as an important strategic asset for the firm—one capable of eliciting self-disclosure of otherwise private consumer information. © 2019, The Author(s).","Thomaz, Felipe and Salge, Carolina and Karahanna, Elena and Hulland, John",Journal of the Academy of Marketing Science,,2020,10.1007/s11747-019-00704-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075185738&doi=10.1007%2fs11747-019-00704-3&partnerID=40&md5=4e93fed65a8f584a08f0ed5fdb7198ab,scopus.bib,2024-02-25 11:35:41,Unclassified
Williams2020314,From WOM to aWOM – the evolution of unpaid influence: a perspective article,"Purpose: Advances in artificial intelligence (AI) natural language processing may see the emergence of algorithmic word of mouth (aWOM), content created and shared by automated tools. As AI tools improve, aWOM will increase in volume and sophistication, displacing eWOM as an influence on customer decision-making. The purpose of this paper is to provide an overview of the socio technological trends that have encouraged the evolution of informal infulence strategies from WOM to aWOM. Design/methodology/approach: This paper examines the origins and path of development of influential customer communications from word of mouth (WOM) to electronic word of mouth (eWOM) and the emerging trend of aWOM. The growth of aWOM is theorized as a result of new developments in AI natural language processing tools along with autonomous distribution systems in the form of software robots and virtual assistants. Findings: aWOM may become a dominant source of information for tourists, as it can support multimodal delivery of useful contextual information. Individuals, organizations and social media platforms will have to ensure that aWOM is developed and deployed responsibly and ethically. Practical implications: aWOM may emerge as the dominant source of information for tourist decision-making, displacing WOM or eWOM. aWOM may also impact online opinion leaders, as they may be challenged by algorithmically generated content. aWOM tools may also generate content using sensors on personal devices, creating privacy and information security concerns if users did not give permission for such activities. Originality/value: This paper is the first to theorize the emergence of aWOM as autonomous AI communication within the framework of unpaid influence or WOM. As customer engagement will increasingly occur in algorithmic environments that comprise person–machine interactions, aWOM will influence future tourism research and practice. © 2019, Emerald Publishing Limited.","Williams, Nigel L. and Ferdinand, Nicole and Bustard, John",Tourism Review,,2020,10.1108/TR-05-2019-0171,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074495423&doi=10.1108%2fTR-05-2019-0171&partnerID=40&md5=606663eb06e78d0c6a4e8f253259ed32,scopus.bib,2024-02-25 11:35:41,Unclassified
Griffin2020504,Conversational Agents for Chronic Disease Self-Management: A Systematic Review,"We conducted a systematic literature review to assess how conversational agents have been used to facilitate chronic disease self-management. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework was used. Literature was searched across five databases, and we included full-text articles that contained primary research findings for text-based conversational agents focused on self-management for chronic diseases in adults. 1,606 studies were identified, and 12 met inclusion criteria. Outcomes were largely focused on usability of conversational agents, and participants mostly reported positive attitudes with some concerns related to privacy and shallow content. In several studies, there were improvements on the Patient Health Questionnaire (p<0.05), Generalized Anxiety Disorder Scale (p=0.004), Perceived Stress Scale (p=0.048), Flourishing Scale (p=0.032), and Overall Anxiety Severity and Impairment Scale (p<0.05). There is early evidence that suggests conversational agents are acceptable, usable, and may be effective in supporting self-management, particularly for mental health. ©2020 AMIA - All rights reserved.","Griffin, Ashley C. and Xing, Zhaopeng and Khairat, Saif and Wang, Yue and Bailey, Stacy and Arguello, Jaime and Chung, Arlene E.",AMIA ... Annual Symposium proceedings. AMIA Symposium,,2020,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105317634&partnerID=40&md5=37f3a3bf32d886b8dc9d46d9265f006a,scopus.bib,2024-02-25 11:35:41,Unclassified
Laban2020,The Effect of Personalization Techniques in Users' Perceptions of Conversational Recommender Systems,"Conversational recommender systems provide users with individually tailored recommendations in a flowing dialogue. These require users to disclose information proactively or reactively for receiving personalized recommendations, which can trigger users' resistance to the platform and to the recommendations. Accordingly, this study examined the extent to which user-initiated and system-initiated recommendations provided by a conversational recommender system influenced users' perceptions of it. The results of an online experiment entail that when recommendations are system-initiated, as compared to user-initiated, users perceive to be in less control and perceive the system as riskier. Furthermore, the results stress that systems that provide user-initiated or system-initiated recommendations do not differ in users' perceptions of anthropomorphism. © 2020 Owner/Author.","Laban, Guy and Araujo, Theo","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020",,2020,10.1145/3383652.3423890,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096954637&doi=10.1145%2f3383652.3423890&partnerID=40&md5=0e018747c6b5ebfecc7db0201a7ac0dc,scopus.bib,2024-02-25 11:35:41,Unclassified
Hernández-Trapote2008305,Embodied conversational agents for Voice-Biometric interfaces,"In this article we present a research scheme which aims to analyze the use of Embodied Conversational Agent (ECA) technology to improve the robustness and acceptability of speaker enrolment and verification dialogues designed to provide secure access through natural and intuitive speaker recognition. In order to find out the possible effects of the visual information channel provided by the ECA, tests were carried out in which users were divided into two groups, each interacting with a different interface (metaphor): an ECA Metaphor group -with an ECA-, and a VOICE Metaphor group -without an ECA-. Our evaluation methodology is based on the ITU-T P.851 recommendation for spoken dialogue system evaluation, which we have complemented to cover particular aspects with regard to the two major extra elements we have incorporated: secure access and an ECA. Our results suggest that likeability-type factors and system capabilities are perceived more positively by the ECA metaphor users than by the VOICE metaphor users. However, the ECA's presence seems to intensify users' privacy concerns. Copyright 2008 ACM.","Hernández-Trapote, Álvaro and López-Mencía, Beatriz and Díaz, David and Fernández-Pozo, Rubén and Caminero, Javier",ICMI'08: Proceedings of the 10th International Conference on Multimodal Interfaces,,2008,10.1145/1452392.1452454,https://www.scopus.com/inward/record.uri?eid=2-s2.0-63449104556&doi=10.1145%2f1452392.1452454&partnerID=40&md5=b12fbdb8584819659f5117121a747bbc,scopus.bib,2024-02-25 11:35:41,Unclassified
Ngo2014222,Improving simulation of continuous emotional facial expressions by analyzing videos of human facial activities,"Conversational agents are receiving significant attention from multiagent and human computer interaction research societies. In order to make conversational agents more believable and friendly, giving them the ability to express emotions is one of research fields which have drawn a lot of attention lately. In this paper, we propose a work on analysis of how emotional facial activities happen temporally. Our goal is to find the temporal patterns of facial activity of six basic emotions in order to improve the simulation of continuous emotional facial expressions on a 3D face of an embodied agent. Using facial expression recognition techniques, we first analyze a spontaneous video database in order to consider how facial activities are related to six basic emotions temporally. From there, we bring out the general temporal patterns for facial expressions of the six basic emotions. Then, based on the temporal patterns, we propose a scheme for displaying continuous emotional states of a conversational agent on a 3D face. © Springer International Publishing Switzerland 2014.","Ngo, Thi Duyen and Vu, Thi Hong Nhan and Nguyen, Viet Ha and Bui, The Duy",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2014,10.1007/978-3-319-13191-7_18,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910138259&doi=10.1007%2f978-3-319-13191-7_18&partnerID=40&md5=7eaaad2b759f5f4e2adc7e44cc454b5e,scopus.bib,2024-02-25 11:35:41,Unclassified
Inkster2018,"An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-methods study","Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short-and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre-and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. © Becky Inkster, Shubhankar Sarda, Vinod Subramanian.","Inkster, Becky and Sarda, Shubhankar and Subramanian, Vinod",JMIR mHealth and uHealth,,2018,10.2196/12106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060334446&doi=10.2196%2f12106&partnerID=40&md5=ee4042f0f43089954f87f8eb3205565f,scopus.bib,2024-02-25 11:35:41,Unclassified
Roca2020,Microservice chatbot architecture for chronic patient support,"Chatbots are able to provide support to patients suffering from very different conditions. Patients with chronic diseases or comorbidities could benefit the most from chatbots which can keep track of their condition, provide specific information, encourage adherence to medication, etc. To perform these functions, chatbots need a suitable underlying software architecture. In this paper, we introduce a chatbot architecture for chronic patient support grounded on three pillars: scalability by means of microservices, standard data sharing models through HL7 FHIR and standard conversation modeling using AIML. We also propose an innovative automation mechanism to convert FHIR resources into AIML files, thus facilitating the interaction and data gathering of medical and personal information that ends up in patient health records. To align the way people interact with each other using messaging platforms with the chatbot architecture, we propose these very same channels for the chatbot-patient interaction, paying special attention to security and privacy issues. Finally, we present a monitored-data study performed in different chronic diseases, and we present a prototype implementation tailored for one specific chronic disease, psoriasis, showing how this new architecture allows the change, the addition or the improvement of different parts of the chatbot in a dynamic and flexible way, providing a substantial improvement in the development of chatbots used as virtual assistants for chronic patients. © 2019 Elsevier Inc.","Roca, Surya and Sancho, Jorge and García, José and Alesanco, Álvaro",Journal of Biomedical Informatics,,2020,10.1016/j.jbi.2019.103305,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077322086&doi=10.1016%2fj.jbi.2019.103305&partnerID=40&md5=bf7bbf24a0a82d95fd11aae98395bea1,scopus.bib,2024-02-25 11:35:41,Unclassified
WOS:000911440600005,"Privacy and Customer's Education: NLP for Information Resources
Suggestions and Expert Finder Systems","Privacy is one of the key issues for citizen's everyday online
activities, with the United Nations defining it as ``a human right in
the digital age{''}. Despite the introduction of data privacy
regulations almost everywhere around the globe, the biggest barrier to
effectiveness is the customer's capacity to map the privacy statement
received with the regulation in force and understand their terms. This
study advocates the creation of a convenient and cost-efficient
question-answering service for answering customers' queries on data
privacy. It proposes a dual step approach, allowing consumers to ask
support to a conversational agent boosted by a smart knowledge base,
attempting to answer the question using the most appropriate legal
document. Being the self-help approach insufficient, our system enacts a
second step suggesting a ranked list of legal experts for focused
advice. To achieve our objective, we need large enough and specialised
dataset and we plan to apply state-of-the-art Natural Language
Processing (NLP) techniques in the field of open domain question
answering. This paper describes the initial steps and some early results
we achieved in this direction and the next steps we propose to develop a
one-stop solution for consumers privacy needs.","Mazzola, Luca and Waldis, Andreas and Shankar, Atreya and Argyris,
Diamantis and Denzler, Alexander and Van Roey, Michiel",,"HCI FOR CYBERSECURITY, PRIVACY AND TRUST, HCI-CPT 2022",2022,10.1007/978-3-031-05563-8\_5,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001078432900001,Ethical Implications of Chatbot Utilization in Nephrology,"This comprehensive critical review critically examines the ethical
implications associated with integrating chatbots into nephrology,
aiming to identify concerns, propose policies, and offer potential
solutions. Acknowledging the transformative potential of chatbots in
healthcare, responsible implementation guided by ethical considerations
is of the utmost importance. The review underscores the significance of
establishing robust guidelines for data collection, storage, and sharing
to safeguard privacy and ensure data security. Future research should
prioritize defining appropriate levels of data access, exploring
anonymization techniques, and implementing encryption methods.
Transparent data usage practices and obtaining informed consent are
fundamental ethical considerations. Effective security measures,
including encryption technologies and secure data transmission
protocols, are indispensable for maintaining the confidentiality and
integrity of patient data. To address potential biases and
discrimination, the review suggests regular algorithm reviews, diversity
strategies, and ongoing monitoring. Enhancing the clarity of chatbot
capabilities, developing user-friendly interfaces, and establishing
explicit consent procedures are essential for informed consent. Striking
a balance between automation and human intervention is vital to preserve
the doctor-patient relationship. Cultural sensitivity and multilingual
support should be considered through chatbot training. To ensure ethical
chatbot utilization in nephrology, it is imperative to prioritize the
development of comprehensive ethical frameworks encompassing data
handling, security, bias mitigation, informed consent, and
collaboration. Continuous research and innovation in this field are
crucial for maximizing the potential of chatbot technology and
ultimately improving patient outcomes.","Valencia, Oscar A. Garcia and Suppadungsuk, Supawadee and Thongprayoon,
Charat and Miao, Jing and Tangpanithandee, Supawit and Craici, Iasmina
M. and Cheungpasitporn, Wisit",JOURNAL OF PERSONALIZED MEDICINE,,2023,10.3390/jpm13091363,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000521736100050,"A Banking Chatbot Security Control Procedure for Protecting User Data
Security and Privacy","The rise of AI has prompted the financial business to enter the
intelligent financial technology (FinTech). Chatbot with AI technologies
is an important member of FinTech. The financial industry is actively
introducing chatbot to enhance the market competitive advantage. Many
banks and card issuers in the United States have introduced or developed
chatbots from 2017 to increase user convenience and assist business
promotion of financial institutions. However, chatbot with AI features
may infringe customer security and personal privacy. Security has become
an important issue that Chatbot must pay attention to. In order to
improve the security of chatbot, this paper analyzes the security
strategies of e-commerce (EC), and combines the AI security principles
to plan the Chatbot Security Control Procedure (CSCP). CSCP uses
security specifications confirmation, specifications implementation,
inspection activity and improvement manners four stages to monitor
chatbot. Banking chatbot with CSPS can hold advantages of chatbots,
reduce the security risk, and concretely protect customer data security
and personal privacy.","Lai, Sen-Tarng and Leu, Fang-Yie and Lin, Jeng-Wei",,"ADVANCES ON BROADBAND AND WIRELESS COMPUTING, COMMUNICATION AND
APPLICATIONS, BWCCA-2018",2019,10.1007/978-3-030-02613-4\_50,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000501543800199,"``Hear me out{''}: Smart Speaker Based Conversational Agent to Monitor
Symptoms in Mental Health","Difference in features of voice such as tone, volume, intonation, and
rate of speech have been suggested as sensitive and valid measures of
mental illness. Researchers have used analysis of voice recordings
during phone calls, response to the IVR systems and smartphone based
conversational agents as a marker in continuous monitoring of symptoms
and effect of treatment in patients with mental illness. While these
methods of recording the patient's voice have been considered efficient,
they come with a number of issues in terms of adoption, privacy,
security, data storage etc. To address these issues we propose a smart
speaker based conversational agent - ``Hear me out{''}. In this paper,
we describe the proposed system, rationale behind using smart speakers,
and the challenges we are facing in the design of the system.","Maharjan, Raju and Baekgaard, Per and Bardram, Jakob E.",,"UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT
CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE
2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS",2019,10.1145/3341162.3346270,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001090755800001,"Human-chatbot interaction studies through the lens of bibliometric
analysis","Since chatbots have been integrated into people's lives from various
industries, human-chatbot interaction has begun to attract widespread
attention in academia. Still, contributions to the systematic mapping of
this field are lacking. This paper is the first to present a systematic
review of human-chatbot interaction research using bibliometric
analysis. A total of 3013 publications (from the year 2000 to 2022) from
Web of Science database were analysed to uncover the current status and
research trend in human-chatbot interaction domain. The analysis focused
on temporal and geographical distribution of these publications and
identified the most influential publication outlets, institutes,
articles, and authors. Additionally, keyword co-occurrence analysis and
temporal distribution of keywords showed that primary topics in
human-chatbot interaction mainly concentrate on techniques and methods
in chatbot systems design, extensive applications in various fields,
user experience and emotional expression, humanizing features design,
and perceived privacy risk and ethics. Finally, this paper sheds light
on a comprehensive understanding of human-chatbot interaction research
and provides directions for future research in this field.","Chen, Jiahao and Guo, Fu and Ren, Zenggen and Wang, Xueshuang and Ham,
Jaap",UNIVERSAL ACCESS IN THE INFORMATION SOCIETY,,2023,10.1007/s10209-023-01058-y,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000756587600003,"IDENTIFYING RELEVANT SEGMENTS OF POTENTIAL BANKING CHATBOT USERS BASED
ON TECHNOLOGY ADOPTION BEHAVIOR","Purpose Chatbot technology is expected to revolutionize customer service
in financial institutions. However, the adoption of customer service
chatbots in banking remains low. Therefore, the aim of this paper is to
identify relevant segments of potential banking chatbot users based on
technology adoption behavior.
Design/Methodology/Approach - Data for the research was collected
through an online questionnaire in Romania using the non-probability
sampling method. The 287 questionnaires were analyzed using hierarchical
and k-means cluster analysis.
Findings and implications - The analysis revealed three distinct
segments: Innovators (2696), consisting of highly educated young women
employed in the business sector; the Late Majority (55\%), consisting of
young women with higher education degrees who work in services-related
fields; and Laggards (19\%), consisting of educated middle-aged men
employed in the business sector. New significant differences among
demographic: and banking behavior variables weft observed across the
profiles of potential banking chatbot user segments.
Limitations - The study is based on a non-probability sample collected
from only one country, with a rather small sample size.
Originality -Technology acceptance variables (perceived usefulness,
perceived ease of use), expanded to include constructs such as awareness
of service, perceived privacy risk, and perceived compatibility, were
found to be appro priate for customer segmentation purposes in the
context of chatbot applications based on artificial intelligence. The
study also revealed a new innovator demographic profile.","Alt, Monika-Anetta and Ibolya, Vizeli",MARKET-TRZISTE,,2021,10.22598/mt/2021.33.2.165,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000854073700027,"Thematic Analysis on User Reviews for Depression and Anxiety Chatbot
Apps: Machine Learning Approach","Background: Anxiety and depression are among the most commonly prevalent
mental health disorders worldwide. Chatbot apps can play an important
role in relieving anxiety and depression. Users' reviews of chatbot apps
are considered an important source of data for exploring users' opinions
and satisfaction.
Objective: This study aims to explore users' opinions, satisfaction, and
attitudes toward anxiety and depression chatbot apps by conducting a
thematic analysis of users' reviews of 11 anxiety and depression chatbot
apps collected from the Google Play Store and Apple App Store. In
addition, we propose a workflow to provide a methodological approach for
future analysis of app review comments.
Methods: We analyzed 205,581 user review comments from chatbots designed
for users with anxiety and depression symptoms. Using scraper tools and
Google Play Scraper and App Store Scraper Python libraries, we extracted
the text and metadata. The reviews were divided into positive and
negative meta-themes based on users' rating per review. We analyzed the
reviews using word frequencies of bigrams and words in pairs. A topic
modeling technique, latent Dirichlet allocation, was applied to identify
topics in the reviews and analyzed to detect themes and subthemes.
Results: Thematic analysis was conducted on 5 topics for each
sentimental set. Reviews were categorized as positive or negative. For
positive reviews, the main themes were confidence and affirmation
building, adequate analysis, and consultation, caring as a friend, and
ease of use. For negative reviews, the results revealed the following
themes: usability issues, update issues, privacy, and noncreative
conversations.
Conclusions: Using a machine learning approach, we were able to analyze
>= 200,000 comments and categorize them into themes, allowing us to
observe users' expectations effectively despite some negative factors. A
methodological workflow is provided for the future analysis of review
comments.","Ahmed, Arfan and Aziz, Sarah and Khalifa, Mohamed and Shah, Uzair and
Hassan, Asma and Abd-Alrazaq, Alaa and Househ, Mowafa",JMIR FORMATIVE RESEARCH,,2022,10.2196/27654,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001161681600001,The AI Institute for Engaged Learning,"The EngageAI Institute focuses on AI-driven narrative-centered learning
environments that create engaging story-based problem-solving
experiences to support collaborative learning. The institute's research
has three complementary strands. First, the institute creates
narrative-centered learning environments that generate interactive
story-based problem scenarios to elicit rich communication, encourage
coordination, and spark collaborative creativity. Second, the institute
creates virtual embodied conversational agent technologies with multiple
modalities for communication (speech, facial expression, gesture, gaze,
and posture) to support student learning. Embodied conversational agents
are driven by advances in natural language understanding, natural
language generation, and computer vision. Third, the institute is
creating an innovative multimodal learning analytics framework that
analyzes parallel streams of multimodal data derived from students'
conversations, gaze, facial expressions, gesture, and posture as they
interact with each other, with teachers, and with embodied
conversational agents. Woven throughout the institute's activities is a
strong focus on ethics, with an emphasis on creating AI-augmented
learning that is deeply informed by considerations of fairness,
accountability, transparency, trust, and privacy. The institute
emphasizes broad participation and diverse perspectives to ensure that
advances in AI-augmented learning address inequities in STEM. The
institute brings together a multistate network of universities, diverse
K-12 school systems, science museums, and nonprofit partners. Key to all
of these endeavors is an emphasis on diversity, equity, and inclusion.","Lester, James and Bansal, Mohit and Biswas, Gautam and Hmelo-Silver,
Cindy and Roschelle, Jeremy and Rowe, Jonathan",AI MAGAZINE,,2024,10.1002/aaai.12161,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000757409600001,"Health-focused conversational agents in person-centered care: a review
of apps","Health-focused apps with chatbots ({''}healthbots{''}) have a critical
role in addressing gaps in quality healthcare. There is limited evidence
on how such healthbots are developed and applied in practice. Our review
of healthbots aims to classify types of healthbots, contexts of use, and
their natural language processing capabilities. Eligible apps were those
that were health-related, had an embedded text-based conversational
agent, available in English, and were available for free download
through the Google Play or Apple iOS store. Apps were identified using
42Matters software, a mobile app search engine. Apps were assessed using
an evaluation framework addressing chatbot characteristics and natural
language processing features. The review suggests uptake across 33 low-
and high-income countries. Most healthbots are patient-facing, available
on a mobile interface and provide a range of functions including health
education and counselling support, assessment of symptoms, and
assistance with tasks such as scheduling. Most of the 78 apps reviewed
focus on primary care and mental health, only 6 (7.59\%) had a
theoretical underpinning, and 10 (12.35\%) complied with health
information privacy regulations. Our assessment indicated that only a
few apps use machine learning and natural language processing
approaches, despite such marketing claims. Most apps allowed for a
finite-state input, where the dialogue is led by the system and follows
a predetermined algorithm. Healthbots are potentially transformative in
centering care around the user; however, they are in a nascent state of
development and require further research on development, automation and
adoption for a population-level health impact.","Parmar, Pritika and Ryu, Jina and Pandya, Shivani and Sedoc, Joao and
Agarwal, Smisha",NPJ DIGITAL MEDICINE,,2022,10.1038/s41746-022-00560-6,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000765484500015,Smart Speakers: The Next Frontier in mHealth,"The rapid dissemination and adoption of smart speakers has enabled
substantial opportunities to improve human health. Just as the
introduction of the mobile phone led to considerable health innovation,
smart speaker computing systems carry several unique advantages that
have the potential to catalyze new fields of health research,
particularly in out-of-hospital environments. The recent rise and
ubiquity of these smart computing systems holds significant potential
for enhancing chronic disease management, enabling passive
identification of unwitnessed medical emergencies, detecting subtle
changes in human behavior and cognition, limiting isolation, and
potentially allowing widespread, passive, remote monitoring of
respiratory diseases that impact public health. There are 3 broad
mechanisms for how a smart speaker can interact with a person to improve
health. These include (1) as an intelligent conversational agent, (2) as
a passive identifier of medically relevant diagnostic sounds, and (3) by
active sensing using the device's internal hardware to measure
physiologic parameters, such as with active sonar, radar, or computer
vision. Each of these different modalities has specific clinical use
cases, all of which need to be balanced against potential privacy
concerns, equity concerns related to system access, and regulatory
frameworks which have not yet been developed for this unique type of
passive data collection.","Sunshine, Jacob",JMIR MHEALTH AND UHEALTH,,2022,10.2196/28686,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001146576200006,"Evaluation of the Current State of Chatbots for Digital Health: Scoping
Review","Background: Chatbots have become ubiquitous in our daily lives, enabling
natural language conversations with users through various modes of
communication. Chatbots have the potential to play a significant role in
promoting health and well-being. As the number of studies and available
products related to chatbots continues to rise, there is a critical need
to assess product features to enhance the design of chatbots that
effectively promote health and behavioral change. Objective: This
scoping review aims to provide a comprehensive assessment of the current
state of health-related chatbots, including the chatbots'
characteristics and features, user backgrounds, communication models,
relational building capacity, personalization, interaction, responses to
suicidal thoughts, and users' in-app experiences during chatbot use.
Through this analysis, we seek to identify gaps in the current research,
guide future directions, and enhance the design of health-focused
chatbots. Methods: Following the scoping review methodology by Arksey
and O'Malley and guided by the PRISMA-ScR (Preferred Reporting Items for
Systematic Reviews and Meta-Analyses extension for Scoping Reviews)
checklist, this study used a two-pronged approach to identify relevant
chatbots: (1) searching the iOS and Android App Stores and (2) reviewing
scientific literature through a search strategy designed by a librarian.
Overall, 36 chatbots were selected based on predefined criteria from
both sources. These chatbots were systematically evaluated using a
comprehensive framework developed for this study, including chatbot
characteristics, user backgrounds, building relational capacity,
personalization, interaction models, responses to critical situations,
and user experiences. Ten coauthors were responsible for downloading and
testing the chatbots, coding their features, and evaluating their
performance in simulated conversations. The testing of all chatbot apps
was limited to their free-to-use features. Results: This review provides
an overview of the diversity of health-related chatbots, encompassing
categories such as mental health support, physical activity promotion,
and behavior change interventions. Chatbots use text, animations,
speech, images, and emojis for communication. The findings highlight
variations in conversational capabilities, including empathy, humor, and
personalization. Notably, concerns regarding safety, particularly in
addressing suicidal thoughts, were evident. Approximately 44\% (16/36)
of the chatbots effectively addressed suicidal thoughts. User
experiences and behavioral outcomes demonstrated the potential of
chatbots in health interventions, but evidence remains limited.
Conclusions: This scoping review underscores the significance of
chatbots in health-related applications and offers insights into their
features, functionalities, and user experiences. This study contributes
to advancing the understanding of chatbots' role in digital health
interventions, thus paving the way for more effective and user-centric
health promotion strategies. This study informs future research
directions, emphasizing the need for rigorous randomized control trials,
standardized evaluation metrics, and user-centered design to unlock the
full potential of chatbots in enhancing health and well-being. Future
research should focus on addressing limitations, exploring real-world
user experiences, and implementing robust data security and privacy
measures.","Xue, Jia and Zhang, Bolun and Zhao, Yaxi and Zhang, Qiaoru and Zheng,
Chengda and Jiang, Jielin and Li, Hanjia and Liu, Nian and Li, Ziqian
and Fu, Weiying and Peng, Yingdong and Logan, Judith and Zhang, Jingwen
and Xiang, Xiaoling",JOURNAL OF MEDICAL INTERNET RESEARCH,,2023,10.2196/47217,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000832007700001,"The Use of Artificial Intelligence-Based Conversational Agents
(Chatbots) for Weight Loss: Scoping Review and Practical Recommendations","Background: Overweight and obesity have now reached a state of a
pandemic despite the clinical and commercial programs available.
Artificial intelligence (AI) chatbots have a strong potential in
optimizing such programs for weight loss.
Objective: This study aimed to review AI chatbot use cases for weight
loss and to identify the essential components for prolonging user
engagement.
Methods: A scoping review was conducted using the 5-stage framework by
Arksey and O'Malley. Articles were searched across nine electronic
databases (ACM Digital Library, CINAHL, Cochrane Central, Embase, IEEE
Xplore, PsycINFO, PubMed, Scopus, and Web of Science) until July 9,
2021. Gray literature, reference lists, and Google Scholar were also
searched.
Results: A total of 23 studies with 2231 participants were included and
evaluated in this review. Most studies (8/23, 35\%) focused on using AI
chatbots to promote both a healthy diet and exercise, 13\% (3/23) of the
studies used AI chatbots solely for lifestyle data collection and
obesity risk assessment whereas only 4\% (1/23) of the studies focused
on promoting a combination of a healthy diet, exercise, and stress
management. In total, 48\% (11/23) of the studies used only text-based
AI chatbots, 52\% (12/23) operationalized AI chatbots through
smartphones, and 39\% (9/23) integrated data collected through fitness
wearables or Internet of Things appliances. The core functions of AI
chatbots were to provide personalized recommendations (20/23, 87\%),
motivational messages (18/23, 78\%), gamification (6/23, 26\%), and
emotional support (6/23, 26\%). Study participants who experienced
speech- and augmented reality based chatbot interactions in addition to
text based chatbot interactions reported higher user engagement because
of the convenience of hands-free interactions. Enabling conversations
through multiple platforms (eg, SMS text messaging, Slack, Telegram,
Signal, WhatsApp, or Facebook Messenger) and devices (eg, laptops,
Google Home, and Amazon Alexa) was reported to increase user engagement.
The human semblance of chatbots through verbal and nonverbal cues
improved user engagement through interactivity and empathy. Other
techniques used in text-based chatbots included personally and
culturally appropriate colloquial tones and content; emojis that emulate
human emotional expressions; positively framed words; citations of
credible information sources; personification; validation; and the
provision of real-time, fast, and reliable recommendations. Prevailing
issues included privacy; accountability; user burden; and
interoperability with other databases, third-party applications, social
media platforms, devices, and appliances.
Conclusions: AI chatbots should be designed to be human-like,
personalized, contextualized, immersive, and enjoyable to enhance user
experience, engagement, behavior change, and weight loss. These require
the integration of health metrics (eg, based on self-reports and
wearable trackers), personality and preferences (eg, based on goal
achievements), circumstantial behaviors (eg, trigger-based
overconsumption), and emotional states (eg, chatbot conversations and
wearable stress detectors) to deliver personalized and effective
recommendations for weight loss.","Chew, Han Shi Jocelyn",JMIR MEDICAL INFORMATICS,,2022,10.2196/32578,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001115600200002,Security Implications of AI Chatbots in Health Care,"Artificial intelligence (AI) chatbots like ChatGPT and Google Bard are
computer programs that use AI and natural language processing to
understand customer questions and generate natural, fluid, dialogue-like
responses to their inputs. ChatGPT, an AI chatbot created by OpenAI, has
rapidly become a widely used tool on the internet. AI chatbots have the
potential to improve patient care and public health. However, they are
trained on massive amounts of people's data, which may include sensitive
patient data and business information. The increased use of chatbots
introduces data security issues, which should be handled yet remain
understudied. This paper aims to identify the most important security
problems of AI chatbots and propose guidelines for protecting sensitive
health information. It explores the impact of using ChatGPT in health
care. It also identifies the principal security risks of ChatGPT and
suggests key considerations for security risk mitigation. It concludes
by discussing the policy implications of using AI chatbots in health
care.","Li, Jingquan",JOURNAL OF MEDICAL INTERNET RESEARCH,,2023,10.2196/47551,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000774798100001,"The Impact of Chatbots on Customer Loyalty: A Systematic Literature
Review","More and more companies have implemented chatbots on their websites to
provide support to their visitors on a 24/7 basis. The new customer
wants to spend less and less time and therefore expects to reach a
company anytime and anywhere, regardless of time, location, and channel.
This study provides insight into the influence of chatbots on customer
loyalty. System quality, service quality, and information quality are
crucial dimensions that a chatbot must meet to give a good customer
experience. To make a chatbot more personal, companies can alter the
language style. Human-like chatbots lead to greater satisfaction and
trust among customers, leading to greater adoption of the chatbot. The
results of this study showed that a connection between chatbots and
customer loyalty is very likely. Besides, some customers suffer from the
privacy paradox because of personalization. Implications of this study
are discussed.","Jenneboer, Liss and Herrando, Carolina and Constantinides, Efthymios",JOURNAL OF THEORETICAL AND APPLIED ELECTRONIC COMMERCE RESEARCH,,2022,10.3390/jtaer17010011,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001069615500001,The impact of ChatGPT on higher education,"Introduction This study explores the effects of Artificial Intelligence
(AI) chatbots, with a particular focus on OpenAI's ChatGPT, on Higher
Education Institutions (HEIs). With the rapid advancement of AI,
understanding its implications in the educational sector becomes
paramount.Methods Utilizing databases like PubMed, IEEE Xplore, and
Google Scholar, we systematically searched for literature on AI
chatbots' impact on HEIs. Our criteria prioritized peer-reviewed
articles, prominent media outlets, and English publications, excluding
tangential AI chatbot mentions. After selection, data extraction focused
on authors, study design, and primary findings. The analysis combined
descriptive and thematic approaches, emphasizing patterns and
applications of AI chatbots in HEIs.Results The literature review
revealed diverse perspectives on ChatGPT's potential in education.
Notable benefits include research support, automated grading, and
enhanced human-computer interaction. However, concerns such as online
testing security, plagiarism, and broader societal and economic impacts
like job displacement, the digital literacy gap, and AI-induced anxiety
were identified. The study also underscored the transformative
architecture of ChatGPT and its versatile applications in the
educational sector. Furthermore, potential advantages like streamlined
enrollment, improved student services, teaching enhancements, research
aid, and increased student retention were highlighted. Conversely, risks
such as privacy breaches, misuse, bias, misinformation, decreased human
interaction, and accessibility issues were identified.Discussion While
AI's global expansion is undeniable, there is a pressing need for
balanced regulation in its application within HEIs. Faculty members are
encouraged to utilize AI tools like ChatGPT proactively and ethically to
mitigate risks, especially academic fraud. Despite the study's
limitations, including an incomplete representation of AI's overall
effect on education and the absence of concrete integration guidelines,
it is evident that AI technologies like ChatGPT present both significant
benefits and risks. The study advocates for a thoughtful and responsible
integration of such technologies within HEIs.","Dempere, Juan and Modugu, Kennedy and Hesham, Allam and Ramasamy,
Lakshmana Kumar",FRONTIERS IN EDUCATION,,2023,10.3389/feduc.2023.1206936,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001086352800001,"Can ChatGPT be the Plastic Surgeon's New Digital Assistant? A
Bibliometric Analysis and Scoping Review of ChatGPT in Plastic Surgery
Literature","Background:ChatGPT, an artificial intelligence (AI) chatbot that uses
natural language processing (NLP) to interact in a humanlike manner, has
made significant contributions to various healthcare fields, including
plastic surgery. However, its widespread use has raised ethical and
security concerns. This study examines the presence of ChatGPT, an
artificial intelligence (AI) chatbot, in the literature of plastic
surgery. Methods:A bibliometric analysis and scoping review of the
ChatGPT plastic surgery literature were performed. PubMed was queried
using the search term ``ChatGPT{''} to identify all biomedical
literature on ChatGPT, with only studies related to plastic,
reconstructive, or aesthetic surgery topics being considered eligible
for inclusion. Results:The analysis included 30 out of 724 articles
retrieved from PubMed, focusing on publications from December 2022 to
July 2023. Four key areas of research emerged: applications in
research/creation of original work, clinical application, surgical
education, and ethics/commentary on previous studies. The versatility of
ChatGPT in research, its potential in surgical education, and its role
in enhancing patient education were explored. Ethical concerns regarding
patient privacy, plagiarism, and the accuracy of information obtained
from ChatGPT-generated sources were also highlighted. Conclusion:While
ethical concerns persist, the study underscores the potential of ChatGPT
in plastic surgery research and practice, emphasizing the need for
careful utilization and collaboration to optimize its benefits while
minimizing risks.","Liu, Hilary Y. and Alessandri-Bonetti, Mario and Arellano, Jose Antonio
and Egro, Francesco M.",AESTHETIC PLASTIC SURGERY,,2023,10.1007/s00266-023-03709-0,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001002898500001,A Systematic Literature Review of Information Security in Chatbots,"Chatbots have become increasingly popular in recent years, but they also
present security risks and vulnerabilities that need to be addressed.
This systematic literature review examines the existing research
relating to information security in chatbots, identifying the potential
threats, proposed solutions, and future directions for research. The
review finds that chatbots face various security threats, including
malicious input, user profiling, contextual attacks, and data breaches,
and that solutions such as blockchain technology, end-to-end encryption,
and organizational controls can be used to mitigate these concerns. The
review also highlights the importance of maintaining user trust and
addressing privacy concerns for the successful adoption and continued
use of chatbots. A taxonomy developed in this review provides a useful
framework for categorizing the articles and their findings. The review
concludes by identifying future research directions that include
developing more sophisticated authentication and authorization
mechanisms, exploring the use of privacy-enhancing technologies, and
improving the detection and prevention of security threats, among
others. This review contributes to the growing body of literature on
information security in chatbots and can guide future research and
practice in this field.","Yang, Jing and Chen, Yen-Lin and Por, Lip Yee and Ku, Chin Soon",APPLIED SCIENCES-BASEL,,2023,10.3390/app13116355,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000495464000001,"The Personalization of Conversational Agents in Health Care: Systematic
Review","Background: The personalization of conversational agents with natural
language user interfaces is seeing increasing use in health care
applications, shaping the content, structure, or purpose of the dialogue
between humans and conversational agents.
Objective: The goal of this systematic review was to understand the ways
in which personalization has been used with conversational agents in
health care and characterize the methods of its implementation.
Methods: We searched on PubMed, Embase, CINAHL, PsycInfo, and ACM
Digital Library using a predefined search strategy. The studies were
included if they: (1) were primary research studies that focused on
consumers, caregivers, or health care professionals; (2) involved a
conversational agent with an unconstrained natural language interface;
(3) tested the system with human subjects; and (4) implemented
personalization features.
Results: The search found 1958 publications. After abstract and
full-text screening, 13 studies were included in the review. Common
examples of personalized content included feedback, daily health
reports, alerts, warnings, and recommendations. The personalization
features were implemented without a theoretical framework of
customization and with limited evaluation of its impact. While
conversational agents with personalization features were reported to
improve user satisfaction, user engagement and dialogue quality, the
role of personalization in improving health outcomes was not assessed
directly.
Conclusions: Most of the studies in our review implemented the
personalization features without theoretical or evidence-based support
for them and did not leverage the recent developments in other domains
of personalization. Future research could incorporate personalization as
a distinct design factor with a more careful consideration of its impact
on health outcomes and its implications on patient safety, privacy, and
decision-making.","Kocaballi, Ahmet Baki and Berkovsky, Shlomo and Quiroz, Juan C. and
Laranjo, Liliana and Huong Ly Tong and Rezazadegan, Dana and Briatore,
Agustina and Coiera, Enrico",JOURNAL OF MEDICAL INTERNET RESEARCH,,2019,10.2196/15360,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001022396100003,Health Chatbots in Africa: Scoping Review,"Background: This scoping review explores and summarizes the existing
literature on the use of chatbots to support and promote health in
Africa. Objective: The primary aim was to learn where, and under what
circumstances, chatbots have been used effectively for health in Africa;
how chatbots have been developed to the best effect; and how they have
been evaluated by looking at literature published between 2017 and 2022.
A secondary aim was to identify potential lessons and best practices for
others chatbots. The review also aimed to highlight directions for
future research on the use of chatbots for health in Africa. Methods:
Using the 2005 Arksey and O'Malley framework, we used a Boolean search
to broadly search literature published between January 2017 and July
2022. Literature between June 2021 and July 2022 was identified using
Google Scholar, EBSCO information services-which includes the African
HealthLine, PubMed, MEDLINE, PsycInfo, Cochrane, Embase, Scopus, and Web
of Science databases-and other internet sources (including gray
literature). The inclusion criteria were literature about health
chatbots in Africa published in journals, conference papers, opinion, or
white papers. Results: In all, 212 records were screened, and 12
articles met the inclusion criteria. Results were analyzed according to
the themes they covered. The themes identified included the purpose of
the chatbot as either providing an educational or information-sharing
service or providing a counselling service. Accessibility as a result of
either technical restrictions or language restrictions was also noted.
Other themes that were identified included the need for the
consideration of trust, privacy and ethics, and evaluation. Conclusions:
The findings demonstrate that current data are insufficient to show
whether chatbots are effectively supporting health in the region.
However, the review does reveal insights into popular chatbots and the
need to make them accessible through language considerations, platform
choice, and user trust, as well as the importance of robust evaluation
frameworks to assess their impact. The review also provides
recommendations on the direction of future research.","Phiri, Millie and Munoriyarwa, Allen",JOURNAL OF MEDICAL INTERNET RESEARCH,,2023,10.2196/35573,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000696619000001,"Promoting Physical Activity Through Conversational Agents: Mixed Methods
Systematic Review","Background: Regular physical activity (PA) is crucial for well-being;
however, healthy habits are difficult to create and maintain.
Interventions delivered via conversational agents (eg, chatbots or
virtual agents) are a novel and potentially accessible way to promote
PA. Thus, it is important to understand the evolving landscape of
research that uses conversational agents.
Objective: This mixed methods systematic review aims to summarize the
usability and effectiveness of conversational agents in promoting PA,
describe common theories and intervention components used, and identify
areas for further development.
Methods: We conducted a mixed methods systematic review. We searched
seven electronic databases (PsycINFO, PubMed, Embase, CINAHL, ACM
Digital Library, Scopus, and Web of Science) for quantitative,
qualitative, and mixed methods studies that conveyed primary research on
automated conversational agents designed to increase PA. The studies
were independently screened, and their methodological quality was
assessed using the Mixed Methods Appraisal Tool by 2 reviewers. Data on
intervention impact and effectiveness, treatment characteristics, and
challenges were extracted and analyzed using parallel-results convergent
synthesis and narrative summary.
Results: In total, 255 studies were identified, 7.8\% (20) of which met
our inclusion criteria. The methodological quality of the studies was
varied. Overall, conversational agents had moderate usability and
feasibility. Those that were evaluated through randomized controlled
trials were found to be effective in promoting PA. Common challenges
facing interventions were repetitive program content, high attrition,
technical issues, and safety and privacy concerns.
Conclusions: Conversational agents hold promise for PA interventions.
However, there is a lack of rigorous research on long-term intervention
effectiveness and patient safety. Future interventions should be based
on evidence-informed theories and treatment approaches and should
address users' desires for program variety, natural language processing,
delivery via mobile devices, and safety and privacy concerns.","Luo, Tiffany Christina and Aguilera, Adrian and Lyles, Courtney Rees and
Figueroa, Caroline Astrid",JOURNAL OF MEDICAL INTERNET RESEARCH,,2021,10.2196/25486,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000518623400005,Ethical Artificial Intelligence for Digital Health Organizations,"This technical report describes the methods undertaken by a US-based
Digital Health company (X2AI or X2 for short) to develop an ethical code
for startup environments and other organizations delivering emotional
artificial intelligence (AI) services, especially for mental health
support. With a growing demand worldwide for scalable, affordable, and
accessible health care solutions, the use of AI offers tremendous
potential to improve emotional well-being. To realize this potential, it
is imperative that AI service providers prioritize clear and consistent
ethical guidelines that align with global considerations regarding user
safety and privacy. This report offers a template for an ethical code
that can be implemented by other emotional AI services and their
affiliates. It includes practical guidelines for integrating support
from clients, collaborators, and research partners. It also shows how
existing ethical systems can inform the development of AI ethics.","Joerin, Angela and Rauws, Michiel and Fulmer, Russell and Black, Valerie",CUREUS JOURNAL OF MEDICAL SCIENCE,,2020,10.7759/cureus.7202,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001011268400001,"To chat or bot to chat: Ethical issues with using chatbots in mental
health","This paper presents a critical review of key ethical issues raised by
the emergence of mental health chatbots. Chatbots use varying degrees of
artificial intelligence and are increasingly deployed in many different
domains including mental health. The technology may sometimes be
beneficial, such as when it promotes access to mental health information
and services. Yet, chatbots raise a variety of ethical concerns that are
often magnified in people experiencing mental ill-health. These ethical
challenges need to be appreciated and addressed throughout the
technology pipeline. After identifying and examining four important
ethical issues by means of a recognised ethical framework comprised of
five key principles, the paper offers recommendations to guide chatbot
designers, purveyers, researchers and mental health practitioners in the
ethical creation and deployment of chatbots for mental health.","Coghlan, Simon and Leins, Kobi and Sheldrick, Susie and Cheong, Marc and
Gooding, Piers and D'Alfonso, Simon",DIGITAL HEALTH,,2023,10.1177/20552076231183542,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000538072100001,"Artificial intelligence and mobile apps for mental healthcare: a social
informatics perspective","Purpose For decades, artificial intelligence (AI) has been utilized
within the field of mental healthcare. This paper aims to examine AI
chatbots, specifically as offered through mobile applications for mental
healthcare (MHapps), with attention to the social implications of these
technologies. For example, AI chatbots in MHapps are programmed with
therapeutic techniques to assist people with anxiety and depression, but
the promise of this technology is tempered by concerns about the apps'
efficacy, privacy, safety and security. Design/methodology/approach
Utilizing a social informatics perspective, a literature review covering
MHapps, with a focus on AI chatbots was conducted from the period of
January-April 2019. A borrowed theory approach pairing information
science and social work was applied to analyze the literature. Findings
Rising needs for mental healthcare, combined with expanding
technological developments, indicate continued growth of MHapps and
chatbots. While an AI chatbot may provide a person with a place to
access tools and a forum to discuss issues, as well as a way to track
moods and increase mental health literacy, AI is not a replacement for a
therapist or other mental health clinician. Ultimately, if AI chatbots
and other MHapps are to have a positive impact, they must be regulated,
and society must avoid techno-fundamentalism in relation to AI for
mental health. Originality/value This study adds to a small but growing
body of information science research into the role of AI in the support
of mental health.","Gamble, Alyson",ASLIB JOURNAL OF INFORMATION MANAGEMENT,,2020,10.1108/AJIM-11-2019-0316,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000462004900001,"Can Your Phone Be Your Therapist? Young People's Ethical Perspectives on
the Use of Fully Automated Conversational Agents (Chatbots) in Mental
Health Support","Over the last decade, there has been an explosion of digital
interventions that aim to either supplement or replace face-to-face
mental health services. More recently. a number of automated
conversational agents have also been made available. which respond to
users in ways that mirror a real-life interaction. What are the social
and ethical concerns that arise from these advances? In this article. we
discuss, from a young person's perspective, the strengths and
limitations of using chatbots in mental health support. We also outline
what we consider to be minimum ethical standards for these platforms.
including issues surrounding privacy and confidentiality. efficacy. and
safety. and review three existing platforms (Woebot. Joy. and Wysa)
according to our proposed framework. It is our hope that this article
will stimulate ethical debate among app developers. practitioners. young
people. and other stakeholders. and inspire ethically responsible
practice in digital mental health.","Kretzschmar, Kira and Tyroll, Holly and Pavarini, Gabriela and Manzini,
Arianna and Singh, Ilina and Sharudin, Aysha and Pavlov, Boris and
Davis, Charlie and Mooney, Daniel and Kibble, Eleyna and Tuckwell,
George and Lewis, Grace and Heelas, Jasmine and Dixon, James and
Bransby-Meehan, Jessica and Katz, Jessica and Seeney, Laura and Lee,
Angela and Allegri, Martino and Beard, Maud and Aithani, Nav and Lumbis,
Nellie and Walker, Niahm and Macfarlane, Poppy and Bonnett, Samantha and
Martin, Sophie and Speakman, Sophie and NeurOx Young Peoples Advisory
Grp",BIOMEDICAL INFORMATICS INSIGHTS,,2019,10.1177/1178222619829083,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001041627500001,ChatGPT in Plastic and Reconstructive Surgery,"Background Chat Generative Pre-Trained Transformer (ChatGPT) is a
versatile large language model-based generative artificial intelligence.
It is proficient in a variety of tasks from drafting emails to coding to
composing music to passing medical licensing exams. While the potential
role of ChatGPT in plastic surgery is promising, evidence-based research
is needed to guide its implementation in practice.Methods This review
aims to summarize the literature surrounding ChatGPT's use in plastic
surgery.Results A literature search revealed several applications for
ChatGPT in the field of plastic surgery, including the ability to create
academic literature and to aid the production of research. However, the
ethical implications of using such chatbots in scientific writing
requires careful consideration. ChatGPT can also generate high-quality
patient discharge summaries and operation notes within seconds, freeing
up busy junior doctors to complete other tasks. However, currently
clinical information must still be manually inputted, and clinicians
must consider data privacy implications. Its use in aiding patient
communication and education and training is also widely documented in
the literature. However, questions have been raised over the accuracy of
answers generated given that current versions of ChatGPT cannot access
the most up-to-date sources.Conclusions While one must be aware of its
shortcomings, ChatGPT is a useful tool for plastic surgeons to improve
productivity for a range of tasks from manuscript preparation to
healthcare communication generation to drafting teaching sessions to
studying and learning. As access improves and technology becomes more
refined, surely more uses for ChatGPT in plastic surgery will become
apparent.","Sharma, Sanjeev Chaand and Ramchandani, Jai Parkash and Thakker, Arjuna
and Lahiri, Anindya",INDIAN JOURNAL OF PLASTIC SURGERY,,2023,10.1055/s-0043-1771514,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001034069900001,Applying the Digital Health Social Justice Guide,"Introduction Digital health, the use of apps, text-messaging, and online
interventions, can revolutionize healthcare and make care more
equitable. Currently, digital health interventions are often not
designed for those who could benefit most and may have unintended
consequences. In this paper, we explain how privacy vulnerabilities and
power imbalances, including racism and sexism, continue to influence
health app design and research. We provide guidelines for researchers to
design, report and evaluate digital health studies to maximize social
justice in health.Methods From September 2020 to April 2021, we held
five discussion and brainstorming sessions with researchers, students,
and community partners to develop the guide and the key questions. We
additionally conducted an informal literature review, invited experts to
review our guide, and identified examples from our own digital health
study and other studies.Results We identified five overarching topics
with key questions and subquestions to guide researchers in designing or
evaluating a digital health research study. The overarching topics are:
1. Equitable distribution; 2. Equitable design; 3. Privacy and data
return; 4. Stereotype and bias; 5. Structural racism.Conclusion We
provide a guide with five key topics and questions for social justice
digital health research. Encouraging researchers and practitioners to
ask these questions will help to spark a transformation in digital
health toward more equitable and ethical research. Future work needs to
determine if the quality of studies can improve when researchers use
this guide.","Figueroa, Caroline A. and Murayama, Hikari and Amorim, Priscila Carcamo
and White, Alison and Quiterio, Ashley and Luo, Tiffany and Aguilera,
Adrian and Smith, Angela D. R. and Lyles, Courtney R. and Robinson,
Victoria and von Vacano, Claudia",FRONTIERS IN DIGITAL HEALTH,,2022,10.3389/fdgth.2022.807886,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000974284000003,Will ChatGPT/GPT-4 be a Lighthouse to Guide Spinal Surgeons?,"The advent of artificial intelligence (AI), particularly ChatGPT/GPT-4,
has led to advancements in various fields, including healthcare. This
study explores the prospective role of ChatGPT/GPT-4 in various facets
of spinal surgical practice, especially in supporting spinal surgeons
during the perioperative management of endoscopic spinal surgery for
patients with lumbar disc herniation. The AI-driven chatbot can
facilitate communication between spinal surgeons, patients, and their
relatives, streamline the collection and analysis of patient data, and
contribute to the surgical planning process. Furthermore, ChatGPT/GPT-4
may enhance intraoperative support by providing real-time surgical
navigation information and physiological parameter monitoring, as well
as aiding in postoperative rehabilitation guidance. However, the
appropriate and supervised use of ChatGPT/GPT-4 is essential,
considering the potential risks associated with data security and
privacy. The study concludes that ChatGPT/GPT-4 can serve as a valuable
lighthouse for spinal surgeons if used correctly and responsibly.","He, Yongbin and Tang, Haifeng and Wang, Dongxue and Gu, Shuqin and Ni,
Guoxin and Wu, Haiyang",ANNALS OF BIOMEDICAL ENGINEERING,,2023,10.1007/s10439-023-03206-0,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001082421700002,Robotics in brick-and-mortar retail,"To make brick-and-mortar retail continue to be profitable and efficient,
the use of technology and software is essential. The deployment of smart
robotics is, in addition, a response to the lack of personnel and
increasing tasks in the store. This article provides an overview of
current and future applications of robots in brick-and-mortar retail,
highlighting challenges and potentials. The article concludes that
robotics in brick-and-mortar retail enables higher competitiveness
through unique customer experiences and improved efficiency. Automated
inventory, automated cleaning, vacancy detection, and chatbot support
can optimize processes. However, challenges exist regarding costs,
training requirements, feasibility, and data privacy.","Kranzer, Simon and Portenschlager, Lukas and Horn, Matthaeus and
Kozlica, Reuf and Muellner, Viktoria and Neureiter, Tina and Noebauer,
Julian and Sassnick, Olaf and Schlager, Christina and Zniva, Robert",ELEKTROTECHNIK UND INFORMATIONSTECHNIK,,2023,10.1007/s00502-023-01162-0,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001062325100001,"ChatGPT and Generative AI Technology: A Mixed Bag of Concerns and New
Opportunities","ChatGPT has garnered unprecedented popularity since its release in
November 2022. This artificial intelligence (AI) large language model
(LLM) is designed to generate human-like text based on patterns found in
massive amounts of data scraped from the internet. ChatGPT is
significantly different from previous versions of GPT by its quality of
output, capability to interact and hold human-like conversations,
enormous speed, and ability to have its output refined by users or
experts. New iterations of ChatGPT as well as open source and
alternative LLMs, and ChatGPT plugins extend the current capabilities of
ChatGPT and offer unlimited opportunities to change how we do things.
Despite its newfound popularity and capabilities, ChatGPT is fraught
with concerns such as cheating, misinformation, bias, abuse and misuse,
and privacy and safety. On the other hand, the integration of ChatGPT in
the classroom prompts us to envision better ways of providing
instruction and assessment of writing skills. ChatGPT also provides
unparalleled approaches for personalized learning. As educators, we must
consider and deal with the serious concerns of using ChatGPT but
simultaneously explore how this AI technology can enhance and extend
current methods of instruction. In this paper, authors explain what
ChatGPT is and how it works, and future iterations of ChatGPT. They also
present concerns and opportunities, and educational implications of
using ChatGPT in the classroom.","Lambert, Judy and Stevens, Mark",COMPUTERS IN THE SCHOOLS,,2023,10.1080/07380569.2023.2256710,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000895694000004,"AI Technologies for Delivering Government Services to Citizens: Benefits
and Challenges","This research presents a comprehensive understanding of AI in the public
sector based on a review of 78 studies. The literature review indicates
that an AI-analytical model and AI-based automation system are mostly
used at the organizational level whilst AI-recommender and chatbot
applications are implemented within the citizens' services context. The
results reveal that AI benefits such as cost reduction and
decision-making improvements are accrued by governments. Further, the
benefits of personalization and positive user experiences are directly
useful to citizens. The review highlights that developing and adopting
AI, presents two categories of challenges: AI obstacles at the
organizational level, such as employees' resistance, lack of managerial,
and financial support, and second - AI dilemmas linked to citizens such
as AI ambiguity, bias, and privacy. Accordingly, this study provides
recommendations for further research on AI within the government and the
public sector.","Mohamad, Ibrahim and Hughes, Laurie and Dwivedi, Yogesh K. and Alalwan,
Ali Abdallah",,ROLE OF DIGITAL TECHNOLOGIES IN SHAPING THE POST-PANDEMIC WORLD,2022,10.1007/978-3-031-15342-6\_4,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000851402000025,"The Role of AI Chatbots in Mental Health Related Public Services in a
(Post)Pandemic World: A Review and Future Research Agenda","The purpose of this paper is to explore the advances in artificial
intelligence (AI) chatbots as part of public services, mainly when
applied to mental health in today's post-pandemic world. The adoption of
AI chatbots to keep up with basic customer support business activities
is based on extensive knowledge, both from the hard (software
development) and the soft side (increasing the added value to the
service/product). However, using chatbots as extenders of public
services to support mental health in pandemic times is an emerging
research topic. Hence, the paper identifies niche and under-explored
research gaps in state-of-the-art literature, thus contributing to the
body of academic knowledge. The paper adopts a design science approach
to formulate the problem statement, articulate the objectives of target
solutions, and propose a design and development framework for future
mental health chatbots by employing an extensive literature review.
Findings from this paper emphasize considerations of ethical issues and
governance, purposeful and goal-oriented design, and AI-based technology
as critical enablers for designing new mental health chatbots. The paper
contributes to the knowledge by providing clear and structured future
research priorities and offers a framework for designing more effective
and intelligent mental health chatbots that public organizations and
managers may find useful.","Damij, Nadja and Bhattacharya, Suman",,"2022 IEEE TECHNOLOGY AND ENGINEERING MANAGEMENT CONFERENCE (TEMSCON
EUROPE)",2022,10.1109/TEMSCONEUROPE54743.2022.9801962,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000935268200001,"What if the devil is my guardian angel: ChatGPT as a case study of using
chatbots in education","Artificial Intelligence (AI) technologies have been progressing
constantly and being more visible in different aspects of our lives. One
recent phenomenon is ChatGPT, a chatbot with a conversational artificial
intelligence interface that was developed by OpenAI. As one of the most
advanced artificial intelligence applications, ChatGPT has drawn much
public attention across the globe. In this regard, this study examines
ChatGPT in education, among early adopters, through a qualitative
instrumental case study. Conducted in three stages, the first stage of
the study reveals that the public discourse in social media is generally
positive and there is enthusiasm regarding its use in educational
settings. However, there are also voices who are approaching cautiously
using ChatGPT in educational settings. The second stage of the study
examines the case of ChatGPT through lenses of educational
transformation, response quality, usefulness, personality and emotion,
and ethics. In the third and final stage of the study, the investigation
of user experiences through ten educational scenarios revealed various
issues, including cheating, honesty and truthfulness of ChatGPT, privacy
misleading, and manipulation. The findings of this study provide several
research directions that should be considered to ensure a safe and
responsible adoption of chatbots, specifically ChatGPT, in education.","Tlili, Ahmed and Shehata, Boulus and Adarkwah, Michael Agyemang and
Bozkurt, Aras and Hickey, Daniel T. and Huang, Ronghuai and Agyemang,
Brighter",SMART LEARNING ENVIRONMENTS,,2023,10.1186/s40561-023-00237-x,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:001118038100252,"Exploring the Effects of Interactive Dialogue in Improving User Control
for Explainable Online Symptom Checkers","There has been a major push to improve the transparency of online
symptom checkers (OSCs) by providing more explanations to users about
their functioning and conclusions. However, not all users will want
explanations about all aspects of these systems. A more user-centered
approach is necessary for personalizing user experience of explanations.
With this in mind, we designed and tested an interactive dialogue
interface to afford user control to receive only those explanations that
they would like to read. A user study (N = 152) with a text-based
chatbot for assessing anxiety levels and presented explanations to
participants in one of the three forms-an interactive dialogue providing
choice for viewing different components of the explanations, a static
disclosure of all explanations, and a control condition with no
explanations whatsoever. We found that participants varied in the kinds
of information they wanted to learn. The interactive delivery of
explanations led to higher levels of perceived transparency and
affective trust in the system. Furthermore, both subjective and
objective understanding of the mechanism used for assessing anxiety was
higher for participants in the interactive dialogue condition. We
discuss theoretical and practical implications of imbuing interactivity
for enhancing the effectiveness of explainable systems.","Sun, Yuan and Sundar, S. Shyam",,"EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN
COMPUTING SYSTEMS, CHI 2022",2022,10.1145/3491101.3519668,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000627564200007,"Value Co-Creation in Smart Services: A Functional Affordances
Perspective on Smart Personal Assistants","In the realm of smart services, smart personal assistants (SPAs) have
become a popular medium for value co-creation between service providers
and users. The market success of SPAs is largely based on their
innovative material properties, such as natural language user
interfaces, machine learning-powered request handling and service
provision, and anthropomorphism. In different combinations, these
properties offer users entirely new ways to intuitively and
interactively achieve their goals and thus co-create value with service
providers. But how does the nature of the SPA shape value co-creation
processes? In this paper, we look through a functional affordances lens
to theorize about the effects of different types of SPAs (i.e., with
different combinations of material properties) on users' value
co-creation processes. Specifically, we collected SPAs from research and
practice by reviewing scientific literature and web resources, developed
a taxonomy of SPAs' material properties, and performed a cluster
analysis to group SPAs of a similar nature. We then derived 2 general
and 11 cluster-specific propositions on how different material
properties of SPAs can yield different affordances for value
co-creation. With our work, we point out that smart services require
researchers and practitioners to fundamentally rethink value co-creation
as well as revise affordances theory to address the dynamic nature of
smart technology as a service counterpart.","Knote, Robin and Janson, Andreas and Soellner, Matthias and Leimeister,
Jan Marco",JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS,,2021,10.17705/1jais.00667,,webofscience.bib,2024-02-25 11:35:41,Unclassified
WOS:000666754300001,"Monolingual and Cross-Lingual Intent Detection without Training Data in
Target Languages","Due to recent DNN advancements, many NLP problems can be effectively
solved using transformer-based models and supervised data.
Unfortunately, such data is not available in some languages. This
research is based on assumptions that (1) training data can be obtained
by the machine translating it from another language; (2) there are
cross-lingual solutions that work without the training data in the
target language. Consequently, in this research, we use the English
dataset and solve the intent detection problem for five target languages
(German, French, Lithuanian, Latvian, and Portuguese). When seeking the
most accurate solutions, we investigate BERT-based word and sentence
transformers together with eager learning classifiers (CNN, BERT
fine-tuning, FFNN) and lazy learning approach (Cosine similarity as the
memory-based method). We offer and evaluate several strategies to
overcome the data scarcity problem with machine translation,
cross-lingual models, and a combination of the previous two. The
experimental investigation revealed the robustness of sentence
transformers under various cross-lingual conditions. The accuracy equal
to similar to 0.842 is achieved with the English dataset with completely
monolingual models is considered our top-line. However, cross-lingual
approaches demonstrate similar accuracy levels reaching similar to
0.831, similar to 0.829, similar to 0.853, similar to 0.831, and similar
to 0.813 on German, French, Lithuanian, Latvian, and Portuguese
languages.","Kapociute-Dzikiene, Jurgita and Salimbajevs, Askars and Skadins, Raivis",ELECTRONICS,,2021,10.3390/electronics10121412,,webofscience.bib,2024-02-25 11:35:41,Unclassified
