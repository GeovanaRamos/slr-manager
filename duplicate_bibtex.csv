BibtexKey,Title,Abstract,Author,Journal,BookTitle,Year,Doi,Url,Source,CreatedAt,Status
Duvvuri2022111,Predicting Depression Symptoms from Discord Chat Messaging Using AI Medical Chatbots,"Depression is a chronic illness with even Olympic athletes [1] and top tennis players [2] withdrawing from competitions due to it. It's important to diagnose depression early. Traditional methods rely on questionnaires to evaluate depression. But they have their limitations due to inherent bias and inhibitions in self reporting. We propose an intelligent chatbot powered by AI approach to assist medical professionals diagnose depression. Specifically, the AI could predict depression symptoms in conversations with pre-care health care personnel and/or personal chats. Notably, due to sensitivity and privacy regulation (HIPPA) such data is not readily available [3]. To use AI driven medical assistants, and to overcome this limitation in training AI models, we propose to seed the models with recent chat engine (Discord) conversation dataset in the channel #depression. We achieve at least 73% accuracy in predicting seven key symptoms for depression using our best ML models. Secondly, with our ensemble random forest model we could recall 30-69% of depression symptoms with 60-99% depression diagnosis accuracy which could be further tuned by medical professional if they know which ones of these symptoms is a key predictor of depression.  © 2022 ACM.","Duvvuri, Venkata and Guan, Qihan and Daddala, Swetha and Harris, Mitch and Kaushik, Sudhakar",ACM International Conference Proceeding Series,,2022,10.1145/3523150.3523168,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128732969&doi=10.1145%2f3523150.3523168&partnerID=40&md5=f375d93733d928d970b322fe472202fe,scopus.bib,2023-09-02 14:05:29,Unclassified
Siddik2022146,Psyche Conversa - A Deep Learning Based Chatbot Framework to Detect Mental Health State,"Mental health is one of the most pressing challenges in today's modern world. Traditional thinking, family pressure, unemployment issues, homesickness, and an unhappy relationship are the most common reasons for mental illness, which may also lead to suicidal attempts. People in impoverished countries do not give this issue enough attention. Furthermore, many are hesitant to seek professional counseling from a psychiatrist to retain their privacy. Monitoring social media activities, in addition to common symptoms, is critical for improving the accuracy of detecting early signs of mental illness because it impacts mental health. So, rather than a psychiatrist, a user-friendly deep learning-based mobile application that will chat with them to support and monitor their social media behaviors to determine their mental health status will be an effective way of handling the situation. This study proposes a deep learning-based chatbot framework to help mentally ill individuals identify their mental health conditions and provide appropriate therapy. This framework comprises three components: a keylogger module, a chat module, and a deep learning-based mental illness detection module. In the background, the keylogger collects data from the user's keyboard to track social media activity. The chatbot converses with users and stores their daily chat history in real-time. Both modules pass the data to a deep learning model to determine mental health conditions. This study also compared the accuracy of multiple deep learning classifiers such as Conv-LSTM and BERT for the Reddit Mental Health Dataset.  © 2022 IEEE.","Siddik, Sayed Abu Noman and Arifuzzaman, B.M. and Kalam, Abul","2022 10th International Conference on Information and Communication Technology, ICoICT 2022",,2022,10.1109/ICoICT55009.2022.9914844,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141561034&doi=10.1109%2fICoICT55009.2022.9914844&partnerID=40&md5=70d694347e2d34765f1de197d37a837a,scopus.bib,2023-09-02 14:05:29,Unclassified
Antonio2022296,Study Literature Review: Discovering the Effect of Chatbot Implementation in E-commerce Customer Service System Towards Customer Satisfaction,"Customer service plays a crucial role for a company. As an important aspect of e-commerce companies, they would be required to directly interact and try to solve customers' problems that might occur anywhere and anytime. However, the limitation of human man hours became a barrier to overcome customers' problems. On one hand, the rapid development of technology was predicted to replace the traditional human customer service with an Artificial Intelligence agent. On the other hand, this replacement affects the customer satisfaction. This paper performed a study literature review to discover the effect of chatbots and its impact towards customer satisfaction. In an e-commerce customer service use case, chatbots could be implemented in a number of methods. The methods implemented by chatbots are avatar-based, verbal-based, text-based, and menu-based. Research showed that text-based chatbot is the most commonly used methodology and has advanced the most, where some are implementing higher level machine learning methods, such as deep learning. The usage of such chatbot in e-commerce customer service systems will lower the cost but might also lower customer satisfaction, due to reasons such as unsatisfying answers and inhuman behavior. Research showed that even a more sophisticated chatbot doesn't always mean higher customer satisfaction, even with high accuracy ratings. To look into customer satisfaction, this paper has identified 4 aspects of a chatbot that are relevant to customer satisfaction, which are privacy, reliability, personalization, and responsiveness. Chatbots currently excel in some of these quality measures, but require further research to effectively replace human customer service agents.  © 2022 IEEE.","Antonio, Randy and Tyandra, Nadya and Nusantara, Linggar Tembus and Anderies and Agung Santoso Gunawan, Alexander","2022 International Seminar on Application for Technology of Information and Communication: Technology 4.0 for Smart Ecosystem: A New Way of Doing Digital Business, iSemantic 2022",,2022,10.1109/iSemantic55962.2022.9920434,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141507114&doi=10.1109%2fiSemantic55962.2022.9920434&partnerID=40&md5=ae03b135befbc3b877a94b17cd6f3974,scopus.bib,2023-09-02 14:05:29,Unclassified
Gondaliya2020235,SLA as a mechanism to manage risks related to chatbot services.,Intelligent Chatbot services become one of the mainstream applications in user help and many other areas. Apart from bringing numerous benefits to users these services may bring additional risks to the companies that employ them. The study starts with the review of the scale of chatbot industry and common use cases by focusing on their applications industry tendencies. Review of functionality and architecture of typical chatbot services shows the potential risks associated with chatbots. Analysis of such risks in the paper helped to build a checklist that security managers can use to assess risks prior to chatbot implementation. The proposed checklist was tested by reviewing a number of Service Level Agreements (SLA) of real chatbot providers. © 2020 IEEE.,"Gondaliya, Krishna and Butakov, Sergey and Zavarsky, Pavol","Proceedings - 2020 IEEE 6th Intl Conference on Big Data Security on Cloud, BigDataSecurity 2020, 2020 IEEE Intl Conference on High Performance and Smart Computing, HPSC 2020 and 2020 IEEE Intl Conference on Intelligent Data and Security, IDS 2020",,2020,10.1109/BigDataSecurity-HPSC-IDS49724.2020.00050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087914640&doi=10.1109%2fBigDataSecurity-HPSC-IDS49724.2020.00050&partnerID=40&md5=d0206f9a3795783e74d1bb73e5c73499,scopus.bib,2023-09-02 14:05:29,Unclassified
Biswas2020179,Privacy Preserving Chatbot Conversations,"With chatbots gaining traction and their adoption growing in different verticals, e.g. Health, Banking, Dating; and users sharing more and more private information with chatbots - studies have started to highlight the privacy risks of chatbots. In this paper, we propose two privacypreserving approaches for chatbot conversations. The first approach applies 'entity' based privacy filtering and transformation, and can be applied directly on the app (client) side. It however requires knowledge of the chatbot design to be enabled. We present a second scheme based on Searchable Encryption that is able to preserve user chat privacy, without requiring any knowledge of the chatbot design. Finally, we present some experimental results based on a real-life employee Help Desk chatbot that validates both the need and feasibility of the proposed approaches. © 2020 IEEE.","Biswas, Debmalya","Proceedings - 2020 IEEE 3rd International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2020",,2020,10.1109/AIKE48582.2020.00035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101913467&doi=10.1109%2fAIKE48582.2020.00035&partnerID=40&md5=a1377d90a202e134c79524b49f7c47b9,scopus.bib,2023-09-02 14:05:29,Unclassified
Tian20221119,A Privacy-Preserving Framework for Mental Health Chatbots Based on Confidential Computing,"Mental health chatbots can provide psychological counseling services to patients at any time regardless of time and location, which can not only relieve patients' ailments but also reduce the workload of psychologists. In order to provide patients with accurate diagnosis and treatment services, mental health robots inevitably collect patient-related information during the communication process with patients, which is often very sensitive and must be well protected. There is a lack of targeted research on how mental health chatbots can provide systematic privacy preserving for patients in the process of providing mental health services to them. In this paper, we propose a privacy preserving framework based on blockchain and confidential computing that can provide comprehensive privacy preserving for patients during mental health chatbot services. We conduct tests using existing mental health chatbots, and the experimental results demonstrate that our proposed framework can meet the requirements for privacy preserving and computational performance of mental health chatbots. © 2022 IEEE.","Tian, Wensheng and Lu, Yifan and Yu, Jinhao and Fan, Jiafeng and Tang, Panpan and Zhang, Lei","Proceedings - 2022 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Autonomous and Trusted Vehicles, Scalable Computing and Communications, Digital Twin, Privacy Computing, Metaverse, SmartWorld/UIC/ATC/ScalCom/DigitalTwin/PriComp/Metaverse 2022",,2022,10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00160,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168083316&doi=10.1109%2fSmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00160&partnerID=40&md5=f30dfb863c56273a453922ae620daa4f,scopus.bib,2023-09-02 14:05:29,Unclassified
Langevin2021,Heuristic evaluation of conversational agents,"Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen's heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We fnd that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen's heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy. © 2021 ACM.","Langevin, Raina and Lordon, Ross and Avrahami, Thi",Conference on Human Factors in Computing Systems - Proceedings,,2021,10.1145/3411764.3445312,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106676286&doi=10.1145%2f3411764.3445312&partnerID=40&md5=97eb7045f0d827c64ee03c2d91ea7002,scopus.bib,2023-09-02 14:05:29,Unclassified
Baudart201899,Protecting chatbots from toxic content,"There is a paradigm shift in web-based services towards conversational user interfaces. Companies increasingly offer conversational interfaces, or chatbots, to let their customers or employees interact with their services in a more flexible and mobile manner. Unfortunately, this new paradigm faces a major problem, namely toxic content in user inputs. Toxic content in user inputs to chatbots may cause privacy concerns, may be adversarial or malicious, and can cause the chatbot provider substantial economic, reputational, or legal harm. We address this problem with an interdisciplinary approach, drawing upon programming languages, cloud computing, and other disciplines to build protections for chatbots. Our solution, called BotShield, is non-intrusive in that it does not require changes to existing chatbots or underlying conversational platforms. This paper introduces novel security mechanisms, articulates their security guarantees, and illustrates them via case studies.  © 2018 ACM.","Baudart, Guillaume and Dolby, Julian and Duesterwald, Evelyn and Hirzel, Martin and Shinnar, Avraham","Onward! 2018 - Proceedings of the 2018 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, co-located with SPLASH 2018",,2018,10.1145/3276954.3276958,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093738628&doi=10.1145%2f3276954.3276958&partnerID=40&md5=d16e8a099896bc18c52701d201b7af18,scopus.bib,2023-09-02 14:05:29,Unclassified
Yorita2021,Development of Esteem Support based on Psychodrama and Design Thinking approach,"So far, we have proposed the Stress management framework and developed methods for stress measurement and coping. There are three types of coping in this framework: information support, emotional support, and esteem support. This time, we developed esteem support. In order to increase self-esteem, we focused on psychodrama techniques and developed a system to realize psychodrama using robots. The advantages of using robots include the ability to carry out a psychodrama alone and to provide privacy-friendly support. In the experiment, a scenario was created for medical staff and a robot psychodrama was performed. As a result, we showed that robots can be used for psychodrama and esteem support can be carried out by combination of robots and the chatbot. © 2021 IEEE.","Yorita, Akihiro and Egerton, Simon and Chan, Carina and Kubota, Naoyuki","2021 IEEE Symposium Series on Computational Intelligence, SSCI 2021 - Proceedings",,2021,10.1109/SSCI50451.2021.9660118,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125803809&doi=10.1109%2fSSCI50451.2021.9660118&partnerID=40&md5=aed3cb6b616405ffc4df91c741236c78,scopus.bib,2023-09-02 14:05:29,Unclassified
Farah20221634,Impersonating Chatbots in a Code Review Exercise to Teach Software Engineering Best Practices,"Over the past decade, the use of chatbots for educational purposes has gained considerable traction. A similar trend has been observed in social coding platforms, where automated agents support software developers with tasks such as performing code reviews. While incorporating code reviews and social coding platforms into software engineering education has been found to be beneficial, challenges such as steep learning curves and privacy considerations are barriers to their adoption. Furthermore, no study has addressed the role chatbots play in supporting code reviews as a pedagogical tool. To help address this gap, we developed an online learning application that simulates the code review features available on social coding platforms and allows instructors to interact with students using chatbot identities. We then embedded this application within a lesson on software engineering best practices and conducted a controlled in-class experiment. This experiment examined the effect that explaining content via chatbot identities had on three aspects: (i) students' perceived usability of the lesson, (ii) their engagement with the code review process, and (iii) their learning gains. While our findings show that it is feasible to simulate the code review process within an online learning platform and achieve good usability, our quantitative analysis did not yield significant differences across treatment conditions for any of the aspects considered. Nevertheless, our qualitative results suggest that students expect explicit feedback when performing this type of exercise and could thus benefit from automated replies provided by an interactive chatbot. We propose to build on our current findings to further explore this line of research in future work. © 2022 IEEE.","Farah, Juan Carlos and Spaenlehauer, Basile and Sharma, Vandit and Rodriguez-Triana, Maria Jesus and Ingram, Sandy and Gillet, Denis","IEEE Global Engineering Education Conference, EDUCON",,2022,10.1109/EDUCON52537.2022.9766793,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130493554&doi=10.1109%2fEDUCON52537.2022.9766793&partnerID=40&md5=d4fa40bf638c4210a392bbdbce4a96d1,scopus.bib,2023-09-02 14:05:29,Unclassified
Kumar20201627,Work-in-progress: A preliminary study on students' acceptance of chatbots for studio-based learning,"Studio-based learning (SBL) is a pedagogy that encompasses collaborative active learning strategies focusing on creativity, peer learning, and problem-solving. The iterative design procedures and critique sessions are the primary learning practices of SBL, which relays to a need to have effective communication between instructors and students. Due to this, we designed a Telegram chatbot using the TextIt to facilitate some of the interactions that are common in SBL. In this preliminary study, students' acceptance of chatbot was investigated based on the Technology Acceptance Model (TAM) using a mix-method approach. Preliminary results indicated positive acceptance and intention to use chatbots due to ease of use, mobile accessibility, human-like communications, and privacy in communicating and providing feedback. © 2020 IEEE.","Kumar, Jeya Amantha and Silva, Paula Alexandra","IEEE Global Engineering Education Conference, EDUCON",,2020,10.1109/EDUCON45650.2020.9125183,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087877672&doi=10.1109%2fEDUCON45650.2020.9125183&partnerID=40&md5=8a984b08dd1cfc21c36d79fc09df5fa4,scopus.bib,2023-09-02 14:05:29,Unclassified
Tran202263,Privacy and Security in Mixed Reality Learning Environments by Input and User/Bot Interaction Protection,"Mixed reality is known as an advanced technology that provides a new approach for learning environments. Such environments allow learners to interact with both virtual and real worlds and bringing in potential enhancements to the learning process at the same time. For example, chatbots can facilitate the learning process. However, security and privacy settings for interacting with chatbots in such mixed reality environments are complex. In this paper, we introduce a mixed reality virtual assistant that is integrated into the collaborative environment of our existing application VIAProMa. This embodied chatbot allows lecturers and students to participate in mixed reality and online classrooms in real-time. The participants can interact with each other via VIAProMa's avatar representations and can communicate with the chatbot that is represented by the mixed reality bot. The bot is realized by connecting a Slack chatbot with the mixed reality learning environment. It is displayed as an intuitive 3D model and is able to communicate with the users in spoken language. In this environment, privacy and security settings are conducted to protect the user input and user interaction with the bot. The evaluation results show that the system works stably with good performance. All the visualizations and features are well designed and were understood by the users. Users preferred the speech interface with the bot over a textual interface. The research has a strong impact on the design of security and privacy features for mixed reality environments in general.  © 2022 ACM.","Tran, Lan Anh and Hensen, Benedikt and Klamma, Ralf and Chantaraskul, Soamsiri",ACM International Conference Proceeding Series,,2022,10.1145/3512353.3512363,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126631945&doi=10.1145%2f3512353.3512363&partnerID=40&md5=b0ac966a83a3ccf6fa6880e3ee6b615b,scopus.bib,2023-09-02 14:05:29,Unclassified
Lin201986,Children privacy identification system in LINE chatbot for smart toys,"Children's privacy concerns about smart toys are becoming more and more critical in the toy industry. Parents and guardians continue to strive to protect their children from unnecessary privacy risks such as collection, and unconsented use of or access to their children's information. However, there is still no standardized privacy framework, which focuses on smart toys in this paradigm; making it difficult to determine possible privacy violation in for example determining whether a phrase shared with a smart toy is sensitive or not. To overcome this challenge, we build a privacy identification system through Chatbot technology. We call this system a Children Privacy Identification (CPI) system. To develop CPI system, we divide our research works into two parts: (1) Collect the phrase from the smart toys; and (2) Explore privacy Identification based on Personally Identifiable Information (PII) and Children's Online Privacy Protection Act (COPPA). For illustration, we integrate the CPI system in LINE Chatbot. The result shows that people feel more comfortable in talking to LINE Chatbot with privacy protection. © 2019 IEEE.","Lin, Pei-Chun and Yankson, Benjamin and Lu, Zhihui and Hung, Patrick C.K.","IEEE International Conference on Cloud Computing, CLOUD",,2019,10.1109/CLOUD.2019.00026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072338496&doi=10.1109%2fCLOUD.2019.00026&partnerID=40&md5=ea40d0f4e65aaf24f3fefecf347fe750,scopus.bib,2023-09-02 14:05:29,Unclassified
Wickramarathna202230,Oxygen: A Distributed Health Care Framework for Patient Health Record Management and Pharmaceutical Diagnosis,"With the COVID-19 pandemic, the world is confronting various healthcare issues, and healthcare automation is more crucial than ever. The pandemic has revealed the limitations of existing digital healthcare systems to manage public health emergencies. There is no registered population for many healthcare institutions in Sri Lanka, as a result, there is a communication gap. Electronic Health Record systems (EHRs) are becoming popular to share patient details but accessing scattered data across several EHRs while safeguarding patient privacy remains a challenge. Most of these medical records are in printed format and manually entering those into EHR systems is time-consuming and error prone. Not only that pharmaceutical error is a critical healthcare problem, but it is even riskier to visit doctors for pharmaceutical diagnosis during a pandemic. This research introduces a Blockchain-based patient health record system, an Optical Character Recognition (OCR) and Natural Language Processing (NLP) based Medical Document Scanner, a Drug Identifier based on Image Processing and a Medical Chatbot powered by NLP as four novel approaches to address these issues. Altogether with the results, this research aims at introducing a solution for the limitations in healthcare while providing a distributed healthcare framework for the healthcare community worldwide. © 2022 IEEE.","Wickramarathna, Maleesha and De Silva, Kithmini and Lekamalage, Vihanga and Senanayake, Janith and Perera, Jeewaka and Ruggahakotuwa, Laneesha","4th International Conference on Advancements in Computing, ICAC 2022 - Proceeding",,2022,10.1109/ICAC57685.2022.10025250,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148598258&doi=10.1109%2fICAC57685.2022.10025250&partnerID=40&md5=67fb84dc6e56ee09a4d23409c86fde6f,scopus.bib,2023-09-02 14:05:29,Unclassified
Bang2021,Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations,"AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.  © 2021 IEEE.","Bang, Junseong and Kim, Sineae and Nam, Jang Won and Yang, Dong-Geun","2021 International Conference on Platform Technology and Service, PlatCon 2021 - Proceedings",,2021,10.1109/PlatCon53246.2021.9680760,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126254756&doi=10.1109%2fPlatCon53246.2021.9680760&partnerID=40&md5=c1adfcc34ee611e791a3514721a1fafe,scopus.bib,2023-09-02 14:05:29,Unclassified
Srivastava201912,Hospitality of chatbot building platforms,"The temptation to be able to talk to a machine is not new. Recent advancements in the field of Natural Language Understanding has made it possible to build conversational components that can be plugged inside an application, similar to other components. These components, called chatbots, can be created from scratch or with the help of commercially available platforms. These platforms make it easier to build and deploy chatbots, often without writing a single line of code. However, similar to any other software component, chatbots also have quality concerns. Despite significant contributions in the field, an architectural perspective of building chatbots with desired quality requirements is missing in the literature. In the current work, we highlight the impact of features provided by these platforms (along with their quality) on the application design process and overall quality attributes. We propose a methodological framework to evaluate support provided by a chatbot platform towards achieving quality in the application. The framework, called Hospitality Framework, is based on software architectural body of knowledge, especially architectural tactics. The framework produces a metric, called Hospitality Index, which has utilities for making various design decisions for the overall application. We present the use of our framework on a simple use case to highlight the phases of evaluation.We showcase the process by picking three popular chatbot platforms - Watson Assistant, DialogFlow and Lex, over four quality attributes - Modifiability, Security & Privacy, Interoperability and Reliability. Our results show that different platforms provide different support for these four quality attributes. Copyright © SQUADE 2019 ACM SIGSOFT International Workshop on Software Qualities and Their Dependencies, co-located with ESEC/FSE 2019.All right reserved.","Srivastava, Saurabh and Prabhakar, T.V.","SQUADE 2019 - Proceedings of the 2nd ACM SIGSOFT International Workshop on Software Qualities and Their Dependencies, co-located with ESEC/FSE 2019",,2019,10.1145/3340495.3342751,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076478035&doi=10.1145%2f3340495.3342751&partnerID=40&md5=e843563d3049e4d2b9860b299c0c9798,scopus.bib,2023-09-02 14:05:29,Unclassified
Arora201815,Exploring Siamese neural network architectures for preserving speaker identity in speech emotion classification,"Voice-enabled communication is increasingly being used in real-world applications, such as the ones involving conversational bots or “chatbots”. Chatbots can spark and sustain user engagement by effectively recognizing their emotions and acting upon them. However, the majority of emotion recognition systems rely on rich spectrotemporal acoustic features. Beyond the emotion-related information, such systems tend to preserve information relevant to the identity of the speaker, therefore raising major privacy concerns from the users. This paper introduces two hybrid architectures for privacy-preserving emotion recognition from speech. These architectures rely on a Siamese neural network, whose input and intermediate layers are transformed using various privacy-performing operations in order to retain emotion-dependent content and suppress information related to the identity of a speaker. The proposed approach is evaluated through emotion classification and speaker identification performance metrics. Results indicate that the proposed framework can achieve up to 67.4% for classifying between happy, sad, frustrated, anger, neutral and other emotions, obtained from the publicly available Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset. At the same time, the proposed approach reduces speaker identification accuracy to 50%, compared to 81%, the latter being achieved through a feedforward neural network solely trained on the speaker identification task using the same input features. © 2018 Association for Computing Machinery.","Arora, Priya and Chaspari, Theodora","Proceedings of the 4th Workshop on Multimodal Analyses Enabling Artificial Agents in Human-Machine Interaction, MA3HMI 2018 - In conjunction with ICMI 2018",,2018,10.1145/3279972.3279980,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058175685&doi=10.1145%2f3279972.3279980&partnerID=40&md5=df3053ad6f6699356bcab7aa1cea1c5a,scopus.bib,2023-09-02 14:05:29,Unclassified
WOS:000882790100004,"Designing, Developing, Evaluating, and Implementing a
Smartphone-Delivered, Rule-Based Conversational Agent (DISCOVER):
Development of a Conceptual Framework","Background: Conversational agents (CAs), also known as chatbots, are
computer programs that simulate human conversations by using
predetermined rule-based responses or artificial intelligence
algorithms. They are increasingly used in health care, particularly via
smartphones. There is, at present, no conceptual framework guiding the
development of smartphone-based, rule-based CAs in health care. To fill
this gap, we propose structured and tailored guidance for their design,
development, evaluation, and implementation. Objective: The aim of this
study was to develop a conceptual framework for the design, evaluation,
and implementation of smartphone-delivered, rule-based, goal-oriented,
and text-based CAs for health care. Methods: We followed the approach by
Jabareen, which was based on the grounded theory method, to develop this
conceptual framework. We performed 2 literature reviews focusing on
health care CAs and conceptual frameworks for the development of mobile
health interventions. We identified, named, categorized, integrated, and
synthesized the information retrieved from the literature reviews to
develop the conceptual framework. We then applied this framework by
developing a CA and testing it in a feasibility study. Results: The
Designing, Developing, Evaluating, and Implementing a
Smartphone-Delivered, Rule-Based Conversational Agent (DISCOVER)
conceptual framework includes 8 iterative steps grouped into 3 stages,
as follows: design, comprising defining the goal, creating an identity,
assembling the team, and selecting the delivery interface; development,
including developing the content and building the conversation flow; and
the evaluation and implementation of the CA. They were complemented by 2
cross-cuttingconsiderations-user-centered design and privacy and
security-that were relevant at all stages. This conceptual framework was
successfully applied in the development of a CA to support lifestyle
changes and prevent type 2 diabetes. Conclusions: Drawing on published
evidence, the DISCOVER conceptual framework provides a step-by-step
guide for developing rule-based, smartphone-delivered CAs. Further
evaluation of this framework in diverse health care areas and settings
and for a variety of users is needed to demonstrate its validity. Future
research should aim to explore the use of CAs to deliver health care
interventions, including behavior change and potential privacy and
safety concerns.","Dhinagaran, Dhakshenya Ardhithy and Martinengo, Laura and Ho, Moon-Ho
Ringo and Joty, Shafiq and Kowatsch, Tobia and Atun, Rifat and Car,
Lorainne Tudor",JMIR MHEALTH AND UHEALTH,,2022,10.2196/38740,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000556208000013,Children Privacy Identification System in LINE Chatbot for Smart Toys,"Children's privacy concerns about smart toys are becoming more and more
critical in the toy industry. Parents and guardians continue to strive
to protect their children from unnecessary privacy risks such as
collection, and unconsented use of or access to their children's
information. However, there is still no standardized privacy framework,
which focuses on smart toys in this paradigm; making it difficult to
determine possible privacy violation in for example determining whether
a phrase shared with a smart toy is sensitive or not. To overcome this
challenge, we build a privacy identification system through Chatbot
technology. We call this system a Children Privacy Identification (CPI)
system. To develop CPI system, we divide our research works into two
parts: (1) Collect the phrase from the smart toys; and (2) Explore
privacy Identification based on Personally Identifiable Information
(PII) and Children's Online Privacy Protection Act (COPPA). For
illustration, we integrate the CPI system in LINE Chatbot. The result
shows that people feel more comfortable in talking to LINE Chatbot with
privacy protection.","Lin, Pei-Chun and Yankson, Benjamin and Lu, Zhihui and Hung, Patrick C.
K.",,"2019 IEEE 12TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (IEEE CLOUD
2019)",2019,10.1109/CLOUD.2019.00026,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000675475500029,Privacy Preserving Chatbot Conversations,"With chatbots gaining traction and their adoption growing in different
verticals, e.g. Health, Banking, Dating; and users sharing more and more
private information with chatbots - studies have started to highlight
the privacy risks of chatbots. In this paper, we propose two
privacy-preserving approaches for chatbot conversations. The first
approach applies `entity' based privacy filtering and transformation,
and can be applied directly on the app (client) side. It however
requires knowledge of the chatbot design to be enabled. We present a
second scheme based on Searchable Encryption that is able to preserve
user chat privacy, without requiring any knowledge of the chatbot
design. Finally, we present some experimental results based on a
real-life employee Help Desk chatbot that validates both the need and
feasibility of the proposed approaches.","Biswas, Debmalya",,"2020 IEEE THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND
KNOWLEDGE ENGINEERING (AIKE 2020)",2020,10.1109/AIKE48582.2020.00035,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000792102900001,"Drivers of privacy concerns when interacting with a chatbot in a
customer service encounter","Purpose This study aims to examine the antecedents of privacy concerns
in the era of artificial intelligence. Specifically, it focuses on the
impact of various factors related to interactions with a chatbot
(creepiness and perceived risk) and individual traits (familiarity with
chatbots and need for privacy) in relation to privacy when interacting
with a chatbot in the context of financial services. The moderating
effect of gender on these relationships was also examined.
Design/methodology/approach A total of 430 Canadians responded to an
online questionnaire after interacting with a chatbot in the context of
a simulated auto insurance quote. A structural equation model was used
to test the hypotheses. Findings The results showed that privacy
concerns are influenced primarily by creepiness, followed by perceived
risk and the need for privacy. The last two relationships are moderated
by gender. Conversely, familiarity with chatbots does not affect privacy
concerns in this context. Originality/value This study is the first to
consider the influence of creepiness as an antecedent of privacy
concerns arising from interactions with AI tools and highlight its key
impacts. It also shows how gender moderates specific relationships in
this context.","Bouhia, Mariem and Rajaobelina, Lova and PromTep, Sandrine and Arcand,
Manon and Ricard, Line",INTERNATIONAL JOURNAL OF BANK MARKETING,,2022,10.1108/IJBM-09-2021-0442,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000657463100001,"Chatbots: Security, privacy, data protection, and social aspects","Chatbots are artificial communication systems becoming increasingly
popular and not all their security questions are clearly solved. People
use chatbots for assistance in shopping, bank communication, meal
delivery, healthcare, cars, and many other actions. However, it brings
an additional security risk and creates serious security challenges
which have to be handled. Understanding the underlying problems requires
defining the crucial steps in the techniques used to design chatbots
related to security. There are many factors increasing security threats
and vulnerabilities. All of them are comprehensively studied, and
security practices to decrease security weaknesses are presented. Modern
chatbots are no longer rule-based models, but they employ modern natural
language and machine learning techniques. Such techniques learn from a
conversation, which can contain personal information. The paper
discusses circumstances under which such data can be used and how
chatbots treat them. Many chatbots operate on a social/messaging
platform, which has their terms and conditions about data. The paper
aims to present a comprehensive study of security aspects in
communication with chatbots. The article could open a discussion and
highlight the problems of data storage and usage obtained from the
communication user-chatbot and propose some standards to protect the
user.","Hasal, Martin and Nowakova, Jana and Saghair, Khalifa Ahmed and Abdulla,
Hussam and Snasel, Vaclav and Ogiela, Lidia",CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE,,2021,10.1002/cpe.6426,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000951832100001,"I, chatbot! the impact of anthropomorphism and gaze direction on
willingness to disclose personal information and behavioral intentions","The present research focuses on the interplay between two common
features of the customer service chatbot experience: gaze direction and
anthropomorphism. Although the dominant approach in marketing theory and
practice is to make chatbots as human-like as possible, the current
study, built on the humanness-value-loyalty model, addresses the chain
of effects through which chatbots' nonverbal behaviors affect customers'
willingness to disclose personal information and purchase intentions. By
means of two experiments that adopt a real chatbot in a simulated
shopping environment (i.e., car rental and travel insurance), the
present work allows us to understand how to reduce individuals' tendency
to see conversational agents as less knowledgeable and empathetic
compared with humans. The results show that warmth perceptions are
affected by gaze direction, whereas competence perceptions are affected
by anthropomorphism. Warmth and competence perceptions are found to be
key drivers of consumers' skepticism toward the chatbot, which, in turn,
affects consumers' trust toward the service provider hosting the
chatbot, ultimately leading consumers to be more willing to disclose
their personal information and to repatronize the e-tailer in the
future. Building on the Theory of Mind, our results show that perceiving
competence from a chatbot makes individuals less skeptical as long as
they feel they are good at detecting others' ultimate intentions.","Pizzi, Gabriele and Vannucci, Virginia and Mazzoli, Valentina and
Donvito, Raffaele",PSYCHOLOGY \& MARKETING,,2023,10.1002/mar.21813,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000634342000001,"EREBOTS: Privacy-Compliant Agent-Based Platform for Multi-Scenario
Personalized Health-Assistant Chatbots","Context. Asynchronous messaging is increasingly used to support
human-machine interactions, generally implemented through chatbots. Such
virtual entities assist the users in activities of different kinds
(e.g., work, leisure, and health-related) and are becoming ingrained
into humans' habits due to factors including (i) the availability of
mobile devices such as smartphones and tablets, (ii) the increasingly
engaging nature of chatbot interactions, (iii) the release of dedicated
APIs from messaging platforms, and (iv) increasingly complex AI-based
mechanisms to power the bots' behaviors. Nevertheless, most of the
modern chatbots rely on state machines (implementing conversational
rules) and one-fits-all approaches, neglecting personalization,
data-stream privacy management, multi-topic management/interconnection,
and multimodal interactions. Objective. This work addresses the
challenges above through an agent-based framework for chatbot
development named EREBOTS. Methods. The foundations of the framework are
based on the implementation of (i) multi-front-end connectors and
interfaces (i.e., Telegram, dedicated App, and web interface), (ii)
enabling the configuration of multi-scenario behaviors (i.e., preventive
physical conditioning, smoking cessation, and support for breast-cancer
survivors), (iii) online learning, (iv) personalized conversations and
recommendations (i.e., mood boost, anti-craving persuasion, and
balance-preserving physical exercises), and (v) responsive multi-device
monitoring interface (i.e., doctor and admin). Results. EREBOTS has been
tested in the context of physical balance preservation in social
confinement times (due to the ongoing pandemic). Thirteen individuals
characterized by diverse age, gender, and country distribution have
actively participated in the experimentation, reporting advancements in
the physical balance and overall satisfaction of the interaction and
exercises' variety they have been proposed.","Calvaresi, Davide and Calbimonte, Jean-Paul and Siboni, Enrico and
Eggenschwiler, Stefan and Manzo, Gaetano and Hilfiker, Roger and
Schumacher, Michael",ELECTRONICS,,2021,10.3390/electronics10060666,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000787145300001,"Trust and digital privacy: willingness to disclose personal information
to banking chatbot services","This study explored digital privacy concerns in the use of chatbots as a
digital banking service. Three dimensions of trust were tested in
relation to user self-disclosure in order to better understand the
consumer-chatbot experience in banking. The methodology selected for
this research study followed a conclusive, pre-experimental, two-group
one-shot case study research design which made use of a non-probability
snowballing sampling technique. Privacy concerns were found to have a
significantly negative relationship with user self-disclosure in both
treatment groups. Respondents exposed to their preferred banking brand
experienced lower user self-disclosure and brand trust than those
exposed to a fictitious banking brand within the South African context.
It is recommended that companies using chatbots focus on easing privacy
concerns and build foundations of trust. The gains that chatbots have
made in the form of increased productivity and quality of customer
service rely on relationships with users who need to disclose personal
information. Through this study, we concluded that, despite its power to
influence decision-making, the power of a brand is not enough for
consumers to considerably increase self-disclosure. Rather, a bridge of
trust (through education, communication and product development) is
needed that encompasses all three elements of trust, which are brand
trust, cognitive trust and emotional trust. Limited research exists on
the relationship between financial services marketing and chatbot
adoption. Thus, this study addressed a theoretical gap, by adding brand
trust to existing studies on cognitive and emotional trust regarding
user self-disclosure.","Lappeman, James and Marlie, Siddeeqah and Johnson, Tamryn and
Poggenpoel, Sloane",JOURNAL OF FINANCIAL SERVICES MARKETING,,2023,10.1057/s41264-022-00154-z,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000631254500039,SLA as a mechanism to manage risks related to chatbot services.,"Intelligent Chatbot services become one of the mainstream applications
in user help and many other areas. Apart from bringing numerous benefits
to users these services may bring additional risks to the companies that
employ them. The study starts with the review of the scale of chatbot
industry and common use cases by focusing on their applications \&
industry tendencies. Review of functionality and architecture of typical
chatbot services shows the potential risks associated with chatbots.
Analysis of such risks in the paper helped to build a checklist that
security managers can use to assess risks prior to chatbot
implementation. The proposed checklist was tested by reviewing a number
of Service Level Agreements (SLA) of real chatbot providers.","Gondaliya, Krishna and Butakov, Sergey and Zavarsky, Pavol",,"2020 IEEE 6TH INT CONFERENCE ON BIG DATA SECURITY ON CLOUD
(BIGDATASECURITY) / 6TH IEEE INT CONFERENCE ON HIGH PERFORMANCE AND
SMART COMPUTING, (HPSC) / 5TH IEEE INT CONFERENCE ON INTELLIGENT DATA
AND SECURITY (IDS)",2020,10.1109/BigDataSecurity-HPSC-IDS49724.2020.00050,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000877356400002,"Should the chatbot ?save itself? or ?be helped by others?? The influence
of service recovery types on consumer perceptions of recovery
satisfaction","The application of artificial intelligence is considered essential to
adapt to a new cycle of industrial trans-formation and technological
advancements in many fields and industries. The extensive use of
artificial intel-ligence technology is expected to improve the level and
quality of services provided by companies adopting these methods. In
this study, we propose a novel approach to self-recovery by chatbot
systems after service failures based on social response theory.
Moreover, we explore differences in consumer perceptions of different
service recovery types and their impact on recovery satisfaction, and
discusses whether the intelligence of the compu-tational agent also has
an effect. We present the results of three scenario-based experiments,
which demonstrate the positive effect of chatbot self-recovery on
consumer satisfaction, and show the mediating paths of service recovery
types in terms of perceived functional value and privacy risks as well
as the boundary condition of the level of robot intelligence. This work
expands the range of applications of chatbots in the service industry
and provides a new framework for the governance of artificial
intelligence.","Song, Mengmeng and Du, Jingzhe and Xing, Xinyu and Mou, Jian",ELECTRONIC COMMERCE RESEARCH AND APPLICATIONS,,2022,10.1016/j.elerap.2022.101199,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000708832400002,"Future directions for chatbot research: an interdisciplinary research
agenda","Chatbots are increasingly becoming important gateways to digital
services and information-taken up within domains such as customer
service, health, education, and work support. However, there is only
limited knowledge concerning the impact of chatbots at the individual,
group, and societal level. Furthermore, a number of challenges remain to
be resolved before the potential of chatbots can be fully realized. In
response, chatbots have emerged as a substantial research area in recent
years. To help advance knowledge in this emerging research area, we
propose a research agenda in the form of future directions and
challenges to be addressed by chatbot research. This proposal
consolidates years of discussions at the CONVERSATIONS workshop series
on chatbot research. Following a deliberative research analysis process
among the workshop participants, we explore future directions within six
topics of interest: (a) users and implications, (b) user experience and
design, (c) frameworks and platforms, (d) chatbots for collaboration,
(e) democratizing chatbots, and (f) ethics and privacy. For each of
these topics, we provide a brief overview of the state of the art,
discuss key research challenges, and suggest promising directions for
future research. The six topics are detailed with a 5-year perspective
in mind and are to be considered items of an interdisciplinary research
agenda produced collaboratively by avid researchers in the field.","Folstad, Asbjorn and Araujo, Theo and Law, Effie Lai-Chong and
Brandtzaeg, Petter Bae and Papadopoulos, Symeon and Reis, Lea and Baez,
Marcos and Laban, Guy and McAllister, Patrick and Ischen, Carolin and
Wald, Rebecca and Catania, Fabio and Meyer von Wolff, Raphael and
Hobert, Sebastian and Luger, Ewa",COMPUTING,,2021,10.1007/s00607-021-01016-7,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000778774900010,"Ethical Chatbot Design for Reducing Negative Effects of Biased Data and
Unethical Conversations","AI technology is being introduced into various public and private
service domains, transforming existing computing systems or creating new
ones. While AI technologies can provide benefits to humans and society,
the unexpected consequences (e.g., malfunctions) of AI systems can cause
social losses. For this reason, research on ethical design for the
development of AI-based systems is becoming important. In this paper,
from existing studies on AI ethics, general guidelines such as
transparency, explainability, predictability, accountability, fairness,
privacy, and control for the ethical design of AI systems are reviewed.
And, based on the ethical design guidelines, we discuss ethical design
to reduce the negative effects of biased data and unethical dialogues in
AI-based conversational chatbots.","Bang, Junseong and Kim, Sineae and Nam, Jang Won and Yang, Dong-Geun",,"2021 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE
(PLATCON)",2021,10.1109/PlatCon53246.2021.9680760,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000812885900002,Chatbot for construction firms using scalable blockchain network,"Information and Communication Technologies (ICT), including multimedia
tools, email services, voice-based tools, and handheld computing tools,
have been extensively used for automating and digitalizing different
construction processes and activities. However, these technologies are
subjected to single-point attacks or failures, manipulation, and lack of
privacy and traceability. This study introduces a novel information
exchange and management system for construction firms based on
blockchain technology and chatbots. The system leverages the
characteristics of blockchain technology in terms of peer-to-peer
operation mode, data integrity, structuring, and privacy, and the
chatbots' merits regarding ease of use and degree of automation. The
system is developed for tracking work progress in construction projects
as a generic use-case using a four-step approach. First, a private
blockchain network is configured for data distribution and storage.
Second, a smart contract is coded for regulating data writing/reading
operations. Third, a chatbot is developed for data collection and
retrieval through textual conversations. Fourth, serverless cloud
function and cloudant database are configured to allow the linkage
between the blockchain network and the chatbot. A prototype of the
system is built and applied to a case study of non-residential
construction project to test and verify its capabilities. Further, the
system's performance is assessed in terms of the writing and reading
latencies and the storage size. The system features can be extended by
embedding mathematical algorithms to simultaneously analyze data and
employing Inter-Planetary File System (IPFS) to maintain visuals and
large-size data.","Adel, Kareem and Elhakeem, Ahmed and Marzouk, Mohamed",AUTOMATION IN CONSTRUCTION,,2022,10.1016/j.autcon.2022.104390,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000653143000001,"Digital transformation in financial services provision: a Nigerian
perspective to the adoption of chatbot","Purpose
Recognising the high numbers of unbanked and financially excluded adults
in Nigeria, this study aims to position chatbot as a digital
transformation tool to radically change business model, improve customer
experience and enhance financial inclusion in emerging markets.
Design/methodology/approach
The Search-Access-Test (S-A-T) model was adopted to understand how
Nigerian banks are adopting chatbots.
Findings
A majority of Nigerian banks now have chatbots that enhance customer
engagement and financial inclusion. WhatsApp was the most frequently
used platform. Chatbots were often branded and presented with female
gender identification. The chatbots were less responsive beyond their
predefined path. While Nigeria is a multilingual country with English
being the original language, none of the chatbots used any of the
Nigerian's local languages.
Practical implications
Brands need to re-evaluate their chatbots with regard to responsiveness,
predefined questions, verification and privacy. There are also
possibilities of branding the chatbot and developing content creation
strategies for proper engagement. Beyond English, the integration of
African languages into chatbot is essential for digital transformation.
Digital literacy and skills, particularly in the field of science,
technology, engineering and mathematics, should be supported to equip
future developers and create more jobs.
Originality/value
While many theoretically based models for investigating the adoption of
digital technologies have often placed focus on users' ability to
engage, this study takes an alternative perspective; by using the S-A-T
model, it lays the responsibilities on the banks and chatbot developer
to ensure that their chatbots are secure, responsive and able to meet
the needs of the customers.","Abdulquadri, Abdulazeez and Mogaji, Emmanuel and Kieu, Tai Anh and
Nguyen, Nguyen Phong","JOURNAL OF ENTERPRISING COMMUNITIES-PEOPLE AND PLACES IN THE GLOBAL
ECONOMY",,2021,10.1108/JEC-06-2020-0126,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:001048160400006,A Medical Ethics Framework for Conversational Artificial Intelligence,"The launch of OpenAI's GPT-3 model in June 2020 began a new era for
conversational chatbots. While there are chatbots that do not use
artificial intelligence (AI), conversational chatbots integrate AI
language models that allow for back-and-forth conversation between an AI
system and a human user. GPT-3, since upgraded to GPT-4, harnesses a
natural language processing technique called sentence embedding and
allows for conversations with users that are more nuanced and realistic
than before. The launch of this model came in the first few months of
the COVID-19 pandemic, where increases in health care needs globally
combined with social distancing measures made virtual medicine more
relevant than ever. GPT-3 and other conversational models have been used
for a wide variety of medical purposes, from providing basic
COVID-19-related guidelines to personalized medical advice and even
prescriptions. The line between medical professionals and conversational
chatbots is somewhat blurred, notably in hard-to-reach communities where
the chatbot replaced face-to-face health care. Considering these blurred
lines and the circumstances accelerating the adoption of conversational
chatbots globally, we analyze the use of these tools from an ethical
perspective. Notably, we map out the many types of risks in the use of
conversational chatbots in medicine to the principles of medical ethics.
In doing so, we propose a framework for better understanding the effects
of these chatbots on both patients and the medical field more broadly,
with the hope of informing safe and appropriate future developments.","Fournier-Tombs, Eleonore and McHardy, Juliette",JOURNAL OF MEDICAL INTERNET RESEARCH,,2023,10.2196/43068,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000666698300001,"AI-Based Analysis of Policies and Images for Privacy-Conscious Content
Sharing","Thanks to the popularity of personal mobile devices, more and more of
the different types of private content, such as images and videos, are
shared on social networking applications. While content sharing may be
an effective practice to enhance social relationships, it is also a
source of relevant privacy issues. Unfortunately, users find it
difficult to understanding the terms and implications of the privacy
policies of apps and services. Moreover, taking privacy decisions about
content sharing on social networks is cumbersome and prone to errors
that could determine privacy leaks. In this paper, we propose two
techniques aimed at supporting the user in taking privacy choices about
sharing personal content online. Our techniques are based on machine
learning and natural language processing to analyze privacy policies,
and on computer vision to assist the user in the privacy-conscious
sharing of multimedia content. Experiments with real-world data show the
potential of our solutions. We also present ongoing work on a system
prototype and chatbot for natural language user assistance.","Contu, Francesco and Demontis, Andrea and Dessi, Stefano and Muscas,
Marco and Riboni, Daniele",FUTURE INTERNET,,2021,10.3390/fi13060139,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000532562900003,Hospitality of Chatbot Building Platforms,"The temptation to be able to talk to a machine is not new. Recent
advancements in the field of Natural Language Understanding has made it
possible to build conversational components that can be plugged inside
an application, similar to other components. These components, called
chatbots, can be created from scratch or with the help of commercially
available platforms. These platforms make it easier to build and deploy
chatbots, often without writing a single line of code. However, similar
to any other software component, chatbots also have quality concerns.
Despite significant contributions in the field, an architectural
perspective of building chatbots with desired quality requirements is
missing in the literature.
In the current work, we highlight the impact of features provided by
these platforms (along with their quality) on the application design
process and overall quality attributes. We propose a methodological
framework to evaluate support provided by a chatbot platform towards
achieving quality in the application. The framework, called Hospitality
Framework, is based on software architectural body of knowledge,
especially architectural tactics. The framework produces a metric,
called Hospitality Index, which has utilities for making various design
decisions for the overall application. We present the use of our
framework on a simple use case to highlight the phases of evaluation. We
showcase the process by picking three popular chatbot platforms - Watson
Assistant, DialogFlow and Lex, over four quality attributes -
Modifiability, Security \& Privacy, Interoperability and Reliability.
Our results show that different platforms provide different support for
these four quality attributes.","Srivastava, Saurabh and Prabhakar, V, T.",,"PROCEEDINGS OF THE 2ND ACM SIGSOFT INTERNATIONAL WORKSHOP ON SOFTWARE
QUALITIES AND THEIR DEPENDENCIES (SQUADE' 19)",2019,10.1145/3340495.3342751,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000787534800001,Chatbots in the frontline: drivers of acceptance,"Purpose By extending the service robot acceptance model (sRAM), this
study aims to explore and enhance the acceptance of chatbots. The study
considered functional, relational, social, user and gratification
elements in determining the acceptance of chatbots.
Design/methodology/approach By using the purposive sampling technique,
data of 321 service customers, gathered from millennials through a
questionnaire and subsequent PLS-SEM modeling, was applied for
hypotheses testing. Findings Findings revealed that the functional
elements, perceived usefulness and perceived ease of use affect
acceptance of chatbots. However, in social elements, only perceived
social interactivity affects the acceptance of chatbots. Moreover, both
user and gratification elements (hedonic motivation and symbolic
motivation) significantly influence the acceptance of chatbots. Lastly,
trust is the only contributing factor for the acceptance of chatbots in
the relational elements. Practical implications The study extends the
literature related to chatbots and offers several guidelines to the
service industry to effectively employ chatbots. Originality/value This
is one of the first studies that used newly developed sRAM in
determining chatbot acceptance. Moreover, the study extended the sRAM by
adding user and gratification elements and privacy concerns as
originally sRAM model was limited to functional, relational and social
elements.","Aslam, Wajeeha and Ahmed Siddiqui, Danish and Arif, Imtiaz and Farhat,
Kashif",KYBERNETES,,2022,10.1108/K-11-2021-1119,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:001030167100001,"Conversational Physical Activity Coaches for Spanish and English
Speaking Women: A User Design Study","Introduction: Digital technologies, including text messaging and mobile
phone apps, can be leveraged to increase people's physical activity and
manage health. Chatbots, powered by artificial intelligence, can
automatically interact with individuals through natural conversation.
They may be more engaging than one-way messaging interventions. To our
knowledge, physical activity chatbots have not been developed with
low-income participants, nor in Spanish-the second most dominant
language in the U.S. We recommend best practices for physical activity
chatbots in English and Spanish for low-income women.Methods: We
designed a prototype physical activity text-message based conversational
agent based on various psychotherapeutic techniques. We recruited
participants through SNAP-Ed (Supplemental Nutrition Assistance Program
Education) in California (Alameda County) and Tennessee (Shelby County).
We conducted qualitative interviews with participants during testing of
our prototype chatbot, held a Wizard of Oz study, and facilitated a
co-design workshop in Spanish with a subset of our participants.Results:
We included 10 Spanish- and 8 English-speaking women between 27 and 41
years old. The majority was Hispanic/Latina (n = 14), 2 were White and 2
were Black/African American. More than half were monolingual Spanish
speakers, and the majority was born outside the US (>50\% in Mexico).
Most participants were unfamiliar with chatbots and were initially
skeptical. After testing our prototype, most users felt positively about
health chatbots. They desired a personalized chatbot that addresses
their concerns about privacy, and stressed the need for a comprehensive
system to also aid with nutrition, health information, stress, and
involve family members. Differences between English and monolingual
Spanish speakers were found mostly in exercise app use, digital
literacy, and the wish for family inclusion.Conclusion: Low-income
Spanish- and English-speaking women are interested in using chatbots to
improve their physical activity and other health related aspects.
Researchers developing health chatbots for this population should focus
on issues of digital literacy, app familiarity, linguistic and cultural
issues, privacy concerns, and personalization. Designing and testing
this intervention for and with this group using co-creation techniques
and involving community partners will increase the probability that it
will ultimately be effective.","Figueroa, Caroline A. A. and Luo, Tiffany C. C. and Jacobo, Andrea and
Munoz, Alan and Manuel, Minx and Chan, David and Canny, John and
Aguilera, Adrian",FRONTIERS IN DIGITAL HEALTH,,2021,10.3389/fdgth.2021.747153,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000758168003066,Heuristic Evaluation of Conversational Agents,"Conversational interfaces have risen in popularity as businesses and
users adopt a range of conversational agents, including chatbots and
voice assistants. Although guidelines have been proposed, there is not
yet an established set of usability heuristics to guide and evaluate
conversational agent design. In this paper, we propose a set of
heuristics for conversational agents adapted from Nielsen's heuristics
and based on expert feedback. We then validate the heuristics through
two rounds of evaluations conducted by participants on two
conversational agents, one chatbot and one voice-based personal
assistant. We find that, when using our heuristics to evaluate both
interfaces, evaluators were able to identify more usability issues than
when using Nielsen's heuristics. We propose that our heuristics
successfully identify issues related to dialogue content, interaction
design, help and guidance, human-like characteristics, and data privacy.","Langevin, Raina and Lordon, Ross and Avrahami, Thi and Cowan, Benjamin
and Hirsch, Tad and Hsieh, Gary",,"CHI `21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN
COMPUTING SYSTEMS",2021,10.1145/3411764.3445312,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000605098300004,"Utilization of Self-Diagnosis Health Chatbots in Real-World Settings:
Case Study","Background: Artificial intelligence (AI)-driven chatbots are
increasingly being used in health care, but most chatbots are designed
for a specific population and evaluated in controlled settings. There is
little research documenting how health consumers (eg, patients and
caregivers) use chatbots for self-diagnosis purposes in real-world
scenarios.
Objective: The aim of this research was to understand how health
chatbots are used in a real-world context, what issues and barriers
exist in their usage, and how the user experience of this novel
technology can be improved.
Methods: We employed a data-driven approach to analyze the system log of
a widely deployed self-diagnosis chatbot in China. Our data set
consisted of 47,684 consultation sessions initiated by 16,519 users over
6 months. The log data included a variety of information, including
users' nonidentifiable demographic information, consultation details,
diagnostic reports, and user feedback. We conducted both statistical
analysis and content analysis on this heterogeneous data set.
Results: The chatbot users spanned all age groups, including middle-aged
and older adults. Users consulted the chatbot on a wide range of medical
conditions, including those that often entail considerable privacy and
social stigma issues. Furthermore, we distilled 2 prominent issues in
the use of the chatbot: (1) a considerable number of users dropped out
in the middle of their consultation sessions, and (2) some users
pretended to have health concerns and used the chatbot for
nontherapeutic purposes. Finally, we identified a set of user concerns
regarding the use of the chatbot, including insufficient actionable
information and perceived inaccurate diagnostic suggestions.
Conclusions: Although health chatbots are considered to be convenient
tools for enhancing patient-centered care, there are issues and barriers
impeding the optimal use of this novel technology. Designers and
developers should employ user-centered approaches to address the issues
and user concerns to achieve the best uptake and utilization. We
conclude the paper by discussing several design implications, including
making the chatbots more informative, easy-to-use, and trustworthy, as
well as improving the onboarding experience to enhance user engagement.","Fan, Xiangmin and Chao, Daren and Zhang, Zhan and Wang, Dakuo and Li,
Xiaohua and Tian, Feng",JOURNAL OF MEDICAL INTERNET RESEARCH,,2021,10.2196/19928,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000748605200001,"How AI chatbots have reshaped the frontline interface in China:
examining the role of sales-service ambidexterity and the
personalization-privacy paradox","Purpose This study serves two purposes: (1) to evaluate the effects of
organizational ambidexterity by examining how the balanced and the
combined sales-service configurations of chatbots differ in their
abilities to enhance customer experience and patronage and (2) to apply
information boundary theory to assess the contingent role that chatbot
sales-service ambidexterity can play in adapting to customers'
personalization-privacy paradox. Design/methodology/approach An online
survey of artificial intelligence chatbots users was conducted, and a
mixed-methods research design involving response surface analysis and
polynomial regression was adopted to address the research aim. Findings
The results of polynomial regressions on survey data from 507 online
customers indicated that as the benefits of personalization decreased
and the risk to privacy increased, the inherently negative (positive)
effects of imbalanced (combined) chatbots' sales-service ambidexterity
had an increasing (decreasing) influence on customer experience.
Furthermore, customer experience fully mediated the association of
chatbots' sales-service ambidexterity with customer patronage.
Originality/value First, this study enriches the literature on frontline
ambidexterity and extends it to the setting of human-machine
interaction. Second, the study contributes to the literature on the
personalization-privacy paradox by demonstrating the importance of
frontline ambidexterity for adapting to customer concerns. Third, the
study examines the conduit between artificial intelligence (AI)
chatbots' ambidexterity and sales performance, thereby helping to
reconcile the previously inconsistent evidence regarding this
relationship.","Fan, Hua and Han, Bing and Gao, Wei and Li, Wenqian",INTERNATIONAL JOURNAL OF EMERGING MARKETS,,2022,10.1108/IJOEM-04-2021-0532,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000748662400001,"Artificial intelligence changes the way we work: A close look at
innovating with chatbots","An enhanced understanding of the innovative use of artificial
intelligence (AI) is essential for organizations to improve work design
and daily business operations. This study's purpose is to offer insights
into how AI can transform organizations' work practices through diving
deeply into its innovative use in the context of a primary AI tool, a
chatbot, and examining the antecedents of innovative use by
conceptualizing employee trust as a multidimensional construct and
exploring employees' perceived benefits. In particular, we have
conceptualized employee trust in chatbots as a second-order construct,
including three first-order variables: trust in functionality, trust in
reliability, and trust in data protection. We collected data from 202
employees. The results supported our conceptualization of trust in
chatbots and showed that three dimensions of first-order trust beliefs
have relatively the same level of importance. Further, both knowledge
support and work-life balance enhance trust in chatbots, which in turn
leads to innovative use of chatbots. Our study contributes to the
existing literature by introducing the new conceptualization of trust in
chatbots and examining its antecedents and outcomes. The results can
provide important practical insights regarding how to support innovative
use of chatbots as the new way we organize work.","Wang, Xuequn and Lin, Xiaolin and Shao, Bin",JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY,,2023,10.1002/asi.24621,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000890212500038,"UX Research on Conversational Human-AI Interaction: A Literature Review
of the ACM Digital Library","Early conversational agents (CAs) focused on dyadic human-AI interaction
between humans and the CAs, followed by the increasing popularity of
polyadic human-AI interaction, in which CAs are designed to mediate
human-human interactions. CAs for polyadic interactions are unique
because they encompass hybrid social interactions, i.e., human-CA,
human-to-human, and human-to-group behaviors. However, research on
polyadic CAs is scattered across diferent felds, making it challenging
to identify, compare, and accumulate existing knowledge. To promote the
future design of CA systems, we conducted a literature review of ACM
publications and identifed a set of works that conducted UX (user
experience) research. We qualitatively synthesized the efects of
polyadic CAs into four aspects of human-human interactions, i.e.,
communication, engagement, connection, and relationship maintenance.
Through a mixed-method analysis of the selected polyadic and dyadic CA
studies, we developed a suite of evaluation measurements on the efects.
Our fndings show that designing with social boundaries, such as privacy,
disclosure, and identifcation, is crucial for ethical polyadic CAs.
Future research should also advance usability testing methods and
trust-building guidelines for conversational AI.","Zheng, Qingxiao and Tang, Yiliu and Liu, Yiren and Liu, Weizi and Huang,
Yun",,"PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
SYSTEMS (CHI' 22)",2022,10.1145/3491102.3501855,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000824464300295,"Development of Esteem Support based on Psychodrama and Design Thinking
approach","So far, we have proposed the Stress management framework and developed
methods for stress measurement and coping. There are three types of
coping in this framework: information support, emotional support, and
esteem support. This time, we developed esteem support. In order to
increase self-esteem, we focused on psychodrama techniques and developed
a system to realize psychodrama using robots. The advantages of using
robots include the ability to carry out a psychodrama alone and to
provide privacy-friendly support. In the experiment, a scenario was
created for medical staff and a robot psychodrama was performed. As a
result, we showed that robots can be used for psychodrama and esteem
support can be carried out by combination of robots and the chatbot.","Yorita, Akihiro and Egerton, Simon and Chan, Carina and Kubota, Naoyuki",,"2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI
2021)",2021,10.1109/SSCI50451.2021.9660118,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000976791200039,The Impact of Artificial Intelligence on Chatbot Design,"Artificial intelligence is transforming the way chatbots are created and
used. The recent boom of artificial intelligence development is creating
a whole new generation of intelligent approaches that enable a more
efficient and effective design of chatbots. On the other hand, the
increasing need and interest from the industry in artificial
intelligence based solutions, is guaranteeing the necessary investment
and applicational know-how that is pushing such solutions to a new
dimension. Some relevant examples are e-commerce, health or education,
which is the main focus of this work. This paper studies and analyses
the impact that artificial intelligence models and solutions is having
on the design and development of chatbots, when compared to the
previously used approaches. Some of the most relevant current and future
challenges in this domain are highlighted, which include language
learning, sentiment interpretation, integration with other services, or
data security and privacy issues.","Duduka, Jacint and Reis, Arsenio and Pereira, Rodrigo and Pires, Eduardo
and Sousa, Jose and Pinto, Tiago",,"TECHNOLOGY AND INNOVATION IN LEARNING, TEACHING AND EDUCATION, TECH-EDU
2022",2022,10.1007/978-3-031-22918-3\_39,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000455805700008,Protecting Chatbots from Toxic Content,"There is a paradigm shift in web-based services towards conversational
user interfaces. Companies increasingly offer conversational interfaces,
or chatbots, to let their customers or employees interact with their
services in a more flexible and mobile manner. Unfortunately, this new
paradigm faces a major problem, namely toxic content in user inputs.
Toxic content in user inputs to chatbots may cause privacy concerns, may
be adversarial or malicious, and can cause the chatbot provider
substantial economic, reputational, or legal harm. We address this
problem with an interdisciplinary approach, drawing upon programming
languages, cloud computing, and other disciplines to build protections
for chatbots. Our solution, called BotShield, is non-intrusive in that
it does not require changes to existing chatbots or underlying
conversational platforms. This paper introduces novel security
mechanisms, articulates their security guarantees, and illustrates them
via case studies.","Baudart, Guillaume and Dolby, Julian and Duesterwald, Evelyn and Hirzel,
Martin and Shinnar, Avraham",,"ONWARD!'18: PROCEEDINGS OF THE 2018 ACM SIGPLAN INTERNATIONAL SYMPOSIUM
ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE",2018,10.1145/3276954.3276958,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000617739900245,"Work-in-Progress: A Preliminary Study on Students' Acceptance of
Chatbots for Studio-Based Learning","Studio-based learning (SBL) is a pedagogy that encompasses collaborative
active learning strategies focusing on creativity, peer learning, and
problem-solving. The iterative design procedures and critique sessions
are the primary learning practices of SBL, which relays to a need to
have effective communication between instructors and students. Due to
this, we designed a Telegram chatbot using the TextIt to facilitate some
of the interactions that are common in SBL. In this preliminary study,
students' acceptance of chatbot was investigated based on the Technology
Acceptance Model (TAM) using a mix-method approach. Preliminary results
indicated positive acceptance and intention to use chatbots due to ease
of use, mobile accessibility, human-like communications, and privacy in
communicating and providing feedback.","Kumar, Jeya Amantha and Silva, Paula Alexandra",,"PROCEEDINGS OF THE 2020 IEEE GLOBAL ENGINEERING EDUCATION CONFERENCE
(EDUCON 2020)",2020,,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000951369300001,"Can chatbots satisfy me? A mixed-method comparative study of
satisfaction with task-oriented chatbots in mainland China and Hong Kong","Task-oriented chatbots are gradually being used across the globe. Most
notably, while chatbots have for a long time penetrated users' daily
lives in mainland China, Hong Kong is still struggling to improve and
promote its chatbot services. To determine whether antecedents of
satisfaction and usage intention differ based on different stages of
chatbot adoption and development, we conduct a comparative study based
on a research model that integrates the Delone and McLean Information
System success model and privacy concerns. The model is developed and
examined using a mixed-method approach. After conducting focus group
interviews (N = 15) in both regions, online surveys were conducted in
mainland China (N = 637) and Hong Kong (N = 647), respec-tively. Based
on qualitative exploration, we identified critical factors of perceived
quality and privacy concerns. The quantitative findings further
illuminate the different roles of the antecedents in the two regions.
The results show that usage intention can be positively influenced by
satisfaction, and satisfaction can be increased by relevance,
completeness, pleasure and assurance in both regions. However, response
time and empathy are factors influencing satisfaction only in mainland
China. Privacy concerns cannot influence satisfaction in both regions.","Liu, Yu-li and Hu, Bo and Yan, Wenjia and Lin, Zhi",COMPUTERS IN HUMAN BEHAVIOR,,2023,10.1016/j.chb.2023.107716,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000836390500238,"Impersonating Chatbots in a Code Review Exercise to Teach Software
Engineering Best Practices","Over the past decade, the use of chatbots for educational purposes has
gained considerable traction. A similar trend has been observed in
social coding platforms, where automated agents support software
developers with tasks such as performing code reviews. While
incorporating code reviews and social coding platforms into software
engineering education has been found to be beneficial, challenges such
as steep learning curves and privacy considerations are barriers to
their adoption. Furthermore, no study has addressed the role chatbots
play in supporting code reviews as a pedagogical tool. To help address
this gap, we developed an online learning application that simulates the
code review features available on social coding platforms and allows
instructors to interact with students using chatbot identities. We then
embedded this application within a lesson on software engineering best
practices and conducted a controlled in-class experiment. This
experiment examined the effect that explaining content via chatbot
identities had on three aspects: (i) students' perceived usability of
the lesson, (ii) their engagement with the code review process, and
(iii) their learning gains. While our findings show that it is feasible
to simulate the code review process within an online learning platform
and achieve good usability, our quantitative analysis did not yield
significant differences across treatment conditions for any of the
aspects considered. Nevertheless, our qualitative results suggest that
students expect explicit feedback when performing this type of exercise
and could thus benefit from automated replies provided by an interactive
chatbot. We propose to build on our current findings to further explore
this line of research in future work.","Farah, Juan Carlos and Spaenlehauer, Basile and Sharma, Vandit and
Rodriguez-Triana, Maria Jesus and Ingram, Sandy and Gillet, Denis",,"PROCEEDINGS OF THE 2022 IEEE GLOBAL ENGINEERING EDUCATION CONFERENCE
(EDUCON 2022)",2022,10.1109/EDUCON52537.2022.9766793,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000606823500034,"Developing an Intelligent Framework for Improving the Quality of Service
in the Government Organizations in the Kingdom of Saudi Arabia","The Kingdom of Saudi Arabia is enhancing the services and applications
in government organizations through the number of systems that generate
a massive amount of data through Big Data technology. Recently, the
Global Artificial Intelligent Summit 2020, Saudi Data and Artificial
Intelligence Authority (SDAIA), NEOM have launched an Artificial
Intelligence (AI) strategy that aligns with the Kingdom Vision 2030. AI
opens a wide door for opportunities and new strategies that will narrow
the gap in the skillset of individuals and promote research and
innovation in the IT industry. Organizations lack advanced techniques to
evaluate the performance of individuals and departments that supports
improving the quality of service. The introduction of AI-based
applications in the government and private sectors will facilitate
decision-makers in tracking and optimizing the efficiency of departments
and individuals. This research aims to develop an intelligent framework
for government organizations to improve the quality of services rendered
to customers and businesses. In addition, it highlights the importance
of AI policies in archiving metadata. This paper presents a framework
for an organization that contains Chatbot, Sentiment Analysis, and Key
Performance Indicators to improve the services. A synthetic dataset is
employed as a testbed to evaluate the performance of the framework. The
outcome of this study shows that the proposed framework able to improve
the performance of organizations. Using this proposed framework,
organizations can build a mechanism for their workforce to retrieve
meaningful information. Moreover, it provides significant features
include efficient data extraction, data management, and AI-based
security for effective document management.","AlGosaibi, Abdulelah Abdallah and Sait, Abdul Rahaman Wahab and
AlOthman, Abdulaziz Fahad and AlHamed, Shadan",INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,2020,,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000954374300001,"?So what if ChatGPT wrote it?? Multidisciplinary perspectives on
opportunities, challenges and implications of generative conversational
AI for research, practice and policy","Transformative artificially intelligent tools, such as ChatGPT, designed
to generate sophisticated text indistin-guishable from that produced by
a human, are applicable across a wide range of contexts. The technology
presents opportunities as well as, often ethical and legal, challenges,
and has the potential for both positive and negative impacts for
organisations, society, and individuals. Offering multi-disciplinary
insight into some of these, this article brings together 43
contributions from experts in fields such as computer science,
marketing, information systems, education, policy, hospitality and
tourism, management, publishing, and nursing. The contributors
acknowledge ChatGPT's capabilities to enhance productivity and suggest
that it is likely to offer significant gains in the banking, hospitality
and tourism, and information technology industries, and enhance business
activities, such as management and marketing. Nevertheless, they also
consider its limitations, dis-ruptions to practices, threats to privacy
and security, and consequences of biases, misuse, and misinformation.
However, opinion is split on whether ChatGPT's use should be restricted
or legislated. Drawing on these con-tributions, the article identifies
questions requiring further research across three thematic areas:
knowledge, transparency, and ethics; digital transformation of
organisations and societies; and teaching, learning, and scholarly
research. The avenues for further research include: identifying skills,
resources, and capabilities needed to handle generative AI; examining
biases of generative AI attributable to training datasets and processes;
exploring business and societal contexts best suited for generative AI
implementation; determining optimal combinations of human and generative
AI for various tasks; identifying ways to assess accuracy of text
produced by generative AI; and uncovering the ethical and legal issues
in using generative AI across different contexts.","Dwivedi, Yogesh K. and Kshetri, Nir and Hughes, Laurie and Slade, Emma
Louise and Jeyaraj, Anand and Kar, Arpan Kumar and Baabdullah, Abdullah
M. and Koohang, Alex and Raghavan, Vishnupriya and Ahuja, Manju and
Albanna, Hanaa and Albashrawi, Mousa Ahmad and Al-Busaidi, Adil S. and
Balakrishnan, Janarthanan and Barlette, Yves and Basu, Sriparna and
Bose, Indranil and Brooks, Laurence and Buhalis, Dimitrios and Carter,
Lemuria and Chowdhury, Soumyadeb and Crick, Tom and Cunningham, Scott W.
and Davies, Gareth H. and Davison, Robert M. and De, Rahul and Dennehy,
Denis and Duan, Yanqing and Dubey, Rameshwar and Dwivedi, Rohita and
Edwards, John S. and Flavian, Carlos and Gauld, Robin and Grover, Varun
and Hu, Mei-Chih and Janssen, Marijn and Jones, Paul and Junglas, Iris
and Khorana, Sangeeta and Kraus, Sascha and Larsen, Kai R. and
Latreille, Paul and Laumer, Sven and Malik, F. Tegwen and Mardani, Abbas
and Mariani, Marcello and Mithas, Sunil and Mogaji, Emmanuel and Nord,
Jeretta Horn and O'Connor, Siobhan and Okumus, Fevzi and Pagani,
Margherita and Pandey, Neeraj and Papagiannidis, Savvas and Pappas,
Ilias O. and Pathak, Nishith and Pries-Heje, Jan and Raman, Ramakrishnan
and Rana, Nripendra P. and Rehm, Sven-Volker and Ribeiro-Navarrete,
Samuel and Richter, Alexander and Rowe, Frantz and Sarker, Suprateek and
Stahl, Bernd Carsten and Tiwari, Manoj Kumar and van der Aalst, Wil and
Venkatesh, Viswanath and Viglia, Giampaolo and Wade, Michael and Walton,
Paul and Wirtz, Jochen and Wright, Ryan",INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,,2023,10.1016/j.ijinfomgt.2023.102642,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000866821600001,"Use of Instant Messaging Software in a German Hospital-An Exploratory
Investigation among Physicians","Internationally, evidence exists that physicians use instant messaging
services for communication tasks in everyday clinical practice However,
there are only few data on physicians in Germany in this regard.
Therefore, at the initiation of our project ``DocTalk-Dialog meets
Chatbot: Collaborative Learning and Teaching in the Process of Work{''},
we conducted a stakeholder survey with an exploratory research approach.
The aim was to gain initial insights into use of instant messaging
software and attitudes towards data security and advantages and
disadvantages before implementing a data-secure in-house messaging
platform. N = 70 physicians at Charite-Universitatsmedizin Berlin
completed an exploratory questionnaire with closed and open-ended
questions. Quantitative data were analyzed using descriptive statistics
and qualitative data using thematic analysis. The use of messenger
software was not widespread in the sample studied. Physicians most
frequently used face-to-face contact for communication. On average, up
to ten instant messages were exchanged per day, mainly among colleagues,
to answer mutual questions, and to send pictures. With a high awareness
of privacy-related restrictions among participating physicians,
advantages such as fast and uncomplicated communication were also
highlighted. An instant messenger solution that complies with the German
data protection guidelines is needed and should be investigated in more
detail.","Sayegh-Jodehl, Sabine and Mukowski-Kickhoefel, Rebecca and Linke, Diane
and Mueller-Birn, Claudia and Rose, Matthias",INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH,,2022,10.3390/ijerph191912618,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:001000861100001,"CHATBOTS IN THE WORKPLACE: A TECHNOLOGY ACCEPTANCE STUDY APPLYING USES
AND GRATIFICATIONS IN COWORKING SPACES","The uses and gratifications approach is used to examine chatbot
acceptance in coworking spaces, identifying how coworkers perceive the
technology and may use it to facilitate their tasks. To do so, potential
influence factors shaping technology acceptance are explored, and a
sample of 101 German coworkers is employed to confirm the framework
drawing on a quantitative combination of partial least squares
structural equation modeling and necessary condition analysis.
Instrumental and non-instrumental gratifications, as well as social
norm, influence chatbot acceptance in the form of sufficient and
necessary conditions, and social norm appears to have a more substantial
impact than hedonic factors in terms of sufficiency. However, social
norm is not a necessary condition. A moderator analysis reveals that
privacy concerns, age and gender do not affect individuals' intention to
use a chatbot. Coworking space providers thus benefit from establishing
a standard chatbot solution to leverage social norm, and the chosen
solution needs to fulfill hedonic expectations in addition to being
useful. Software vendors may also integrate dedicated interfaces to
powerful solutions such as ChatGPT.","Kopplin, Cristopher Siegfried",JOURNAL OF ORGANIZATIONAL COMPUTING AND ELECTRONIC COMMERCE,,2022,10.1080/10919392.2023.2215666,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000825820000001,"A tool or a social being? A dynamic longitudinal investigation of
functional use and relational use of AI voice assistants","This study integrates two lines of research: technologies as tools and
technologies as social beings, under the theoretical framework of
dynamic systems, to investigate the reciprocal dynamics between
functional use and relational use of artificial intelligence (AI) voice
assistants, and the mediating roles of self-disclosure and privacy
concerns. A two-wave longitudinal survey was conducted among 354 AI
voice assistant users across 2 months. Factor analysis results supported
the conceptualization and operationalization of functional use and
relational use of voice assistants. Results from the cross-lagged panel
model confirmed that functional use and relational use reinforced
themselves over time, respectively. Relational use increased subsequent
functional use, and relational use reinforced itself through
self-disclosure. Surprisingly, functional use did not increase
subsequent relational use; instead, longitudinal mediation analysis
showed that functional use reduced subsequent relational use due to the
lack of self-disclosure. Furthermore, while self-disclosure increased
subsequent privacy concerns, privacy concerns did not reduce subsequent
self-disclosure.","Xu, Shan and Li, Wenbo",NEW MEDIA \& SOCIETY,,2022,10.1177/14614448221108112,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000876574700005,"Formative Evaluation of the Acceptance of HIV Prevention Artificial
Intelligence Chatbots By Men Who Have Sex With Men in Malaysia: Focus
Group Study","Background: Mobile technologies are being increasingly developed to
support the practice of medicine, nursing, and public health, including
HIV testing and prevention. Chatbots using artificial intelligence (AI)
are novel mobile health strategies that can promote HIV testing and
prevention among men who have sex with men (MSM) in Malaysia, a
hard-to-reach population at elevated risk of HIV, yet little is known
about the features that are important to this key population.Objective:
The aim of this study was to identify the barriers to and facilitators
of Malaysian MSM's acceptance of an AI chatbot designed to assist in HIV
testing and prevention in relation to its perceived benefits,
limitations, and preferred features among potential users.Methods: We
conducted 5 structured web-based focus group interviews with 31 MSM in
Malaysia between July 2021 and September 2021. The interviews were first
recorded, transcribed, coded, and thematically analyzed using NVivo
(version 9; QSR International). Subsequently, the unified theory of
acceptance and use of technology was used to guide data analysis to map
emerging themes related to the barriers to and facilitators of chatbot
acceptance onto its 4 domains: performance expectancy, effort
expectancy, facilitating conditions, and social influence.Results:
Multiple barriers and facilitators influencing MSM's acceptance of an AI
chatbot were identified for each domain. Performance expectancy (ie, the
perceived usefulness of the AI chatbot) was influenced by MSM's concerns
about the AI chatbot's ability to deliver accurate information, its
effectiveness in information dissemination and problem-solving, and its
ability to provide emotional support and raise health awareness.
Convenience, cost, and technical errors influenced the AI chatbot's
effort expectancy (ie, the perceived ease of use). Efficient linkage to
health care professionals and HIV self-testing was reported as a
facilitating condition of MSM's receptiveness to using an AI chatbot to
access HIV testing. Participants stated that social influence (ie,
sociopolitical climate) factors influencing the acceptance of mobile
technology that addressed HIV in Malaysia included privacy concerns,
pervasive stigma against homosexuality, and the criminalization of
same-sex sexual behaviors. Key design strategies that could enhance
MSM's acceptance of an HIV prevention AI chatbot included an anonymous
user setting; embedding the chatbot in MSM-friendly web-based platforms;
and providing user-guiding questions and options related to HIV testing,
prevention, and treatment.Conclusions: This study provides important
insights into key features and potential implementation strategies
central to designing an AI chatbot as a culturally sensitive digital
health tool to prevent stigmatized health conditions in vulnerable and
systematically marginalized populations. Such features not only are
crucial to designing effective user-centered and culturally situated
mobile health interventions for MSM in Malaysia but also illuminate the
importance of incorporating social stigma considerations into health
technology implementation strategies.","Peng, Mary L. and Wickersham, Jeffrey A. and Altice, Frederick L. and
Shrestha, Roman and Azwa, Iskandar and Zhou, Xin and Halim, Mohd Akbar
Ab and Ikhtiaruddin, Wan Mohd and Tee, Vincent and Kamarulzaman, Adeeba
and Ni, Zhao",JMIR FORMATIVE RESEARCH,,2022,10.2196/42055,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000474467908006,"Transformation through Provocation? Designing a `Bot of Conviction' to
Challenge Conceptions and Evoke Critical Reflection","Can a chatbot enable us to change our conceptions, to be critically
reflective? To what extent can interaction with a technologically
``minimal{''} medium such as a chatbot evoke emotional engagement in
ways that can challenge us to act on the world? In this paper, we
discuss the design of a provocative bot, a ``bot of conviction{''},
aimed at triggering conversations on complex topics (e.g. death, wealth
distribution, gender equality, privacy) and, ultimately, soliciting
specific actions from the user it converses with. We instantiate our
design with a use case in the cultural sector, specifically a Neolithic
archaeological site that acts as a stage of conversation on such hard
themes. Our larger contributions include an interaction framework for
bots of conviction, insights gained from an iterative process of
participatory design and evaluation, and a vision for bot interaction
mechanisms that can apply to the HCI community more widely.","Roussou, Maria and Perry, Sara and Katifori, Akrivi and Vassos, Stavros
and Tzouganatou, Angeliki and McKinney, Sierra",,"CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN
COMPUTING SYSTEMS",2019,10.1145/3290605.3300857,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000502733200048,"BotFlowMon: Learning-Based, Content-Agnostic Identification of Social
Bot Traffic Flows","With the fast-growing popularity of online social networks (OSN),
maintaining the security of OSN ecosystems becomes essential for the
public. Among all the security threats facing OSN, malicious social bots
have become the most common and detrimental. These bot programs are
often employed to violate users' privacy, distribute spam, and disturb
the financial market, posing a compelling need for effective social bot
detection solutions.
Unlike traditional bot detection approaches that have strict
requirements on data sources (e.g., private payload information, social
relationships, or activity histories), this paper proposes a detection
method called BotFlowMon that relies only on NetFlow data as input to
identify OSN bot traffic, where every NetFlow record is a summary of a
traffic flow on the Internet and contains no payload content. BotFlowMon
introduces several new algorithms and techniques to help use machine
learning to classify the social bot traffic from the real OSN user
traffic, including aggregating NetFlow records to obtain transaction
data, fusing transaction data to extract features and visualize flows,
as well as subdividing transactions into basic actions. Our evaluation
shows that with 535GB raw NetFlow records as input, BotFlowMon can
efficiently classify the traffic from social bots, including chatbot,
amplification bot, post bot, crawler bot, and hybrid bot, with
92.33-93.61\% accuracy.","Feng, Yebo and Li, Jun and Jiao, Lei and Wu, Xintao",,2019 IEEE CONFERENCE ON COMMUNICATIONS AND NETWORK SECURITY (CNS),2019,,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000702429700001,Systematizing Audit in Algorithmic Recruitment,"Business psychologists study and assess relevant individual differences,
such as intelligence and personality, in the context of work. Such
studies have informed the development of artificial intelligence systems
(AI) designed to measure individual differences. This has been
capitalized on by companies who have developed AI-driven recruitment
solutions that include aggregation of appropriate candidates (Hiretual),
interviewing through a chatbot (Paradox), video interview assessment
(MyInterview), and CV-analysis (Textio), as well as estimation of
psychometric characteristics through image-(Traitify) and game-based
assessments (HireVue) and video interviews (Cammio). However, driven by
concern that such high-impact technology must be used responsibly due to
the potential for unfair hiring to result from the algorithms used by
these tools, there is an active effort towards proving mechanisms of
governance for such automation. In this article, we apply a systematic
algorithm audit framework in the context of the ethically critical
industry of algorithmic recruitment systems, exploring how audit
assessments on AI-driven systems can be used to assure that such systems
are being responsibly deployed in a fair and well-governed manner. We
outline sources of risk for the use of algorithmic hiring tools, suggest
the most appropriate opportunities for audits to take place, recommend
ways to measure bias in algorithms, and discuss the transparency of
algorithms.","Kazim, Emre and Koshiyama, Adriano Soares and Hilliard, Airlie and
Polle, Roseline",JOURNAL OF INTELLIGENCE,,2021,10.3390/jintelligence9030046,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000886937900032,"Designing Virtual Reality-Based Conversational Agents to Train
Clinicians in Verbal De-escalation Skills: Exploratory Usability Study","Background: Violence and aggression are significant workplace challenges
faced by clinicians worldwide. Traditional methods of training consist
of ``on-the-job learning{''} and role-play simulations. Although both
approaches can result in improved skill levels, they are not without
limitation. Interactive simulations using virtual reality (VR) can
complement traditional training processes as a cost-effective, engaging,
easily accessible, and flexible training tool.
Objective: In this exploratory study, we aimed to determine the
feasibility of and barriers to verbal engagement with a virtual agent in
the context of the Code Black VR application. Code Black VR is a new
interactive VR-based verbal de-escalation trainer that we developed
based on the Clinical Training Through VR Design Framework.
Methods: In total, 28 participants with varying clinical expertise from
4 local hospitals enrolled in the Western Sydney Local Health District
Clinical Initiative Nurse program and Transition to Emergency Nursing
Programs and participated in 1 of 5 workshops. They completed multiple
playthroughs of the Code Black VR verbal de-escalation trainer
application and verbally interacted with a virtual agent. We documented
observations and poststudy reflection notes. After the playthroughs, the
users completed the System Usability Scale and provided written comments
on their experience. A thematic analysis was conducted on the results.
Data were also obtained through the application itself, which also
recorded the total interactions and successfully completed interactions.
Results: The Code Black VR verbal de-escalation training application was
well received. The findings reinforced the factors in the existing
design framework and identified 3 new factors-motion sickness, perceived
value, and privacy-to be considered for future application development.
Conclusions: Verbal interaction with a virtual agent is feasible for
training staff in verbal de-escalation skills. It is an effective medium
to supplement clinician training in verbal de-escalation skills. We
provide broader design considerations to guide further developments in
this area.","Moore, Nathan and Ahmadpour, Naseem and Brown, Martin and Poronnik,
Philip and Davids, Jennifer",JMIR SERIOUS GAMES,,2022,10.2196/38669,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:001024995000001,"The imperative for regulatory oversight of large language models (or
generative AI) in healthcare","The rapid advancements in artificial intelligence (AI) have led to the
development of sophisticated large language models (LLMs) such as GPT-4
and Bard. The potential implementation of LLMs in healthcare settings
has already garnered considerable attention because of their diverse
applications that include facilitating clinical documentation, obtaining
insurance pre-authorization, summarizing research papers, or working as
a chatbot to answer questions for patients about their specific data and
concerns. While offering transformative potential, LLMs warrant a very
cautious approach since these models are trained differently from
AI-based medical technologies that are regulated already, especially
within the critical context of caring for patients. The newest version,
GPT-4, that was released in March, 2023, brings the potentials of this
technology to support multiple medical tasks; and risks from mishandling
results it provides to varying reliability to a new level. Besides being
an advanced LLM, it will be able to read texts on images and analyze the
context of those images. The regulation of GPT-4 and generative AI in
medicine and healthcare without damaging their exciting and
transformative potential is a timely and critical challenge to ensure
safety, maintain ethical standards, and protect patient privacy. We
argue that regulatory oversight should assure medical professionals and
patients can use LLMs without causing harm or compromising their data or
privacy. This paper summarizes our practical recommendations for what we
can expect from regulators to bring this vision to reality.","Mesko, Bertalan and Topol, Eric J. J.",NPJ DIGITAL MEDICINE,,2023,10.1038/s41746-023-00873-0,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000575079000006,"The Essential Role of Technology in the Public Health Battle Against
COVID-19","Technology has played an important role in responding to the novel
coronavirus (SARS-CoV-2) and subsequent COVID-19 pandemic. The virus's
blend of lethality and transmissibility have challenged officials and
exposed critical limitations of the traditional public health apparatus.
However, throughout this pandemic, technology has answered the call for
a new form of public health that illustrates opportunities for enhanced
agility, scale, and responsiveness. The authors share the Microsoft
perspective and illustrate how technology has helped transform the
public health landscape with new and refined capabilities - the efficacy
and impact of which will be determined by history. Technologies like
chatbot and virtualized patient care offer a mechanism to triage and
distribute care at scale. Artificial intelligence and high-performance
computing have accelerated research into understanding the virus and
developing targeted therapeutics to treat infection and prevent
transmission. New mobile contact tracing protocols that preserve patient
privacy and civil liberties were developed in response to public
concerns, creating new opportunities for privacy-sensitive technologies
that aid efforts to prevent and control outbreaks. While much progress
is still needed, the COVID-19 pandemic has highlighted technology's
importance to public health security and pandemic preparedness. Future
multi-stakeholder collaborations, including those with technology
organizations, are needed to facilitate progress in overcoming the
current pandemic, setting the stage for improved pandemic preparedness
in the future. As lessons are assessed from the current pandemic, public
officials should consider technology's role and continue to seek
opportunities to supplement and improve on traditional approaches.","Uohara, Michael Y. and Weinstein, James N. and Rhew, David C.",POPULATION HEALTH MANAGEMENT,,2020,10.1089/pop.2020.0187,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:001020998700003,"Relief in Sight? Chatbots, In-baskets, and the Overwhelmed Primary Care
Clinician","The recent emergence of publically facing artificial intelligence (AI)
chatbots has generated vigorous discussion in the lay public around the
possibilities, liabilities, and uncertainties of the integration of such
technology into everyday life. As primary care clinicians continue to
struggle against ever-increasing loads of asynchronous, electronic work,
the potential for AI to improve the quality and efficiency of this work
looms large. In this essay, we discuss the basic premise of open-access
AI chatbots such as CHATGPT, review prior applications of AI in
healthcare, and preview some possible AI chatbot-assisted in-basket
assistance including scenarios of communicating test results with
patients, providing patient education, and clinical decision support in
history taking, review of prior diagnostic test characteristics, and
common management scenarios. We discuss important concerns related to
the future adoption of this technology including the transparency of the
training data used in developing these models, the level of oversight
and trustworthiness of the information generated, and possible impacts
on equity, bias, and patient privacy. A stepwise and balanced approach
to simultaneously understand the capabilities and address the concerns
associated with these tools will be needed before these tools can
improve patient care.","Matulis, John and McCoy, Rozalina",JOURNAL OF GENERAL INTERNAL MEDICINE,,2023,10.1007/s11606-023-08271-8,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000550289400002,"Chatbots in retailers' customer communication: How to measure their
acceptance?","Currently, online retailers evaluate whether chatbots-software programs
that interact with users using natural languages-could improve their
customers' satisfaction. In a retail context, chatbots allow humans to
pose shopping-related questions and receive answers in natural language
without waiting for a salesperson or using other automated communication
forms. However, until now, it has been unclear which customers accept
this new communication form and which factors determine their
acceptance. In this paper, we contrast the well-known technology
acceptance model (TAM) with the lesser known uses and gratifications
(U\&G) theory, applying both approaches to measure the acceptance of the
text-based ``Emma{''} chatbot by its target segment. ``Emma{''} was
developed for the prepurchase phase of online fashion retailing and
integrated into Facebook Messenger by the major German online retailer
Zalando. Data were collected from 205 German Millennial respondents in a
usability study. The results show that both utilitarian factors such as
``authenticity of conversation{''} and ``perceived usefulness,{''} as
well as hedonic factors such as ``perceived enjoyment{''}, positively
influence the acceptance of ``Emma{''}. However, privacy concerns and
the immaturity of the technology had a negative effect on usage
intention and frequency. The predictive power of both models was
similar, showing little deviation, but U\&G gives alternative insights
into the customers' motivation to use ``Emma{''} compared to the TAM.","Rese, Alexandra and Ganster, Lena and Baier, Daniel",JOURNAL OF RETAILING AND CONSUMER SERVICES,,2020,10.1016/j.jretconser.2020.102176,,webofscience.bib,2023-09-02 14:05:29,Unclassified
