@inproceedings{10.1145/3582515.3609536,
author = {Montagna, Sara and Ferretti, Stefano and Klopfenstein, Lorenz Cuno and Florio, Antonio and Pengo, Martino Francesco},
title = {Data Decentralisation of LLM-Based Chatbot Systems in Chronic Disease Self-Management},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609536},
doi = {10.1145/3582515.3609536},
abstract = {Chronic patient self-management is crucial for maintaining physical and psychological health, reducing pressure on healthcare systems, and promoting patient empowerment. Digital technologies, particularly chatbots, have emerged as powerful tools for supporting patients in managing their chronic conditions. Large language models (LLMs), such as GPT-4, have shown potential in improving chatbot-based systems in healthcare. However, their adoption in clinical practice faces challenges, including reliability, the need for clinical trials, and privacy concerns. This paper proposes a general architecture for developing an LLM-based chatbot system that supports chronic patients while addressing privacy and security concerns. The architecture is designed to be independent of specific technologies and health conditions, focusing on data protection legislation compliance. A prototype of the system has been developed for hypertension management, demonstrating its potential for motivating patients to monitor their blood pressure and adhere to prescriptions.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {205–212},
numpages = {8},
keywords = {chatbot, healthcare data privacy, hypertension, personal data store},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

@inproceedings{10.1145/3340495.3342751,
author = {Srivastava, Saurabh and Prabhakar, T.V.},
title = {Hospitality of chatbot building platforms},
year = {2019},
isbn = {9781450368575},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340495.3342751},
doi = {10.1145/3340495.3342751},
abstract = {The temptation to be able to talk to a machine is not new. Recent advancements in the field of Natural Language Understanding has made it possible to build conversational components that can be plugged inside an application, similar to other components. These components, called chatbots, can be created from scratch or with the help of commercially available platforms. These platforms make it easier to build and deploy chatbots, often without writing a single line of code. However, similar to any other software component, chatbots also have quality concerns. Despite significant contributions in the field, an architectural perspective of building chatbots with desired quality requirements is missing in the literature. In the current work, we highlight the impact of features provided by these platforms (along with their quality) on the application design process and overall quality attributes. We propose a methodological framework to evaluate support provided by a chatbot platform towards achieving quality in the application. The framework, called Hospitality Framework, is based on software architectural body of knowledge, especially architectural tactics. The framework produces a metric, called Hospitality Index, which has utilities for making various design decisions for the overall application. We present the use of our framework on a simple use case to highlight the phases of evaluation. We showcase the process by picking three popular chatbot platforms - Watson Assistant, DialogFlow and Lex, over four quality attributes - Modifiability, Security \&amp; Privacy, Interoperability and Reliability. Our results show that different platforms provide different support for these four quality attributes.},
booktitle = {Proceedings of the 2nd ACM SIGSOFT International Workshop on Software Qualities and Their Dependencies},
pages = {12–19},
numpages = {8},
keywords = {Conversational Systems, Hospitality, Quality Attributes},
location = {Tallinn, Estonia},
series = {SQUADE 2019}
}

@inproceedings{10.1145/3512353.3512363,
author = {Tran, Lan Anh and Hensen, Benedikt and Klamma, Ralf and Chantaraskul, Soamsiri},
title = {Privacy and Security in Mixed Reality Learning Environments by Input and User/Bot Interaction Protection},
year = {2022},
isbn = {9781450395571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512353.3512363},
doi = {10.1145/3512353.3512363},
abstract = {Mixed reality is known as an advanced technology that provides a new approach for learning environments. Such environments allow learners to interact with both virtual and real worlds and bringing in potential enhancements to the learning process at the same time. For example, chatbots can facilitate the learning process. However, security and privacy settings for interacting with chatbots in such mixed reality environments are complex. In this paper, we introduce a mixed reality virtual assistant that is integrated into the collaborative environment of our existing application VIAProMa. This embodied chatbot allows lecturers and students to participate in mixed reality and online classrooms in real-time. The participants can interact with each other via VIAProMa’s avatar representations and can communicate with the chatbot that is represented by the mixed reality bot. The bot is realized by connecting a Slack chatbot with the mixed reality learning environment. It is displayed as an intuitive 3D model and is able to communicate with the users in spoken language. In this environment, privacy and security settings are conducted to protect the user input and user interaction with the bot. The evaluation results show that the system works stably with good performance. All the visualizations and features are well designed and were understood by the users. Users preferred the speech interface with the bot over a textual interface. The research has a strong impact on the design of security and privacy features for mixed reality environments in general.},
booktitle = {Proceedings of the 2022 4th Asia Pacific Information Technology Conference},
pages = {63–71},
numpages = {9},
keywords = {collaboration, learning environment, mixed reality, social bots},
location = {Virtual Event, Thailand},
series = {APIT '22}
}

@inproceedings{10.1145/3290605.3300857,
author = {Roussou, Maria and Perry, Sara and Katifori, Akrivi and Vassos, Stavros and Tzouganatou, Angeliki and McKinney, Sierra},
title = {Transformation through Provocation?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300857},
doi = {10.1145/3290605.3300857},
abstract = {Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chatbots, conversational agents, cultural informatics, emotional engagement, provocative interaction, ux design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3411764.3445312,
author = {Langevin, Raina and Lordon, Ross J and Avrahami, Thi and Cowan, Benjamin R. and Hirsch, Tad and Hsieh, Gary},
title = {Heuristic Evaluation of Conversational Agents},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445312},
doi = {10.1145/3411764.3445312},
abstract = {Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen’s heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We find that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen’s heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {632},
numpages = {15},
keywords = {conversational agents, heuristic evaluation, user interface design},
location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
series = {CHI '21}
}

@inproceedings{10.1145/3276954.3276958,
author = {Baudart, Guillaume and Dolby, Julian and Duesterwald, Evelyn and Hirzel, Martin and Shinnar, Avraham},
title = {Protecting chatbots from toxic content},
year = {2018},
isbn = {9781450360319},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3276954.3276958},
doi = {10.1145/3276954.3276958},
abstract = {There is a paradigm shift in web-based services towards conversational user interfaces. Companies increasingly offer conversational interfaces, or chatbots, to let their customers or employees interact with their services in a more flexible and mobile manner. Unfortunately, this new paradigm faces a major problem, namely toxic content in user inputs. Toxic content in user inputs to chatbots may cause privacy concerns, may be adversarial or malicious, and can cause the chatbot provider substantial economic, reputational, or legal harm. We address this problem with an interdisciplinary approach, drawing upon programming languages, cloud computing, and other disciplines to build protections for chatbots. Our solution, called BotShield, is non-intrusive in that it does not require changes to existing chatbots or underlying conversational platforms. This paper introduces novel security mechanisms, articulates their security guarantees, and illustrates them via case studies.},
booktitle = {Proceedings of the 2018 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {99–110},
numpages = {12},
keywords = {Chatbot, Context Digression, Homomorphic Redaction},
location = {Boston, MA, USA},
series = {Onward! 2018}
}

@inproceedings{10.1145/3279972.3279980,
author = {Arora, Priya and Chaspari, Theodora},
title = {Exploring Siamese Neural Network Architectures for Preserving Speaker Identity in Speech Emotion Classification},
year = {2018},
isbn = {9781450360760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3279972.3279980},
doi = {10.1145/3279972.3279980},
abstract = {Voice-enabled communication is increasingly being used in real-world applications, such as the ones involving conversational bots or "chatbots". Chatbots can spark and sustain user engagement by effectively recognizing their emotions and acting upon them. However, the majority of emotion recognition systems rely on rich spectrotemporal acoustic features. Beyond the emotion-related information, such systems tend to preserve information relevant to the identity of the speaker, therefore raising major privacy concerns from the users. This paper introduces two hybrid architectures for privacy-preserving emotion recognition from speech. These architectures rely on a Siamese neural network, whose input and intermediate layers are transformed using various privacy-performing operations in order to retain emotion-dependent content and suppress information related to the identity of a speaker. The proposed approach is evaluated through emotion classification and speaker identification performance metrics. Results indicate that the proposed framework can achieve up to 67.4\% for classifying between happy, sad, frustrated, anger, neutral and other emotions, obtained from the publicly available Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset. At the same time, the proposed approach reduces speaker identification accuracy to 50\%, compared to 81\%, the latter being achieved through a feedforward neural network solely trained on the speaker identification task using the same input features.},
booktitle = {Proceedings of the 4th International Workshop on Multimodal Analyses Enabling Artificial Agents in Human-Machine Interaction},
pages = {15–18},
numpages = {4},
keywords = {Emotionally-aware conversational agents, Siamese neural network, multiplicative perturbation, principal component analysis, repeated Gombertz Function, speaker identity},
location = {Boulder, CO, USA},
series = {MA3HMI'18}
}

@inproceedings{10.1145/3313831.3376315,
author = {Strengers, Yolande and Qu, Lizhen and Xu, Qiongkai and Knibbe, Jarrod},
title = {Adhering, Steering, and Queering: Treatment of Gender in Natural Language Generation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376315},
doi = {10.1145/3313831.3376315},
abstract = {Natural Language Generation (NLG) supports the creation of personalized, contextualized, and targeted content. However, the algorithms underpinning NLG have come under scrutiny for reinforcing gender, racial, and other problematic biases. Recent research in NLG seeks to remove these biases through principles of fairness and privacy. Drawing on gender and queer theories from sociology and Science and Technology studies, we consider how NLG can contribute towards the advancement of gender equity in society. We propose a conceptual framework and technical parameters for aligning NLG with feminist HCI qualities. We present three approaches: (1) adhering to current approaches of removing sensitive gender attributes, (2) steering gender differences away from the norm, and (3) queering gender by troubling stereotypes. We discuss the advantages and limitations of these approaches across three hypothetical scenarios; newspaper headlines, job advertisements, and chatbots. We conclude by discussing considerations for implementing this framework and related ethical and equity agendas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {feminist hci, natural language generation},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI '20}
}

@inproceedings{10.1145/3517745.3561433,
author = {Edu, Jide and Mulligan, Cliona and Pierazzi, Fabio and Polakis, Jason and Suarez-Tangil, Guillermo and Such, Jose},
title = {Exploring the security and privacy risks of chatbots in messaging services},
year = {2022},
isbn = {9781450392594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3517745.3561433},
doi = {10.1145/3517745.3561433},
abstract = {The unprecedented adoption of messaging platforms for work and recreation has made it an attractive target for malicious actors. In this context, third-party apps (so-called chatbots) offer a variety of attractive functionalities that support the experience in large channels. Unfortunately, under the current permission and deployment models, chatbots in messaging systems could steal information from channels without the victim's awareness. In this paper, we propose a methodology that incorporates static and dynamic analysis for automatically assessing security and privacy issues in messaging platform chatbots. We also provide preliminary findings from the popular Discord platform that highlight the risks that chatbots pose to users. Unlike other popular platforms like Slack or MS Teams, Discord does not implement user-permission checks---a task entrusted to third-party developers. Among others, we find that 55\% of chatbots from a leading Discord repository request the "administrator" permission, and only 4.35\% of chatbots with permissions actually provide a privacy policy.},
booktitle = {Proceedings of the 22nd ACM Internet Measurement Conference},
pages = {581–588},
numpages = {8},
keywords = {chatbots, discord, messaging platorms, security and privacy},
location = {Nice, France},
series = {IMC '22}
}

@article{10.1145/3449171,
author = {Tian, Xiaoyi and Risha, Zak and Ahmed, Ishrat and Lekshmi Narayanan, Arun Balajiee and Biehl, Jacob},
title = {Let's Talk It Out: A Chatbot for Effective Study Habit Behavioral Change},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449171},
doi = {10.1145/3449171},
abstract = {Research has shown study habits and skills to be correlated with academic success, calling for a deeper comprehension of these behaviors and processes to design effective interventions for struggling students. Chatbots have recently been used as a persuasive technology to help support behavioral change, making them an intriguing design space for students' study habits and skills. This paper investigated the feasibility of using chatbots for promoting behavioral change of college students majoring in Computer Science (CS). We conducted semi-structured interviews with CS peer-tutors and surveyed university freshmen to understand students' study habits and identify technical intervention opportunities. Inspired by the findings, we designed StudyBuddy, a chatbot prototype deployed in Slack that periodically sends tips, provides assessments of students' study habits via surveys, helps the students break down assignments, recommends academic resources, and sends reminders. We evaluated the usability of the prototype in-depth with 8 students (both first-year and senior students) and 5 course instructors followed by a large scale evaluative survey (n=117) using video of the prototype. Our research identified important design challenges such as building trust and preserving privacy, limiting interaction costs, and supporting both immediate and long-term sustainable support. Likewise, we proposed design recommendations that demonstrate context awareness, personalize the experience based on user preferences, and adapt over time as students mature and grow.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {97},
numpages = {32},
keywords = {behavioral change, chatbot, computer science, persuasive technology, study habits and skills}
}

@inproceedings{10.1145/3625469.3625483,
author = {Liu, Yage},
title = {AI Chatbots in Social Media: Ethical Responsibilities and Privacy Challenges of Information and Communication Technology},
year = {2023},
isbn = {9798400707681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625469.3625483},
doi = {10.1145/3625469.3625483},
abstract = {In recent years, the pervasive integration of Artificial Intelligence (AI) chatbots into social media platforms has transformed the way individuals communicate and access information. This paper aims to critically examine the ethical responsibilities and privacy challenges associated with the application of Information and Communication Technology (ICT) in AI chatbots within social media environments. The purpose of this investigation is to highlight the complexities surrounding the implementation of chatbots and understand the implications of ICT with regards to ethical and privacy concerns. The study addresses the adoption of AI chatbots for varied applications such as customer support, content moderation, and personalized advertising. The central focus is on how ICT can inadvertently contribute to potential ethical dilemmas, including data bias, transparency, accountability, and privacy breaches. Moreover, the paper explores the existing regulatory frameworks governing the use of AI chatbots and recommends a set of best practices for ensuring ethical compliance and safeguarding user privacy. By evaluating the interplay between AI chatbots and ICT, this research offers valuable insights into the responsibilities and challenges that need to be considered to foster a more ethical and privacy-conscious implementation of AI chatbots in social media.},
booktitle = {Proceedings of the 2023 6th International Conference on Information Management and Management Science},
pages = {96–99},
numpages = {4},
keywords = {Data Protection, Information and Communication Technology (ICT), Social Media},
location = {<conf-loc>, <city>Chengdu</city>, <country>China</country>, </conf-loc>},
series = {IMMS '23}
}

@inproceedings{10.1145/3523150.3523168,
author = {Duvvuri, Venkata and Guan, Qihan and Daddala, Swetha and Harris, Mitch and Kaushik, Sudhakar},
title = {Predicting Depression Symptoms from Discord Chat Messaging Using AI Medical Chatbots},
year = {2022},
isbn = {9781450387477},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3523150.3523168},
doi = {10.1145/3523150.3523168},
abstract = {Depression is a chronic illness with even Olympic athletes [1] and top tennis players [2] withdrawing from competitions due to it. It's important to diagnose depression early. Traditional methods rely on questionnaires to evaluate depression. But they have their limitations due to inherent bias and inhibitions in self reporting. We propose an intelligent chatbot powered by AI approach to assist medical professionals diagnose depression. Specifically, the AI could predict depression symptoms in conversations with pre-care health care personnel and/or personal chats. Notably, due to sensitivity and privacy regulation (HIPPA) such data is not readily available [3]. To use AI driven medical assistants, and to overcome this limitation in training AI models, we propose to seed the models with recent chat engine (Discord) conversation dataset in the channel #depression. We achieve at least 73\% accuracy in predicting seven key symptoms for depression using our best ML models. Secondly, with our ensemble random forest model we could recall 30-69\% of depression symptoms with 60-99\% depression diagnosis accuracy which could be further tuned by medical professional if they know which ones of these symptoms is a key predictor of depression.},
booktitle = {Proceedings of the 2022 6th International Conference on Machine Learning and Soft Computing},
pages = {111–119},
numpages = {9},
keywords = {Artificial Intelligence, Convolution Neural Networks, Depression, Discord chat, Medical Chatbots, Random Forest, Support Vector Machine},
location = {Haikou, China},
series = {ICMLSC '22}
}

@inproceedings{10.1145/3461778.3462143,
author = {Park, SoHyun and Thieme, Anja and Han, Jeongyun and Lee, Sungwoo and Rhee, Wonjong and Suh, Bongwon},
title = {“I wrote as if I were telling a story to someone I knew.”: Designing Chatbot Interactions for Expressive Writing in Mental Health},
year = {2021},
isbn = {9781450384766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461778.3462143},
doi = {10.1145/3461778.3462143},
abstract = {Writing about experiences of trauma and other challenges in life is known to provide measurable health benefits. Though writing for an audience may ensure better benefits, confiding one's most troubled memories in others risks a social stigma. Conversational agents can provide a virtual audience that ensures privacy and allows social disclosure. To understand the writing experience with an agent, we created Diarybot, a chatbot assistant for expressive writing. We designed two versions, Basic and Responsive, to explore the writing experience with and without bot follow-up interactions compared to a Google doc baseline. Findings from a 4-day user study with 30 participants reveal that social disclosure with Diarybot can encourage narrative writing, with relative ease and emotional expression in Basic chat. Responsive chat can mediate social acceptance of the bot and provide guidance for self-reflection in the process. We discuss design reflections on social disclosure with agents in pursuit of wellbeing.},
booktitle = {Proceedings of the 2021 ACM Designing Interactive Systems Conference},
pages = {926–941},
numpages = {16},
keywords = {Expressive writing, chatbots, mental health, user experience},
location = {Virtual Event, USA},
series = {DIS '21}
}

@inproceedings{10.1145/3472301.3484358,
author = {Galv\~{a}o, Vinicius Ferreira and Maciel, Cristiano and Pereira, Vinicius Carvalho and Garcia, Ana Cristina Bicharra and Pereira, Roberto and Viterbo, Jos\'{e}},
title = {Posthumous data at stake: An Overview of Digital Immortality Issues},
year = {2021},
isbn = {9781450386173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472301.3484358},
doi = {10.1145/3472301.3484358},
abstract = {Who wants to be immortal? While this rhetorical question seems to haunt humans, digital immortality is already a reality. Social networks have allowed and facilitated our digital footprints to remain forever at reach of Internet users. We will all die, on the other hand, our digital self may remain forever. Social media technology has also allowed people to browse or even post messages to maintain the memory of a person alive. It seems spooky, but it is technically feasible to build a chatbot from a deceased person's digital legacy allowing a certain degree of presence of a deceased. This unaware digital immortality brings new cultural, technical, social, ethical, and legal challenges and implications that should be brought to light and discussed. There is an urge to recognize the limits for an adequate use of digital immortality. By means of an overview, this paper reports our literature survey where we identified some key issues regarding digital immortality, looking at the benefits, consequences and complications from its use. Our study identified differences when dealing with famous versus non-famous deceased, explicitly defined public versus private data, right and duties related to data preservation versus deletion, technological advances versus restrictions, cultural impedance, and differences from the reasons for desiring immortalization. With this article, we aim to encourage discussions on digital immortality, its current limits and points that need to be considered regarding such a sensitive theme that is already a current issue.},
booktitle = {Proceedings of the XX Brazilian Symposium on Human Factors in Computing Systems},
articleno = {43},
numpages = {8},
keywords = {Death, Digital Immortality, Digital Legacy, Posthumous Interaction},
location = {Virtual Event, Brazil},
series = {IHC '21}
}

@inproceedings{10.1145/3406522.3446043,
author = {Papenmeier, Andrea and Kern, Dagmar and Hienert, Daniel and Sliwa, Alfred and Aker, Ahmet and Fuhr, Norbert},
title = {Dataset of Natural Language Queries for E-Commerce},
year = {2021},
isbn = {9781450380553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406522.3446043},
doi = {10.1145/3406522.3446043},
abstract = {Shopping online is more and more frequent in our everyday life. For e-commerce search systems, understanding natural language coming through voice assistants, chatbots or from conversational search is an essential ability to understand what the user really wants. However, evaluation datasets with natural and detailed information needs of product-seekers which could be used for research do not exist. Due to privacy issues and competitive consequences, only few datasets with real user search queries from logs are openly available. In this paper, we present a dataset of 3,540 natural language queries in two domains that describe what users want when searching for a laptop or a jacket of their choice. The dataset contains annotations of vague terms and key facts of 1,754 laptop queries. This dataset opens up a range of research opportunities in the fields of natural language processing and (interactive) information retrieval for product search.},
booktitle = {Proceedings of the 2021 Conference on Human Information Interaction and Retrieval},
pages = {307–311},
numpages = {5},
keywords = {dataset, e-commerce, natural language query, user intent},
location = {Canberra ACT, Australia},
series = {CHIIR '21}
}

@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\"{a}, Pia},
title = {"\"Call me Kiran\" – ChatGPT as a Tutoring Chatbot in a Computer Science Course"},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {ChatGPT, artificial intelligence, chatbots, discussion forum, education, generative AI, student perceptions, tutoring},
location = {<conf-loc>, <city>Tampere</city>, <country>Finland</country>, </conf-loc>},
series = {Mindtrek '23}
}

