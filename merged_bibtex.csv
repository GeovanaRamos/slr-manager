BibtexKey,Title,Abstract,Author,Journal,BookTitle,Year,Doi,Url,Source,CreatedAt,Status
10.1145/3582515.3609536,Data Decentralisation of LLM-Based Chatbot Systems in Chronic Disease Self-Management,"Chronic patient self-management is crucial for maintaining physical and psychological health, reducing pressure on healthcare systems, and promoting patient empowerment. Digital technologies, particularly chatbots, have emerged as powerful tools for supporting patients in managing their chronic conditions. Large language models (LLMs), such as GPT-4, have shown potential in improving chatbot-based systems in healthcare. However, their adoption in clinical practice faces challenges, including reliability, the need for clinical trials, and privacy concerns. This paper proposes a general architecture for developing an LLM-based chatbot system that supports chronic patients while addressing privacy and security concerns. The architecture is designed to be independent of specific technologies and health conditions, focusing on data protection legislation compliance. A prototype of the system has been developed for hypertension management, demonstrating its potential for motivating patients to monitor their blood pressure and adhere to prescriptions.","Montagna, Sara and Ferretti, Stefano and Klopfenstein, Lorenz Cuno and Florio, Antonio and Pengo, Martino Francesco",,Proceedings of the 2023 ACM Conference on Information Technology for Social Good,2023,10.1145/3582515.3609536,https://doi.org/10.1145/3582515.3609536,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3340495.3342751,Hospitality of Chatbot Building Platforms,"The temptation to be able to talk to a machine is not new. Recent advancements in the field of Natural Language Understanding has made it possible to build conversational components that can be plugged inside an application, similar to other components. These components, called chatbots, can be created from scratch or with the help of commercially available platforms. These platforms make it easier to build and deploy chatbots, often without writing a single line of code. However, similar to any other software component, chatbots also have quality concerns. Despite significant contributions in the field, an architectural perspective of building chatbots with desired quality requirements is missing in the literature. In the current work, we highlight the impact of features provided by these platforms (along with their quality) on the application design process and overall quality attributes. We propose a methodological framework to evaluate support provided by a chatbot platform towards achieving quality in the application. The framework, called Hospitality Framework, is based on software architectural body of knowledge, especially architectural tactics. The framework produces a metric, called Hospitality Index, which has utilities for making various design decisions for the overall application. We present the use of our framework on a simple use case to highlight the phases of evaluation. We showcase the process by picking three popular chatbot platforms - Watson Assistant, DialogFlow and Lex, over four quality attributes - Modifiability, Security \&amp; Privacy, Interoperability and Reliability. Our results show that different platforms provide different support for these four quality attributes.","Srivastava, Saurabh and Prabhakar, T.V.",,Proceedings of the 2nd ACM SIGSOFT International Workshop on Software Qualities and Their Dependencies,2019,10.1145/3340495.3342751,https://doi.org/10.1145/3340495.3342751,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3512353.3512363,Privacy and Security in Mixed Reality Learning Environments by Input and User/Bot Interaction Protection,"Mixed reality is known as an advanced technology that provides a new approach for learning environments. Such environments allow learners to interact with both virtual and real worlds and bringing in potential enhancements to the learning process at the same time. For example, chatbots can facilitate the learning process. However, security and privacy settings for interacting with chatbots in such mixed reality environments are complex. In this paper, we introduce a mixed reality virtual assistant that is integrated into the collaborative environment of our existing application VIAProMa. This embodied chatbot allows lecturers and students to participate in mixed reality and online classrooms in real-time. The participants can interact with each other via VIAProMa’s avatar representations and can communicate with the chatbot that is represented by the mixed reality bot. The bot is realized by connecting a Slack chatbot with the mixed reality learning environment. It is displayed as an intuitive 3D model and is able to communicate with the users in spoken language. In this environment, privacy and security settings are conducted to protect the user input and user interaction with the bot. The evaluation results show that the system works stably with good performance. All the visualizations and features are well designed and were understood by the users. Users preferred the speech interface with the bot over a textual interface. The research has a strong impact on the design of security and privacy features for mixed reality environments in general.","Tran, Lan Anh and Hensen, Benedikt and Klamma, Ralf and Chantaraskul, Soamsiri",,Proceedings of the 2022 4th Asia Pacific Information Technology Conference,2022,10.1145/3512353.3512363,https://doi.org/10.1145/3512353.3512363,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3313831.3376315,"Adhering, Steering, and Queering: Treatment of Gender in Natural Language Generation","Natural Language Generation (NLG) supports the creation of personalized, contextualized, and targeted content. However, the algorithms underpinning NLG have come under scrutiny for reinforcing gender, racial, and other problematic biases. Recent research in NLG seeks to remove these biases through principles of fairness and privacy. Drawing on gender and queer theories from sociology and Science and Technology studies, we consider how NLG can contribute towards the advancement of gender equity in society. We propose a conceptual framework and technical parameters for aligning NLG with feminist HCI qualities. We present three approaches: (1) adhering to current approaches of removing sensitive gender attributes, (2) steering gender differences away from the norm, and (3) queering gender by troubling stereotypes. We discuss the advantages and limitations of these approaches across three hypothetical scenarios; newspaper headlines, job advertisements, and chatbots. We conclude by discussing considerations for implementing this framework and related ethical and equity agendas.","Strengers, Yolande and Qu, Lizhen and Xu, Qiongkai and Knibbe, Jarrod",,Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems,2020,10.1145/3313831.3376315,https://doi.org/10.1145/3313831.3376315,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3290605.3300857,Transformation through Provocation?,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely.","Roussou, Maria and Perry, Sara and Katifori, Akrivi and Vassos, Stavros and Tzouganatou, Angeliki and McKinney, Sierra",,Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems,2019,10.1145/3290605.3300857,https://doi.org/10.1145/3290605.3300857,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3411764.3445312,Heuristic Evaluation of Conversational Agents,"Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen’s heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We find that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen’s heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy.","Langevin, Raina and Lordon, Ross J and Avrahami, Thi and Cowan, Benjamin R. and Hirsch, Tad and Hsieh, Gary",,Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,2021,10.1145/3411764.3445312,https://doi.org/10.1145/3411764.3445312,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3449171,Let's Talk It Out: A Chatbot for Effective Study Habit Behavioral Change,"Research has shown study habits and skills to be correlated with academic success, calling for a deeper comprehension of these behaviors and processes to design effective interventions for struggling students. Chatbots have recently been used as a persuasive technology to help support behavioral change, making them an intriguing design space for students' study habits and skills. This paper investigated the feasibility of using chatbots for promoting behavioral change of college students majoring in Computer Science (CS). We conducted semi-structured interviews with CS peer-tutors and surveyed university freshmen to understand students' study habits and identify technical intervention opportunities. Inspired by the findings, we designed StudyBuddy, a chatbot prototype deployed in Slack that periodically sends tips, provides assessments of students' study habits via surveys, helps the students break down assignments, recommends academic resources, and sends reminders. We evaluated the usability of the prototype in-depth with 8 students (both first-year and senior students) and 5 course instructors followed by a large scale evaluative survey (n=117) using video of the prototype. Our research identified important design challenges such as building trust and preserving privacy, limiting interaction costs, and supporting both immediate and long-term sustainable support. Likewise, we proposed design recommendations that demonstrate context awareness, personalize the experience based on user preferences, and adapt over time as students mature and grow.","Tian, Xiaoyi and Risha, Zak and Ahmed, Ishrat and Lekshmi Narayanan, Arun Balajiee and Biehl, Jacob",Proc. ACM Hum.-Comput. Interact.,,2021,10.1145/3449171,https://doi.org/10.1145/3449171,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3276954.3276958,Protecting Chatbots from Toxic Content,"There is a paradigm shift in web-based services towards conversational user interfaces. Companies increasingly offer conversational interfaces, or chatbots, to let their customers or employees interact with their services in a more flexible and mobile manner. Unfortunately, this new paradigm faces a major problem, namely toxic content in user inputs. Toxic content in user inputs to chatbots may cause privacy concerns, may be adversarial or malicious, and can cause the chatbot provider substantial economic, reputational, or legal harm. We address this problem with an interdisciplinary approach, drawing upon programming languages, cloud computing, and other disciplines to build protections for chatbots. Our solution, called BotShield, is non-intrusive in that it does not require changes to existing chatbots or underlying conversational platforms. This paper introduces novel security mechanisms, articulates their security guarantees, and illustrates them via case studies.","Baudart, Guillaume and Dolby, Julian and Duesterwald, Evelyn and Hirzel, Martin and Shinnar, Avraham",,"Proceedings of the 2018 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software",2018,10.1145/3276954.3276958,https://doi.org/10.1145/3276954.3276958,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3279972.3279980,Exploring Siamese Neural Network Architectures for Preserving Speaker Identity in Speech Emotion Classification,"Voice-enabled communication is increasingly being used in real-world applications, such as the ones involving conversational bots or ""chatbots"". Chatbots can spark and sustain user engagement by effectively recognizing their emotions and acting upon them. However, the majority of emotion recognition systems rely on rich spectrotemporal acoustic features. Beyond the emotion-related information, such systems tend to preserve information relevant to the identity of the speaker, therefore raising major privacy concerns from the users. This paper introduces two hybrid architectures for privacy-preserving emotion recognition from speech. These architectures rely on a Siamese neural network, whose input and intermediate layers are transformed using various privacy-performing operations in order to retain emotion-dependent content and suppress information related to the identity of a speaker. The proposed approach is evaluated through emotion classification and speaker identification performance metrics. Results indicate that the proposed framework can achieve up to 67.4\% for classifying between happy, sad, frustrated, anger, neutral and other emotions, obtained from the publicly available Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset. At the same time, the proposed approach reduces speaker identification accuracy to 50\%, compared to 81\%, the latter being achieved through a feedforward neural network solely trained on the speaker identification task using the same input features.","Arora, Priya and Chaspari, Theodora",,Proceedings of the 4th International Workshop on Multimodal Analyses Enabling Artificial Agents in Human-Machine Interaction,2018,10.1145/3279972.3279980,https://doi.org/10.1145/3279972.3279980,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3517745.3561433,Exploring the Security and Privacy Risks of Chatbots in Messaging Services,"The unprecedented adoption of messaging platforms for work and recreation has made it an attractive target for malicious actors. In this context, third-party apps (so-called chatbots) offer a variety of attractive functionalities that support the experience in large channels. Unfortunately, under the current permission and deployment models, chatbots in messaging systems could steal information from channels without the victim's awareness. In this paper, we propose a methodology that incorporates static and dynamic analysis for automatically assessing security and privacy issues in messaging platform chatbots. We also provide preliminary findings from the popular Discord platform that highlight the risks that chatbots pose to users. Unlike other popular platforms like Slack or MS Teams, Discord does not implement user-permission checks---a task entrusted to third-party developers. Among others, we find that 55\% of chatbots from a leading Discord repository request the ""administrator"" permission, and only 4.35\% of chatbots with permissions actually provide a privacy policy.","Edu, Jide and Mulligan, Cliona and Pierazzi, Fabio and Polakis, Jason and Suarez-Tangil, Guillermo and Such, Jose",,Proceedings of the 22nd ACM Internet Measurement Conference,2022,10.1145/3517745.3561433,https://doi.org/10.1145/3517745.3561433,acm.bib,2023-09-02 14:05:28,Unclassified
10.1145/3523150.3523168,Predicting Depression Symptoms from Discord Chat Messaging Using AI Medical Chatbots,"Depression is a chronic illness with even Olympic athletes [1] and top tennis players [2] withdrawing from competitions due to it. It's important to diagnose depression early. Traditional methods rely on questionnaires to evaluate depression. But they have their limitations due to inherent bias and inhibitions in self reporting. We propose an intelligent chatbot powered by AI approach to assist medical professionals diagnose depression. Specifically, the AI could predict depression symptoms in conversations with pre-care health care personnel and/or personal chats. Notably, due to sensitivity and privacy regulation (HIPPA) such data is not readily available [3]. To use AI driven medical assistants, and to overcome this limitation in training AI models, we propose to seed the models with recent chat engine (Discord) conversation dataset in the channel #depression. We achieve at least 73\% accuracy in predicting seven key symptoms for depression using our best ML models. Secondly, with our ensemble random forest model we could recall 30-69\% of depression symptoms with 60-99\% depression diagnosis accuracy which could be further tuned by medical professional if they know which ones of these symptoms is a key predictor of depression.","Duvvuri, Venkata and Guan, Qihan and Daddala, Swetha and Harris, Mitch and Kaushik, Sudhakar",,Proceedings of the 2022 6th International Conference on Machine Learning and Soft Computing,2022,10.1145/3523150.3523168,https://doi.org/10.1145/3523150.3523168,acm.bib,2023-09-02 14:05:28,Unclassified
9355474,Privacy Preserving Chatbot Conversations,"With chatbots gaining traction and their adoption growing in different verticals, e.g. Health, Banking, Dating; and users sharing more and more private information with chatbots - studies have started to highlight the privacy risks of chatbots. In this paper, we propose two privacypreserving approaches for chatbot conversations. The first approach applies `entity' based privacy filtering and transformation, and can be applied directly on the app (client) side. It however requires knowledge of the chatbot design to be enabled. We present a second scheme based on Searchable Encryption that is able to preserve user chat privacy, without requiring any knowledge of the chatbot design. Finally, we present some experimental results based on a real-life employee Help Desk chatbot that validates both the need and feasibility of the proposed approaches.","Biswas, Debmalya",,2020 IEEE Third International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),2020,10.1109/AIKE48582.2020.00035,,ieee.bib,2023-09-02 14:05:28,Unclassified
8814570,Children Privacy Identification System in LINE Chatbot for Smart Toys,"Children's privacy concerns about smart toys are becoming more and more critical in the toy industry. Parents and guardians continue to strive to protect their children from unnecessary privacy risks such as collection, and unconsented use of or access to their children's information. However, there is still no standardized privacy framework, which focuses on smart toys in this paradigm; making it difficult to determine possible privacy violation in for example determining whether a phrase shared with a smart toy is sensitive or not. To overcome this challenge, we build a privacy identification system through Chatbot technology. We call this system a Children Privacy Identification (CPI) system. To develop CPI system, we divide our research works into two parts: (1) Collect the phrase from the smart toys; and (2) Explore privacy Identification based on Personally Identifiable Information (PII) and Children's Online Privacy Protection Act (COPPA). For illustration, we integrate the CPI system in LINE Chatbot. The result shows that people feel more comfortable in talking to LINE Chatbot with privacy protection.","Lin, Pei-Chun and Yankson, Benjamin and Lu, Zhihui and Hung, Patrick C.K.",,2019 IEEE 12th International Conference on Cloud Computing (CLOUD),2019,10.1109/CLOUD.2019.00026,,ieee.bib,2023-09-02 14:05:28,Unclassified
10189497,A Privacy-Preserving Framework for Mental Health Chatbots Based on Confidential Computing,"Mental health chatbots can provide psychological counseling services to patients at any time regardless of time and location, which can not only relieve patients’ ailments but also reduce the workload of psychologists. In order to provide patients with accurate diagnosis and treatment services, mental health robots inevitably collect patient-related information during the communication process with patients, which is often very sensitive and must be well protected. There is a lack of targeted research on how mental health chatbots can provide systematic privacy preserving for patients in the process of providing mental health services to them. In this paper, we propose a privacy preserving framework based on blockchain and confidential computing that can provide comprehensive privacy preserving for patients during mental health chatbot services. We conduct tests using existing mental health chatbots, and the experimental results demonstrate that our proposed framework can meet the requirements for privacy preserving and computational performance of mental health chatbots.","Tian, Wensheng and Lu, Yifan and Yu, Jinhao and Fan, Jiafeng and Tang, Panpan and Zhang, Lei",,"2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)",2022,10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00160,,ieee.bib,2023-09-02 14:05:28,Unclassified
10125731,Data Preservation in Chatbot with Cloud Deployment,"In today's digital age, the importance of preserving and organizing important documents and information cannot be overstated. To create a comprehensive solution for secure file sharing through the use of a Telegram chatbot. The bot will have the ability to encrypt and decrypt files, allowing users to share sensitive information with confidence. The encryption and decryption will be performed using AES algorithms to ensure the security of the files. To further enhance security and scalability, the chatbot will be deployed to a cloud platform, allowing it to be accessed from anywhere and handle a larger number of users. Additionally, this project will also focus on implementing data preservation functionality within the chatbot. This will ensure that files are retained and accessible even when they are deleted from the Telegram chat or when the chatbot is deployed to the doud. This will be achieved through techniques such as data backup and disaster recovery to ensure data availability. Overall, this aims to provide a secure and reliable system for sharing files through Telegram, that guarantees the security of the files, the availability of the data and the scalability of the system. It is tailored for organizations, businesses and individuals who need to share sensitive information regularly.","T, Vijaya Kumar and P, Rajasekaran and L, Jeevika and S, Lavan and R, Tharshan",,2023 7th International Conference on Trends in Electronics and Informatics (ICOEI),2023,10.1109/ICOEI56765.2023.10125731,,ieee.bib,2023-09-02 14:05:28,Unclassified
9125183,Work-in-Progress: A Preliminary Study on Students’ Acceptance of Chatbots for Studio-Based Learning,"Studio-based learning (SBL) is a pedagogy that encompasses collaborative active learning strategies focusing on creativity, peer learning, and problem-solving. The iterative design procedures and critique sessions are the primary learning practices of SBL, which relays to a need to have effective communication between instructors and students. Due to this, we designed a Telegram chatbot using the TextIt to facilitate some of the interactions that are common in SBL. In this preliminary study, students’ acceptance of chatbot was investigated based on the Technology Acceptance Model (TAM) using a mix-method approach. Preliminary results indicated positive acceptance and intention to use chatbots due to ease of use, mobile accessibility, human-like communications, and privacy in communicating and providing feedback.","Kumar, Jeya Amantha and Silva, Paula Alexandra",,2020 IEEE Global Engineering Education Conference (EDUCON),2020,10.1109/EDUCON45650.2020.9125183,,ieee.bib,2023-09-02 14:05:28,Unclassified
9660118,Development of Esteem Support based on Psychodrama and Design Thinking approach,"So far, we have proposed the Stress management framework and developed methods for stress measurement and coping. There are three types of coping in this framework: information support, emotional support, and esteem support. This time, we developed esteem support. In order to increase self-esteem, we focused on psychodrama techniques and developed a system to realize psychodrama using robots. The advantages of using robots include the ability to carry out a psychodrama alone and to provide privacy-friendly support. In the experiment, a scenario was created for medical staff and a robot psychodrama was performed. As a result, we showed that robots can be used for psychodrama and esteem support can be carried out by combination of robots and the chatbot.","Yorita, Akihiro and Egerton, Simon and Chan, Carina and Kubota, Naoyuki",,2021 IEEE Symposium Series on Computational Intelligence (SSCI),2021,10.1109/SSCI50451.2021.9660118,,ieee.bib,2023-09-02 14:05:28,Unclassified
9766793,Impersonating Chatbots in a Code Review Exercise to Teach Software Engineering Best Practices,"Over the past decade, the use of chatbots for educational purposes has gained considerable traction. A similar trend has been observed in social coding platforms, where automated agents support software developers with tasks such as performing code reviews. While incorporating code reviews and social coding platforms into software engineering education has been found to be beneficial, challenges such as steep learning curves and privacy considerations are barriers to their adoption. Furthermore, no study has addressed the role chatbots play in supporting code reviews as a pedagogical tool. To help address this gap, we developed an online learning application that simulates the code review features available on social coding platforms and allows instructors to interact with students using chatbot identities. We then embedded this application within a lesson on software engineering best practices and conducted a controlled in-class experiment. This experiment examined the effect that explaining content via chatbot identities had on three aspects: (i) students’ perceived usability of the lesson, (ii) their engagement with the code review process, and (iii) their learning gains. While our findings show that it is feasible to simulate the code review process within an online learning platform and achieve good usability, our quantitative analysis did not yield significant differences across treatment conditions for any of the aspects considered. Nevertheless, our qualitative results suggest that students expect explicit feedback when performing this type of exercise and could thus benefit from automated replies provided by an interactive chatbot. We propose to build on our current findings to further explore this line of research in future work.","Farah, Juan Carlos and Spaenlehauer, Basile and Sharma, Vandit and Rodríguez-Triana, María Jesús and Ingram, Sandy and Gillet, Denis",,2022 IEEE Global Engineering Education Conference (EDUCON),2022,10.1109/EDUCON52537.2022.9766793,,ieee.bib,2023-09-02 14:05:28,Unclassified
10219493,Transforming Chronic Disease Management with Chatbots: Key Use Cases for Personalized and Cost-effective Care,"Globally, the problem of chronic diseases like diabetes, hypertension, and heart disease is getting worse. These diseases have a significant impact on patients and healthcare systems. Innovative technologies like chatbots, which promise to improve the management of chronic diseases, have emerged as potential solutions to these difficulties. Chatbots are man-made brainpower (artificial intelligence) programs that can recreate discussions with people and give customized and practical consideration. The primary purposes of this study are to investigate the most important applications of chatbots in the management of chronic diseases, including personalized education, symptom monitoring, medication management, and lifestyle coaching. In addition, it discusses the potential advantages and disadvantages of chatbots in the management of chronic diseases, including the need for human oversight, data privacy, and patient engagement. The paper concludes that, although chatbots have the potential to transform the management of chronic diseases by providing personalized and cost-effective care, careful consideration of ethical, legal, and regulatory frameworks is required for their integration into healthcare systems.","Haque, Ahshanul and Chowdhury, Md Naseef-Ur-Rahman and Soliman, Hamdy",,"2023 Sixth International Symposium on Computer, Consumer and Control (IS3C)",2023,10.1109/IS3C57901.2023.00104,,ieee.bib,2023-09-02 14:05:28,Unclassified
9680760,Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations,"AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.","Bang, Junseong and Kim, Sineae and Nam, Jang Won and Yang, Dong-Geun",,2021 International Conference on Platform Technology and Service (PlatCon),2021,10.1109/PlatCon53246.2021.9680760,,ieee.bib,2023-09-02 14:05:28,Unclassified
9920434,Study Literature Review: Discovering the Effect of Chatbot Implementation in E-commerce Customer Service System Towards Customer Satisfaction,"Customer service plays a crucial role for a company. As an important aspect of e-commerce companies, they would be required to directly interact and try to solve customers’ problems that might occur anywhere and anytime. However, the limitation of human man hours became a barrier to overcome customers’ problems. On one hand, the rapid development of technology was predicted to replace the traditional human customer service with an Artificial Intelligence agent. On the other hand, this replacement affects the customer satisfaction. This paper performed a study literature review to discover the effect of chatbots and its impact towards customer satisfaction. In an e-commerce customer service use case, chatbots could be implemented in a number of methods. The methods implemented by chatbots are avatar-based, verbal-based, text-based, and menu-based. Research showed that text-based chatbot is the most commonly used methodology and has advanced the most, where some are implementing higher level machine learning methods, such as deep learning. The usage of such chatbot in e-commerce customer service systems will lower the cost but might also lower customer satisfaction, due to reasons such as unsatisfying answers and inhuman behavior. Research showed that even a more sophisticated chatbot doesn’t always mean higher customer satisfaction, even with high accuracy ratings. To look into customer satisfaction, this paper has identified 4 aspects of a chatbot that are relevant to customer satisfaction, which are privacy, reliability, personalization, and responsiveness. Chatbots currently excel in some of these quality measures, but require further research to effectively replace human customer service agents.","Antonio, Randy and Tyandra, Nadya and Nusantara, Linggar Tembus and Anderies and Agung Santoso Gunawan, Alexander",,2022 International Seminar on Application for Technology of Information and Communication (iSemantic),2022,10.1109/iSemantic55962.2022.9920434,,ieee.bib,2023-09-02 14:05:28,Unclassified
10219468,Chatbots: A Game Changer in mHealth,"Chatbots have emerged as a promising tool in healthcare for improving patient engagement, providing education and support, and delivering interventions for a variety of health conditions. In the field of mHealth (mobile health), chatbots are being increasingly used to support self-management, provide remote monitoring, and offer personalized coaching to patients with chronic conditions. A growing body of research has demonstrated the feasibility, acceptability, and effectiveness of chatbots in mHealth, with many studies reporting positive outcomes such as improved patient adherence, increased physical activity, and reduced hospital readmissions. However, there are also limitations and challenges to the use of chatbots in mHealth, such as concerns around data privacy and security, the need for effective natural language processing and machine learning algorithms, and ensuring that chatbots are designed with the end user in mind. Future research is needed to further explore the potential of chatbots in mHealth, and to develop best practices for their design, implementation, and evaluation.","Chowdhury, Md Naseef-Ur-Rahman and Haque, Ahshanul and Soliman, Hamdy",,"2023 Sixth International Symposium on Computer, Consumer and Control (IS3C)",2023,10.1109/IS3C57901.2023.00103,,ieee.bib,2023-09-02 14:05:28,Unclassified
10200330,A Machine Learning-Based Methodology for IoT Security,"The popularity of IoT and gadget connectivity is rapidly growing in the present world. Cyber risk has become a significant issue for IoT devices, particularly edge devices, as D2D communication and Internet traffic have grown. The use case of machine learning for IoT security is presented in this proposal. Recent scientific advancements often lead to the development of new technologies. In order to help with this proposal, machine learning is now used by our society. It is because maintaining and managing the data is extremely difficult for humans. As new technologies are developed, cybersecurity measures can be enhanced through innovative methods. The most recent and promising strategy in cyber-physical security is machine learning (ML), which can help address a number of burgeoning issues. Explore potential problems with IoT security controls when applying machine learning to IoT systems and the design of IoT systems. Because smart gadgets are so accessible and in such high demand, IoT systems are exposed to new cyber-physical security and privacy assaults. IoT systems need to be secured with strong, adaptable, and contemporary security techniques.","S, Pousia and N, Kowsick and M S, Rinishvanth and D, Rahul and S, Shri Hari and S, Pravin Kumar",,"2023 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)",2023,10.1109/ACCAI58221.2023.10200330,,ieee.bib,2023-09-02 14:05:28,Unclassified
9914844,Psyche Conversa - A Deep Learning Based Chatbot Framework to Detect Mental Health State,"Mental health is one of the most pressing challenges in today's modern world. Traditional thinking, family pressure, unemployment issues, homesickness, and an unhappy relationship are the most common reasons for mental illness, which may also lead to suicidal attempts. People in impoverished countries do not give this issue enough attention. Furthermore, many are hesitant to seek professional counseling from a psychiatrist to retain their privacy. Monitoring social media activities, in addition to common symptoms, is critical for improving the accuracy of detecting early signs of mental illness because it impacts mental health. So, rather than a psychiatrist, a user-friendly deep learning-based mobile application that will chat with them to support and monitor their social media behaviors to determine their mental health status will be an effective way of handling the situation. This study proposes a deep learning-based chatbot framework to help mentally ill individuals identify their mental health conditions and provide appropriate therapy. This framework comprises three components: a keylogger module, a chat module, and a deep learning-based mental illness detection module. In the background, the keylogger collects data from the user's keyboard to track social media activity. The chatbot converses with users and stores their daily chat history in real-time. Both modules pass the data to a deep learning model to determine mental health conditions. This study also compared the accuracy of multiple deep learning classifiers such as Conv-LSTM and BERT for the Reddit Mental Health Dataset.","Abu Noman Siddik, Sayed and Arifuzzaman, B.M. and Kalam, Abul",,2022 10th International Conference on Information and Communication Technology (ICoICT),2022,10.1109/ICoICT55009.2022.9914844,,ieee.bib,2023-09-02 14:05:28,Unclassified
10065328,"Chatbots in Healthcare: Challenges, Technologies and Applications","Artificial intelligence (AI) technologies have been around for more than fifty years. However, current improvements in processing power, the accessibility of huge amounts of data, and improved algorithms have led to significant advancements in AI. A chatbot is a software program with AI that simulates user interactions. Healthcare chatbots gradually eliminate hospital wait times, appointments, and consultation meetups, thus instantly assisting patients in connecting with the right doctor. Chatbots reduce the workload of healthcare providers by decreasing the number of hospital visits and unnecessary treatments, providing suggestions and alerts. However, the introduction of such chatbots in the healthcare domain exposes users to a plethora of challenges. This paper presents a systematic survey of recent developments by researchers in the field of healthcare chatbots. This research brings to light general information regarding the application type, various technologies and evaluation methods that have been used to evaluate the effectiveness of healthcare chatbots and aims to serve as a research guideline which may be valuable for the development of chatbots in various fields.","Sharma, Deepali and Kaushal, Sakshi and Kumar, Harish and Gainder, Shalini",,2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST),2022,10.1109/AIST55798.2022.10065328,,ieee.bib,2023-09-02 14:05:28,Unclassified
9123051,SLA as a mechanism to manage risks related to chatbot services,Intelligent Chatbot services become one of the mainstream applications in user help and many other areas. Apart from bringing numerous benefits to users these services may bring additional risks to the companies that employ them. The study starts with the review of the scale of chatbot industry and common use cases by focusing on their applications & industry tendencies. Review of functionality and architecture of typical chatbot services shows the potential risks associated with chatbots. Analysis of such risks in the paper helped to build a checklist that security managers can use to assess risks prior to chatbot implementation. The proposed checklist was tested by reviewing a number of Service Level Agreements (SLA) of real chatbot providers.,"Gondaliya, Krishna and Butakov, Sergey and Zavarsky, Pavol",,"2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)",2020,10.1109/BigDataSecurity-HPSC-IDS49724.2020.00050,,ieee.bib,2023-09-02 14:05:28,Unclassified
9794852,Sociocultural and Information Security Issues in the Implementation of Neural Network Technologies in Chat-bots Design,"Neural networks are trained on actual material. People in their communication use both socio-cultural rules of courtesy and good taste, and take into account threats to protect data, based on long-term experience and long-term risk prediction. Human behavior provides neural networks with examples of both appropriate behavior and manners with limited application depending on the context, as well as unacceptable and unacceptable behaviors, such as rude emotional discharge or information disclosure in associated metadata. Based on the analysis of several cases of the implementation and functioning of chatbots, the main groups of ethical problems and the main tasks in the field of information security are shown, key approaches to ensuring etiquette and data protection are identified, and proposals are formulated for procedures for machine learning in relation to chatbots in corporate ecosystems.","Pokrovskaia, Nadezhda N.",,2022 XXV International Conference on Soft Computing and Measurements (SCM),2022,10.1109/SCM55405.2022.9794852,,ieee.bib,2023-09-02 14:05:28,Unclassified
8929183,On Design and Implementation a Federated Chat Service Framework in Social Network Applications,"As many organizations deploy their chatbots on social network applications to interact with their customers, a person may switch among different chatbots for different services. To reduce the switching cost, this study proposed the Federated Chat Service Framework. The framework maintains user profiles and historical behaviors. Instead of deploying chatbots, organizations follow the rules of the framework to provide chat services. Therefore, the framework can organize service requests with context information and responses to emulate the conversations between users and chat services. Consequently, the study can hopefully contribute to reducing the cost for a user to communicate with different chatbots.","Cha, Shi-Cho and Li, Zhuo-Xun and Fan, Chuan-Yen and Tsai, Mila and Li, Je-Yu and Huang, Tzu-Chia",,2019 IEEE International Conference on Agents (ICA),2019,10.1109/AGENTS.2019.8929183,,ieee.bib,2023-09-02 14:05:28,Unclassified
10104905,Artificial Intelligence’s Contribution To Mental Health Education,"As AI offers a suitable response to various challenges associated with this disease, it plays a crucial role in mental health. A fundamental concept of the AI-based mental health remedy and its impact on directly affecting social-emotional learning has also been examined in this study with the appropriate material and references. The many types of AI that may unquestionably aid in general mental health education have already been specifically outlined in this research using all the data from existing books and publications. In addition to this, an AI-based chatbot platform has been built within the software system to identify various health factors that seem to be directly linked to mental health. The main challenges in this regard remained consistent with other AI-related healthcare systems including concerns for privacy and confidentiality apart from data integrity.","Anand, Neha and Pant, Lalit Mohan and Alam, Tanweer and Pundir, Sumit and Thomas, Lims and Rakshith, U.R.",,2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),2023,10.1109/ICSCDS56580.2023.10104905,,ieee.bib,2023-09-02 14:05:28,Unclassified
9570253,Artificial Intelligence for Futuristic Banking,"Artificial Intelligence (AI) has become an essential resource for large banks that deal with regulatory changes, new Anti-Money Laundering (AML) obligations and vulnerable fraud-prone clients. Cybersecurity has thus become a hot topic due to security failures using traditional methods and concerns about how companies use the personal data collected from clients or their regular users. The most obvious apparent reason why cybersecurity is critical in banking sector transactions is to protect client assets with a high level of data privacy. The main approaches in the front office conventional banking such as AI chatbots, smart virtual assistants and biometric user authentication are discovered to answer security challenges and to enhance prosperity in the field. Concurrently, advanced AI applications in fraud detection, fraud risk monitoring, anti-money laundering techniques and cross-border payments handling are observed under the back-office operations. The paper reviews the conceptualizations of privacy concerns and the antecedents and consequences of using AI-power in the banking sector. Moreover, overlooked limitations of AI such as scarcity of quality data, a rise of hidden-bias in suggestions and obliviousness of lacking knowledge are discussed with several thriving solutions.","Thisarani, Moksha and Fernando, Subha",,"2021 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)",2021,10.1109/ICE/ITMC52061.2021.9570253,,ieee.bib,2023-09-02 14:05:28,Unclassified
10198233,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.","Gupta, Maanak and Akiri, Charankumar and Aryal, Kshitiz and Parker, Eli and Praharaj, Lopamudra",IEEE Access,,2023,10.1109/ACCESS.2023.3300381,,ieee.bib,2023-09-02 14:05:28,Unclassified
9422858,Anonymous Communication Strategy in Telegram: Toward Comparative Analysis of Russia and Belarus,"This paper aims to study anonymous communication strategy in the Telegram. Telegram is a new cloud-messenger that is highly popular among bloggers and media in Russia and Belarus. Established by Pavel Durov in 2013, it offers secure and anonymous communication features. Anonymous communication has been studied by many scholars (Choudhury, Sharon, Watt, Zhang, etc), but it seems that more questions are left unanswered. This paper starts distinguishing anonymity from related notions of confidentiality and secrecy, privacy, and publicity. We provide some vocabulary to talk about anonymization and identification efforts by message sources and receivers. The paper highlights some of the limitations of current communication scholarship in this area such as anonymous communication strategy. The growing role of the Telegram messenger in the mass communications systems of Russia and Belarus indicates new opportunities for anonymous communication strategy in the digital society. The research methodology is based on a comparative analysis of statistical data on the audience of the leading Telegram news channels. The authors argue that the anonymous communication strategy has taken an important share of the market in both countries. In a comparative aspect, the indicators of the involvement of Telegram channels were analyzed. The main results of the study show that the use of various Telegram features both as a messenger and as a full-fledged media is constantly increasing. The intensity of the use of the messenger has increased and the variety of functions it performs has also increased. It has been established that the Telegram platform contributes to strengthening feedback from the audience. Chatbots have become a new opportunity to receive information from readers. The authors conclude that alternative Telegram channels play an important role in the digital environment.","Bykov, Ilya A. and Medvedeva, Mariia V. and Hradziushka, Aleksandr A.",,2021 Communication Strategies in Digital Society Seminar (ComSDS),2021,10.1109/ComSDS52473.2021.9422858,,ieee.bib,2023-09-02 14:05:28,Unclassified
10202649,Speaker Orientation-Aware Privacy Control to Thwart Misactivation of Voice Assistants,"Smart home voice assistants (VAs) such as Amazon Echo and Google Home have become popular because of the convenience they provide through voice commands. VAs continuously listen to detect the wake command and send the subsequent audio data to the manufacturer-owned cloud service for processing to identify actionable commands. However, research has shown that VAs are prone to replay attack and accidental activations when the wake words are spoken in the background (either by a human or played through a mechanical speaker). Existing privacy controls are not effective in preventing such misactivations. This raises privacy and security concerns for the users as their conversations can be recorded and relayed to the cloud without their knowledge. Recent studies have shown that the visual gaze plays an important role when interacting with conservation agents such as VAs, and users tend to turn their heads or body toward the VA when invoking it. In this paper, we propose a device-free, non-obtrusive acoustic sensing system called HeadTalk to thwart the misactivation of VAs. The proposed system leverages the user's head direction information and verifies that a human generates the sound to minimize accidental activations. Our extensive evaluation shows that HeadTalk can accurately infer a speaker's head orientation with an average accuracy of 96.14\% and distinguish human voice from a mechanical speaker with an equal error rate of 2.58\%. We also conduct a user interaction study to assess how users perceive our proposed approach compared to existing privacy controls. Our results suggest that HeadTalk can not only enhance the security and privacy controls for VAs but do so in a usable way without requiring any additional hardware.","Zhang, Shaohu and Sabir, Aafaq and Das, Anupam",,2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),2023,10.1109/DSN58367.2023.00061,,ieee.bib,2023-09-02 14:05:28,Unclassified
9995430,Psychosis iREACH: Reach for Psychosis Treatment using Artificial Intelligence,"Psychosis iREACH aims to optimize the delivery of evidence-based cognitive behavioral therapy to family caregivers who have a loved one with psychosis. It is an accessible digital platform that can utilize the user’s intent and entities to determine the appropriate response. The platform is implemented based on an artificial intelligence and natural language understanding (NLU) framework, RASA. We developed the web application of the platform, and the chatbot has been integrated into the platform to collect data and evaluate the performance. The results showed that the NLU model’s accuracy, precision, recall, and F1- score of the intent prediction are 88.31\%, 89.80\%, 88.22\%, and 88.65\% respectively. The link to the website is https://psychosisireach.uw.edu/.","Lee, Jonathan and Kopelovich, Sarah and Cheng, Sunny Chieh and Si, Dong",,2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),2022,10.1109/BIBM55620.2022.9995430,,ieee.bib,2023-09-02 14:05:28,Unclassified
9892366,Domain-Aware Federated Social Bot Detection with Multi-Relational Graph Neural Networks,"Social networks have been the widespread popular tools for communication and socialization, and it also been the ideal platform for bots to publish malicious information. Therefore, social bot detection is essential for the social network's security. Existing methods almost ignore the differences in bot behaviors in multiple domains. Thus, we first propose a DomainAware detection method with Multi-Relational Graph neural networks (DA-MRG) to improve detection performance. Specifically, DA-MRG constructs multi-relational graphs with users' features and relationships, obtains the user presentations with graph embedding and distinguishes bots from humans with domainaware classifiers. Meanwhile, considering the similarity between bot behaviors in different social networks, we believe that sharing data among them could boost detection performance. However, the data privacy of users needs to be strictly protected. To overcome the problem, we implement a study of federated learning framework for DA-MRG to achieve data sharing between different social networks and protect data privacy simultaneously. We conduct extensive experiments on TwiBot-20, and the results demonstrate that the proposed method can effectively achieve federated social bot detection.","Peng, Huailiang and Zhang, Yujun and Sun, Hao and Bai, Xu and Li, Yangyang and Wang, Shuhai",,2022 International Joint Conference on Neural Networks (IJCNN),2022,10.1109/IJCNN55064.2022.9892366,,ieee.bib,2023-09-02 14:05:28,Unclassified
10025250,Oxygen: A Distributed Health Care Framework for Patient Health Record Management and Pharmaceutical Diagnosis,"With the COVID-19 pandemic, the world is confronting various healthcare issues, and healthcare automation is more crucial than ever. The pandemic has revealed the limitations of existing digital healthcare systems to manage public health emergencies. There is no registered population for many healthcare institutions in Sri Lanka, as a result, there is a communication gap. Electronic Health Record systems (EHRs) are becoming popular to share patient details but accessing scattered data across several EHRs while safeguarding patient privacy remains a challenge. Most of these medical records are in printed format and manually entering those into EHR systems is time-consuming and error prone. Not only that pharmaceutical error is a critical healthcare problem, but it is even riskier to visit doctors for pharmaceutical diagnosis during a pandemic. This research introduces a Blockchain-based patient health record system, an Optical Character Recognition (OCR) and Natural Language Processing (NLP) based Medical Document Scanner, a Drug Identifier based on Image Processing and a Medical Chatbot powered by NLP as four novel approaches to address these issues. Altogether with the results, this research aims at introducing a solution for the limitations in healthcare while providing a distributed healthcare framework for the healthcare community worldwide.","Wickramarathna, Maleesha and De Silva, Kithmini and Lekamalage, Vihanga and Senanayake, Janith and Perera, Jeewaka and Ruggahakotuwa, Laneesha",,2022 4th International Conference on Advancements in Computing (ICAC),2022,10.1109/ICAC57685.2022.10025250,,ieee.bib,2023-09-02 14:05:28,Unclassified
Bosse2015650,Integrating conversation trees and cognitive models within an ECA for aggression de-escalation training,"Traditionally, Embodied Conversational Agents communicate with humans using dialogue systems based on conversation trees. To enhance the flexibility and variability of dialogues, this paper proposes an approach to integrate conversation trees with cognitive models. The approach is illustrated by a case study in the domain of aggression de-escalation training, and a preliminary evaluation in the context of a practical application is presented. © Springer International Publishing Switzerland 2015.","Bosse, Tibor and Provoost, Simon",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2015,10.1007/978-3-319-25524-8_48,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950336129&doi=10.1007%2f978-3-319-25524-8_48&partnerID=40&md5=e289e5b528b5a1db01513dffee4ac153,scopus.bib,2023-09-02 14:05:29,Unclassified
Bahja202032,A User-Centric Framework for Educational Chatbots Design and Development,"Increasing frequency of epidemics, such as SARS-CoV, MERS-CoV, Ebola, and the recent COVID-19, have affected various sectors, especially education. As a result, emphasis on e-learning and distance learning has been increasing in recent years. The growing numbers of mobile users and access to the internet across the world has created more favorable conditions for adopting distance learning on a wider scale. However, lessons learnt from current experiments have highlighted poor student engagement with learning processes, hence a user-centric approach to design and develop educational chatbots is presented. A User-centric approach enables developers to consider the following: learners’ and teachers’ technological skills and competencies, attitudes, and perceptions and behaviour; conceptual concerns, such as pedagogical integration on online platforms, assessment procedures, varying learning culture and lifestyles; technical concerns, such as privacy, security, performance, ubiquity; and regulatory concerns, such as policies, frameworks, standards, ethics, roles and responsibilities have been identified in this study. To address these concerns, there is the need for user-centric design and collaborative approaches to the development of distance learning tools. Considering the abovementioned challenges and the growing emphasis on distance learning, we propose chatbot learning as an effective and efficient tool for delivering such learning. In this regard, a user-centric framework for designing chatbot learning applications and a collaborative user-centric design methodology for developing chatbot learning applications is proposed and discussed. © 2020, Springer Nature Switzerland AG.","Bahja, Mohammed and Hammad, Rawad and Butt, Gibran",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2020,10.1007/978-3-030-60117-1_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094133150&doi=10.1007%2f978-3-030-60117-1_3&partnerID=40&md5=4baee2d8c75b50a1f03bcff28e812b66,scopus.bib,2023-09-02 14:05:29,Unclassified
Roussou2019,Transformation through provocation? Designing a ‘bot of conviction’ to challenge conceptions and evoke critical reflection,"Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically “minimal” medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a “bot of conviction”, aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely. © 2019 Association for Computing Machinery.","Roussou, Maria and Perry, Sara and Katifori, Akrivi and Vassos, Stavros and Tzouganatou, Angeliki and McKinney, Sierra",Conference on Human Factors in Computing Systems - Proceedings,,2019,10.1145/3290605.3300857,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067615313&doi=10.1145%2f3290605.3300857&partnerID=40&md5=ab8c04e96ab8576470a51ac574b70571,scopus.bib,2023-09-02 14:05:29,Unclassified
Macdonald2023,Can ChatGPT draft a research article? An example of population-level vaccine effectiveness analysis,"We reflect on our experiences of using Generative Pre-trained Transformer ChatGPT, a chatbot launched by OpenAI in November 2022, to draft a research article. We aim to demonstrate how ChatGPT could help researchers to accelerate drafting their papers. We created a simulated data set of 100 000 health care workers with varying ages, Body Mass Index (BMI), and risk profiles. Simulation data allow analysts to test statistical analysis techniques, such as machine-learning based approaches, without compromising patient privacy. Infections were simulated with a randomized probability of hospitalisation. A subset of these fictitious people was vaccinated with a fictional vaccine that reduced this probability of hospitalisation after infection. We then used ChatGPT to help us decide how to handle the simulated data in order to determine vaccine effectiveness and draft a related research paper. AI-based language models in data analysis and scientific writing are an area of growing interest, and this exemplar analysis aims to contribute to the understanding of how ChatGPT can be used to facilitate these tasks © 2023 THE AUTHOR(S)","Macdonald, Calum and Adeloye, Davies and Sheikh, Aziz and Rudan, Igor",Journal of Global Health,,2023,10.7189/JOGH.13.01003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148258728&doi=10.7189%2fJOGH.13.01003&partnerID=40&md5=c23fae3c463e3087a61de2c24bde1f93,scopus.bib,2023-09-02 14:05:29,Unclassified
Zheng2022,UX Research on Conversational Human-AI Interaction: A Literature Review of the ACM Digital Library,"Early conversational agents (CAs) focused on dyadic human-AI interaction between humans and the CAs, followed by the increasing popularity of polyadic human-AI interaction, in which CAs are designed to mediate human-human interactions. CAs for polyadic interactions are unique because they encompass hybrid social interactions, i.e., human-CA, human-to-human, and human-to-group behaviors. However, research on polyadic CAs is scattered across different fields, making it challenging to identify, compare, and accumulate existing knowledge. To promote the future design of CA systems, we conducted a literature review of ACM publications and identified a set of works that conducted UX (user experience) research. We qualitatively synthesized the effects of polyadic CAs into four aspects of human-human interactions, i.e., communication, engagement, connection, and relationship maintenance. Through a mixed-method analysis of the selected polyadic and dyadic CA studies, we developed a suite of evaluation measurements on the effects. Our findings show that designing with social boundaries, such as privacy, disclosure, and identification, is crucial for ethical polyadic CAs. Future research should also advance usability testing methods and trust-building guidelines for conversational AI. © 2022 ACM.","Zheng, Qingxiao and Tang, Yiliu and Liu, Yiren and Liu, Weizi and Huang, Yun",Conference on Human Factors in Computing Systems - Proceedings,,2022,10.1145/3491102.3501855,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130572358&doi=10.1145%2f3491102.3501855&partnerID=40&md5=eb84b38295ceed7d799a491b95120418,scopus.bib,2023-09-02 14:05:29,Unclassified
Contu2021,AI-based analysis of policies and images for privacy-conscious content sharing,"Thanks to the popularity of personal mobile devices, more and more of the different types of private content, such as images and videos, are shared on social networking applications. While content sharing may be an effective practice to enhance social relationships, it is also a source of relevant privacy issues. Unfortunately, users find it difficult to understanding the terms and implications of the privacy policies of apps and services. Moreover, taking privacy decisions about content sharing on social networks is cumbersome and prone to errors that could determine privacy leaks. In this paper, we propose two techniques aimed at supporting the user in taking privacy choices about sharing personal content online. Our techniques are based on machine learning and natural language processing to analyze privacy policies, and on computer vision to assist the user in the privacy-conscious sharing of multimedia content. Experiments with real-world data show the potential of our solutions. We also present ongoing work on a system prototype and chatbot for natural language user assistance. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Contu, Francesco and Demontis, Andrea and Dessì, Stefano and Muscas, Marco and Riboni, Daniele",Future Internet,,2021,10.3390/fi13060139,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116072033&doi=10.3390%2ffi13060139&partnerID=40&md5=06e9aaa53bdcb0c5edb534c03cb114c2,scopus.bib,2023-09-02 14:05:29,Unclassified
Pedrosa2021391,Risk Assessment of Non-Compliance with General Data Protection Law (LGPD): A Necessary Adjustment for Healthcare Companies That Use Chatbots For Automated Care,"With the publication of the General Data Protection Law-(LGPD) many companies having their headquarters in Brazil need to work on adapting their processes. Most companies are seeking for compliance, however, many still do not know how to proceed. The risk of legal and financial issues related to non-compliance is high. This study reviews the current percentage of companies that use a Chatbot service and are compliant with the LGPD. It also reviews the steps to adjust the Chatbot service used by companies in the European Union to be compliant with the General Data Protection Regulation-(GDPR). As a methodological approach, a search in the state-of-the-art literature was conducted to identify the most recent published related content. A survey was conducted with several companies based in the Rio de Janeiro city which use a Chatbot service and are compliant with the LGPD. As a result, a flowchart showing the steps for adapting a Chatbot service to the LGPD is presented. The risks of non-compliance are also presented. This study addresses a gap observed in the literature since no specific previous work has been found covering this topic. Many companies may benefit from this study by knowing the steps to adapt their Chatbot service to the LGPD requirements, and avoid the risks associated to non-compliance. © ESREL 2021. Published by Research Publishing, Singapore.","Pedrosa, Antonio de Paula and Pereira, José Cristiano and Póvoas, Marcelo and Marinato, Davi da Fonseca Vieira Junior and Bastos, Matheus Bastos de Almeida and da Costa, Jose Luís Corrêa","Proceedings of the 31st European Safety and Reliability Conference, ESREL 2021",,2021,10.3850/978-981-18-2016-8_221-cd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135490917&doi=10.3850%2f978-981-18-2016-8_221-cd&partnerID=40&md5=ae977d496e9998d9241751a3bec23d81,scopus.bib,2023-09-02 14:05:29,Unclassified
Alt2021165,IDENTIFYING RELEVANT SEGMENTS OF POTENTIAL BANKING CHATBOT USERS BASED ON TECHNOLOGY ADOPTION BEHAVIOR; [IDENTIFICIRANJE RELEVANTNIH SEGMENATA POTENCIJALNIH KORISNIKA CHATBOTA U BANKARSTVU NA TEMELJU PONAŠANJA PRI PRIHVAĆANJU TEHNOLOGIJE],"Purpose – Chatbot technology is expected to revolution-ize customer service in financial institutions. However, the adoption of customer service chatbots in banking remains low. Therefore, the aim of this paper is to identify relevant segments of potential banking chatbot users based on technology adoption behavior. Design/Methodology/Approach – Data for the research was collected through an online questionnaire in Romania using the non-probability sampling method. The 287 questionnaires were analyzed using hierarchical and k-means cluster analysis. Findings and implications – The analysis revealed three distinct segments: Innovators (26%), consisting of highly educated young women employed in the business sec-tor; the Late Majority (55%), consisting of young women with higher education degrees who work in services-re-lated fields; and Laggards (19%), consisting of educated middle-aged men employed in the business sector. New significant differences among demographic and banking behavior variables were observed across the profiles of potential banking chatbot user segments. Limitations – The study is based on a non-probability sample collected from only one country, with a rather small sample size. Originality – Technology acceptance variables (perceived usefulness, perceived ease of use), expanded to include constructs such as awareness of service, perceived privacy risk, and perceived compatibility, were found to be appro-priate for customer segmentation purposes in the context of chatbot applications based on artificial intelligence. The study also revealed a new innovator demographic profile. © 2021, University of Zagreb, Faculty of Economics and Business Zagreb. All rights reserved.","Alt, Mónika-Anetta and Ibolya, Vizeli",Market-Trziste,,2021,10.22598/mt/2021.33.2.165,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123023220&doi=10.22598%2fmt%2f2021.33.2.165&partnerID=40&md5=da181df15bc8f67a24635f379453c7d9,scopus.bib,2023-09-02 14:05:29,Unclassified
Følstad20212915,Future directions for chatbot research: an interdisciplinary research agenda,"Chatbots are increasingly becoming important gateways to digital services and information—taken up within domains such as customer service, health, education, and work support. However, there is only limited knowledge concerning the impact of chatbots at the individual, group, and societal level. Furthermore, a number of challenges remain to be resolved before the potential of chatbots can be fully realized. In response, chatbots have emerged as a substantial research area in recent years. To help advance knowledge in this emerging research area, we propose a research agenda in the form of future directions and challenges to be addressed by chatbot research. This proposal consolidates years of discussions at the CONVERSATIONS workshop series on chatbot research. Following a deliberative research analysis process among the workshop participants, we explore future directions within six topics of interest: (a) users and implications, (b) user experience and design, (c) frameworks and platforms, (d) chatbots for collaboration, (e) democratizing chatbots, and (f) ethics and privacy. For each of these topics, we provide a brief overview of the state of the art, discuss key research challenges, and suggest promising directions for future research. The six topics are detailed with a 5-year perspective in mind and are to be considered items of an interdisciplinary research agenda produced collaboratively by avid researchers in the field. © 2021, The Author(s).","Følstad, Asbjørn and Araujo, Theo and Law, Effie Lai-Chong and Brandtzaeg, Petter Bae and Papadopoulos, Symeon and Reis, Lea and Baez, Marcos and Laban, Guy and McAllister, Patrick and Ischen, Carolin and Wald, Rebecca and Catania, Fabio and Meyer von Wolff, Raphael and Hobert, Sebastian and Luger, Ewa",Computing,,2021,10.1007/s00607-021-01016-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117326888&doi=10.1007%2fs00607-021-01016-7&partnerID=40&md5=ad4cf045204dac3a2701bf5e852b01be,scopus.bib,2023-09-02 14:05:29,Unclassified
Abdulquadri2021258,Digital transformation in financial services provision: a Nigerian perspective to the adoption of chatbot,"Purpose: Recognising the high numbers of unbanked and financially excluded adults in Nigeria, this study aims to position chatbot as a digital transformation tool to radically change business model, improve customer experience and enhance financial inclusion in emerging markets. Design/methodology/approach: The Search-Access-Test (S-A-T) model was adopted to understand how Nigerian banks are adopting chatbots. Findings: A majority of Nigerian banks now have chatbots that enhance customer engagement and financial inclusion. WhatsApp was the most frequently used platform. Chatbots were often branded and presented with female gender identification. The chatbots were less responsive beyond their predefined path. While Nigeria is a multilingual country with English being the original language, none of the chatbots used any of the Nigerian’s local languages. Practical implications: Brands need to re-evaluate their chatbots with regard to responsiveness, predefined questions, verification and privacy. There are also possibilities of branding the chatbot and developing content creation strategies for proper engagement. Beyond English, the integration of African languages into chatbot is essential for digital transformation. Digital literacy and skills, particularly in the field of science, technology, engineering and mathematics, should be supported to equip future developers and create more jobs. Originality/value: While many theoretically based models for investigating the adoption of digital technologies have often placed focus on users’ ability to engage, this study takes an alternative perspective; by using the S-A-T model, it lays the responsibilities on the banks and chatbot developer to ensure that their chatbots are secure, responsive and able to meet the needs of the customers. © 2021, Emerald Publishing Limited.","Abdulquadri, Abdulazeez and Mogaji, Emmanuel and Kieu, Tai Anh and Nguyen, Nguyen Phong",Journal of Enterprising Communities,,2021,10.1108/JEC-06-2020-0126,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101505207&doi=10.1108%2fJEC-06-2020-0126&partnerID=40&md5=016d3b8dd34e7ccbd5c814db173caf13,scopus.bib,2023-09-02 14:05:29,Unclassified
Morsi2023156,Artificial Intelligence in Electronic Commerce: Investigating the Customers' Acceptance of Using Chatbots,"Artificial intelligence (AI) has become an important tool for companies trying to gain a competitive edge in the online market. Business to Consumer (B2C) e-commerce firms are increasingly integrating chatbots as virtual shopping assistants for providing more personalized and efficient shopping experiences to online customers. Chatbots are AI-powered software programs that can communicate with users through text or voice interfaces. However, there is a lack of research on the acceptance of chatbots in B2C e-commerce in Egypt. Therefore, this research tries to fill the gap in e-commerce chatbot literature by investigating the acceptance of the use of chatbots in online shopping among Egyptian users by applying the Use and Gratification theory. This is an exploratory study using a quantitative survey-based approach for collecting data from online Egyptian customers on their attitudes or intentions to use Chatbots in online shopping. The data were analysed by using regression analysis for identifying factors that influence user acceptance and usage of chatbots. The results revealed that both of hedonic and technology factors have positive influence on users' behavioural intention. While the risk factor which has two sub-factors namely; privacy and immature technology has negative influence on customers' behavioural intentions. The study contributes to the expanding body of literature on the acceptance and use of Chatbots among customers in B2C e-commerce context. In addition, the study's findings give significant insights for Egyptian online retailers looking to implement Chatbots in their customer service strategy. © 2023, Success Culture Press. All rights reserved.","Morsi, Shereen",Journal of System and Management Sciences,,2023,10.33168/JSMS.2023.0311,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162777495&doi=10.33168%2fJSMS.2023.0311&partnerID=40&md5=dc55a2eed4f57fca6c72a3910b76d5c8,scopus.bib,2023-09-02 14:05:29,Unclassified
Väänänen2020143,CivicBots – Chatbots for Supporting Youth in Societal Participation,"Supporting young people to participate in societal development is an important factor in achieving sustainable future. Digital solutions can be designed to help youth participate in civic activities, such as city planning and legislation. To this end, we are using human-centered approach to study how digital tools can help youth discuss their ideas on various societal issues. Chatbots are conversational agents that have potential to trigger and support thought processes, as well as online activities. In this context, we are exploring how chatbots – which we call CivicBots – can be used to support youth (16–27 years) in societal participation. We created three scenarios for CivicBots and evaluated them with the youth in an online survey (N = 54). Positive perceptions of the youth concerning CivicBots suggest that CivicBots can advance equality and they may be able to reach youth better than a real person. On the negative side, CivicBots may cause unpleasant interactions by their over-proactive behaviour, and trustworthiness is affected by fears that the bot does not respect user’s privacy, or that it provides biased or limited information about societally important issues. © 2020, Springer Nature Switzerland AG.","Väänänen, Kaisa and Hiltunen, Aleksi and Varsaluoma, Jari and Pietilä, Iikka",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2020,10.1007/978-3-030-39540-7_10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079104131&doi=10.1007%2f978-3-030-39540-7_10&partnerID=40&md5=a770f9d26fa2addfbd3490441f0c2682,scopus.bib,2023-09-02 14:05:29,Unclassified
Sun2023,VCAs as partners or servants? The effects of information sensitivity and anthropomorphism roles on privacy concerns,"Advances in machine learning and natural language processing have driven the growing popularity of virtual conversational agents (VCAs). This anthropomorphic communication approach relies on user information sharing and real-time feedback from VCAs, and has raised privacy concerns while affecting various social interactions and relationships. Previous research on reducing user privacy concerns has mainly focused on user information mining, sensitive user information requests and privacy policies, while little is known about the anthropomorphic roles of partners and servants at the human-machine social hierarchy level. Therefore, this study, based on human-computer interaction (service) anthropomorphism at social level, develops a framework to investigate the impact of information sensitivity and VCAs' anthropomorphic roles, including partner and servant, on users' privacy concerns, as well as the mediating effects of competence- and integrity-based trust. The results show that when highly sensitive information is requested, user privacy concerns are greater for a partner VCA than a servant VCA, and vice-versa. Meanwhile, when a VCA requests highly sensitive information, integrity-based trust mediates the relationship between servant VCAs and privacy concerns, and when a VCA requests low-sensitivity information, competence-based trust mediates the same relationship. These insights provide actionable implications for managers. © 2023 Elsevier Inc.","Sun, Zhuo and Zang, Guoquan and Wang, ZongShui and Zhao, Hong and Liu, Wei",Technological Forecasting and Social Change,,2023,10.1016/j.techfore.2023.122560,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152229604&doi=10.1016%2fj.techfore.2023.122560&partnerID=40&md5=c63fd49e6c829e7d3387a2d514634c80,scopus.bib,2023-09-02 14:05:29,Unclassified
Følstad2020671,Communicating Service Offers in a Conversational User Interface: An Exploratory Study of User Preferences in Chatbot Interaction,"The increased interest in chatbots accentuates the importance of conversational design. A key conversational design challenge concerns how to communicate available service offers to users. We present an exploratory study, conducted in the context of financial service provision. Here, we first detailed four alternative approaches to communicate available service offers, reflecting different levels of proactivity. We then gathered feedback on user preference through interviews with 17 users following their interactions with prototypes representing the four approaches. Proactivity in the communication of service offers was found to be potentially valuable, provided that the offer is relevant to the conversation, do not compromise conversational efficiency, and is easy to discard. However, proactive communication of service offers may also entail challenges concerning perceptions of privacy and invasiveness, and, hence, needs to be designed with great care. Based on our findings, we summarize implications for theory and practice and propose directions for future research.  © 2020 Owner/Author.","Følstad, Asbjørn and Halvorsrud, Ragnhild",ACM International Conference Proceeding Series,,2020,10.1145/3441000.3441046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101734030&doi=10.1145%2f3441000.3441046&partnerID=40&md5=0aa3188c5e7fb2197ee6f07be5dde0c4,scopus.bib,2023-09-02 14:05:29,Unclassified
Adetayo2023,Revitalizing reference services and fostering information literacy: Google Bard’s dynamic role in contemporary libraries,"Purpose: This paper aims to explore the transformative potential of Google Bard, an artificial intelligence (AI)-powered chatbot, in reshaping contemporary library reference services and advancing information literacy. Design/methodology/approach: In this perspective piece, a qualitative research approach is used to explore the capabilities of Google Bard within library contexts. Real-world case studies and insights are used to critically examine Bard’s evolving role as a virtual assistant, its impact on enhancing information literacy and the multifaceted challenges it introduces, including biases and privacy concerns. Findings: The research reveals that Google Bard, leveraging natural language processing and machine learning, engages users in dynamic conversational interactions. It provides contextually relevant responses and personalized guidance, leading to an enriched library experience. The symbiotic relationship between AI-driven technology and traditional librarian expertise is highlighted, contributing to interactive knowledge exploration and collaborative learning. Originality/value: This study contributes to the literature by exploring the multifaceted impact of Google Bard on library services and information literacy. It uncovers novel insights into the integration of AI-powered chatbots in traditional library settings. © 2023, Emerald Publishing Limited.","Adetayo, Adebowale Jeremy and Oyeniyi, Wosilat Omolara",Library Hi Tech News,,2023,10.1108/LHTN-08-2023-0137,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168317354&doi=10.1108%2fLHTN-08-2023-0137&partnerID=40&md5=849b1b0d0b73a5e15d121b5f8d8708e8,scopus.bib,2023-09-02 14:05:29,Unclassified
Siemon2022,Requirements and Solution Approaches to Personality-Adaptive Conversational Agents in Mental Health Care,"Artificial intelligence (AI) technologies enable Conversational Agents (CAs) to perform highly complex tasks in a human-like manner and may help people cope with anxiety to improve their mental health and well-being. To support patients with their mental well-being in an authentic way, CAs need to be imbued with human-like behavior, such as personality. In this paper we cover an innovative form of CA, so-called Personality-Adaptive Conversational Agents (PACAs) that automatically infer users’ personality traits and adapt accordingly to their personality. We empirically investigate their benefits and caveats in mental health care. The results of our study show that PACAs can be beneficial for mental health support, but they also raise concerns about trust and privacy issues. We present a set of relevant requirements for designing PACAs and provide solution approaches that can be followed when designing and implementing PACAs for mental health care. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Siemon, Dominik and Ahmad, Rangina and Harms, Henrik and de Vreede, Triparna",Sustainability (Switzerland),,2022,10.3390/su14073832,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127554480&doi=10.3390%2fsu14073832&partnerID=40&md5=582917541399e326caf1a183aa6bbbb2,scopus.bib,2023-09-02 14:05:29,Unclassified
Fan2022967,How AI chatbots have reshaped the frontline interface in China: examining the role of sales–service ambidexterity and the personalization–privacy paradox,"Purpose: This study serves two purposes: (1) to evaluate the effects of organizational ambidexterity by examining how the balanced and the combined sales–service configurations of chatbots differ in their abilities to enhance customer experience and patronage and (2) to apply information boundary theory to assess the contingent role that chatbot sales–service ambidexterity can play in adapting to customers' personalization–privacy paradox. Design/methodology/approach: An online survey of artificial intelligence chatbots users was conducted, and a mixed-methods research design involving response surface analysis and polynomial regression was adopted to address the research aim. Findings: The results of polynomial regressions on survey data from 507 online customers indicated that as the benefits of personalization decreased and the risk to privacy increased, the inherently negative (positive) effects of imbalanced (combined) chatbots' sales–service ambidexterity had an increasing (decreasing) influence on customer experience. Furthermore, customer experience fully mediated the association of chatbots' sales–service ambidexterity with customer patronage. Originality/value: First, this study enriches the literature on frontline ambidexterity and extends it to the setting of human–machine interaction. Second, the study contributes to the literature on the personalization–privacy paradox by demonstrating the importance of frontline ambidexterity for adapting to customer concerns. Third, the study examines the conduit between artificial intelligence (AI) chatbots' ambidexterity and sales performance, thereby helping to reconcile the previously inconsistent evidence regarding this relationship. © 2022, Emerald Publishing Limited.","Fan, Hua and Han, Bing and Gao, Wei and Li, Wenqian",International Journal of Emerging Markets,,2022,10.1108/IJOEM-04-2021-0532,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122748717&doi=10.1108%2fIJOEM-04-2021-0532&partnerID=40&md5=f85c4217a247f7d015bb796bd7009586,scopus.bib,2023-09-02 14:05:29,Unclassified
Kronemann20232,"How AI encourages consumers to share their secrets? The role of anthropomorphism, personalisation, and privacy concerns and avenues for future research","Purpose: This paper aims to explore the overall research question “How can artificial intelligence (AI) influence consumer information disclosure?”. It considers how anthropomorphism of AI, personalisation and privacy concerns influence consumers’ attitudes and encourage disclosure of their private information. Design/methodology/approach: This research draws upon the personalisation-privacy paradox (PPP) and privacy calculus theory (PCT) to address the research question and examine how AI can influence consumer information disclosure. It is proposed that anthropomorphism of AI and personalisation positively influence consumer attitudes and intentions to disclose personal information to a digital assistant, while privacy concerns negatively affect attitude and information disclosure. Findings: This paper develops a conceptual model based on and presents seven research propositions (RPs) for future research. Originality/value: Building upon PPP and PCT, this paper presents a view on the benefits and drawbacks of AI from a consumer perspective. This paper contributes to literature by critically reflecting upon on the question how consumer information disclosure is influenced by AI. In addition, seven RPs and future research areas are outlined in relation to privacy and consumer information disclosure in relation to AI. © 2022, Bianca Kronemann, Hatice Kizgin, Nripendra Rana and Yogesh K. Dwivedi.","Kronemann, Bianca and Kizgin, Hatice and Rana, Nripendra and K. Dwivedi, Yogesh",Spanish Journal of Marketing - ESIC,,2023,10.1108/SJME-10-2022-0213,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146279636&doi=10.1108%2fSJME-10-2022-0213&partnerID=40&md5=87514f4c8e81c76e1b831a607d0ef16a,scopus.bib,2023-09-02 14:05:29,Unclassified
Wang2023339,Artificial intelligence changes the way we work: A close look at innovating with chatbots,"An enhanced understanding of the innovative use of artificial intelligence (AI) is essential for organizations to improve work design and daily business operations. This study's purpose is to offer insights into how AI can transform organizations' work practices through diving deeply into its innovative use in the context of a primary AI tool, a chatbot, and examining the antecedents of innovative use by conceptualizing employee trust as a multidimensional construct and exploring employees' perceived benefits. In particular, we have conceptualized employee trust in chatbots as a second-order construct, including three first-order variables: trust in functionality, trust in reliability, and trust in data protection. We collected data from 202 employees. The results supported our conceptualization of trust in chatbots and showed that three dimensions of first-order trust beliefs have relatively the same level of importance. Further, both knowledge support and work–life balance enhance trust in chatbots, which in turn leads to innovative use of chatbots. Our study contributes to the existing literature by introducing the new conceptualization of trust in chatbots and examining its antecedents and outcomes. The results can provide important practical insights regarding how to support innovative use of chatbots as the new way we organize work. © 2022 Association for Information Science and Technology.","Wang, Xuequn and Lin, Xiaolin and Shao, Bin",Journal of the Association for Information Science and Technology,,2023,10.1002/asi.24621,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123950868&doi=10.1002%2fasi.24621&partnerID=40&md5=a8a26a3a9d8e2353efd50bdb7b8c3d0b,scopus.bib,2023-09-02 14:05:29,Unclassified
Pizzi20231372,"I, chatbot! the impact of anthropomorphism and gaze direction on willingness to disclose personal information and behavioral intentions","The present research focuses on the interplay between two common features of the customer service chatbot experience: gaze direction and anthropomorphism. Although the dominant approach in marketing theory and practice is to make chatbots as human-like as possible, the current study, built on the humanness-value-loyalty model, addresses the chain of effects through which chatbots' nonverbal behaviors affect customers' willingness to disclose personal information and purchase intentions. By means of two experiments that adopt a real chatbot in a simulated shopping environment (i.e., car rental and travel insurance), the present work allows us to understand how to reduce individuals' tendency to see conversational agents as less knowledgeable and empathetic compared with humans. The results show that warmth perceptions are affected by gaze direction, whereas competence perceptions are affected by anthropomorphism. Warmth and competence perceptions are found to be key drivers of consumers’ skepticism toward the chatbot, which, in turn, affects consumers’ trust toward the service provider hosting the chatbot, ultimately leading consumers to be more willing to disclose their personal information and to repatronize the e-tailer in the future. Building on the Theory of Mind, our results show that perceiving competence from a chatbot makes individuals less skeptical as long as they feel they are good at detecting others’ ultimate intentions. © 2023 The Authors. Psychology & Marketing published by Wiley Periodicals LLC.","Pizzi, Gabriele and Vannucci, Virginia and Mazzoli, Valentina and Donvito, Raffaele",Psychology and Marketing,,2023,10.1002/mar.21813,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150974118&doi=10.1002%2fmar.21813&partnerID=40&md5=7586c860885fd96262417ee9e6157c20,scopus.bib,2023-09-02 14:05:29,Unclassified
Meskó2023,The imperative for regulatory oversight of large language models (or generative AI) in healthcare,"The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality. © 2023, The Author(s).","Meskó, Bertalan and Topol, Eric J.",npj Digital Medicine,,2023,10.1038/s41746-023-00873-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164295991&doi=10.1038%2fs41746-023-00873-0&partnerID=40&md5=657da2c6a8b235b18551d0094cd60b67,scopus.bib,2023-09-02 14:05:29,Unclassified
Bahja202020,An Antenatal Care Awareness Prototype Chatbot Application Using a User-Centric Design Approach,"The frequency of occurrence of severe infectious diseases, such as SARS-CoV, MERS-CoV, Ebola and COVID-19, has been increasing in recent years, thus putting pressure on the delivery of healthcare services. Pregnant women are some of the most vulnerable patients, as they are more prone to infections and have limited mobility due to their health situation. In addition, preventive measures, such as social distancing and lockdowns have affected their access to healthcare services. Considering these issues, in this study, a prototype chatbot application that can provide antenatal care and support for pregnant women from the comfort of their home is proposed. A user-centric design methodology was adopted, where two midwives, one obstetrician and eleven pregnant women participated in the design and development process by providing regular reviews at various stages of the process. In addition, an online User Experience Questionnaire was employed for collecting the users’ experiences after engaging with the protype application for two weeks. The findings reveal that the proposed chatbot application (Alia) is effective in terms of attractiveness, perspicuity, efficiency, stimulation, and novelty. In addition, concerns related to dependability (privacy and security) and supportability were identified. Finally, UEQ scales of pragmatic quality (1.12) and hedonic quality (1.11) related to the chatbot application Alia, reflected good usability, reliability and quality aspects. © 2020, Springer Nature Switzerland AG.","Bahja, Mohammed and Abuhwaila, Nour and Bahja, Julia",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2020,10.1007/978-3-030-60117-1_2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094113713&doi=10.1007%2f978-3-030-60117-1_2&partnerID=40&md5=1593f2dc3e36fb4c2ea7b1167c339c38,scopus.bib,2023-09-02 14:05:29,Unclassified
Feng2019169,"BotFlowMon: Learning-based, Content-Agnostic Identification of Social Bot Traffic Flows","With the fast-growing popularity of online social networks (OSN), maintaining the security of OSN ecosystems becomes essential for the public. Among all the security threats facing OSN, malicious social bots have become the most common and detrimental. These bot programs are often employed to violate users' privacy, distribute spam, and disturb the financial market, posing a compelling need for effective social bot detection solutions. Unlike traditional bot detection approaches that have strict requirements on data sources (e.g., private payload information, social relationships, or activity histories), this paper proposes a detection method called BotFlowMon that relies only on NetFlow data as input to identify OSN bot traffic, where every NetFlow record is a summary of a traffic flow on the Internet and contains no payload content. BotFlowMon introduces several new algorithms and techniques to help use machine learning to classify the social bot traffic from the real OSN user traffic, including aggregating NetFlow records to obtain transaction data, fusing transaction data to extract features and visualize flows, as well as subdividing transactions into basic actions. Our evaluation shows that with 535GB raw NetFlow records as input, BotFlowMon can efficiently classify the traffic from social bots, including chatbot, amplification bot, post bot, crawler bot, and hybrid bot, with 92.33-93.61 % accuracy. © 2019 IEEE.","Feng, Yebo and Li, Jun and Jiao, Lei and Wu, Xintao","2019 IEEE Conference on Communications and Network Security, CNS 2019",,2019,10.1109/CNS.2019.8802706,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071724650&doi=10.1109%2fCNS.2019.8802706&partnerID=40&md5=f66cd67c59326a6969799a521972cbdd,scopus.bib,2023-09-02 14:05:29,Unclassified
Limna202364,The use of ChatGPT in the digital era: Perspectives on chatbot implementation,"The rapid advancement of technology has led to the integration of ChatGPT, an artificial intelligence (AI)-powered chatbot, in various sectors, including education. This research aims to explore the perceptions of educators and students on the use of ChatGPT in education during the digital era. This study adopted a qualitative research approach, using in-depth interviews to gather data. A purposive sampling technique was used to select ten educators and 15 students from different academic institutions in Krabi, Thailand. The data collected was analysed using content analysis and NVivo. The findings revealed that educators and students generally have a positive perception of using ChatGPT in education. The chatbot was perceived to be a helpful tool for providing immediate feedback, answering questions, and providing support to students. Educators noted that ChatGPT could reduce their workload by answering routine questions and enabling them to focus on higher-order tasks. However, the findings also showed some concerns regarding the use of ChatGPT in education. Participants were worried about the accuracy of information provided by the chatbot and the potential loss of personal interaction with teachers. The need for privacy and data security was also raised as a significant concern. The results of this study could help educators and policymakers make informed decisions about using ChatGPT in education. © 2023. Pongsakorn Limna, Tanpat Kraiwanit, Kris Jangjarat, Prapasiri Klayklung and Piyawatjana Chocksathaporn.","Limna, Pongsakorn and Kraiwanit, Tanpat and Jangjarat, Kris and Klayklung, Prapasiri and Chocksathaporn, Piyawatjana",Journal of Applied Learning and Teaching,,2023,10.37074/jalt.2023.6.1.32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162975175&doi=10.37074%2fjalt.2023.6.1.32&partnerID=40&md5=f66ca072652a80d33decf88547c88ffc,scopus.bib,2023-09-02 14:05:29,Unclassified
AlGosaibi2020260,Developing an intelligent framework for improving the quality of service in the government organizations in the Kingdom of Saudi Arabia,"—The Kingdom of Saudi Arabia is enhancing the services and applications in government organizations through the number of systems that generate a massive amount of data through Big Data technology. Recently, the Global Artificial Intelligent Summit 2020, Saudi Data and Artificial Intelligence Authority (SDAIA), NEOM have launched an Artificial Intelligence (AI) strategy that aligns with the Kingdom Vision 2030. AI opens a wide door for opportunities and new strategies that will narrow the gap in the skillset of individuals and promote research and innovation in the IT industry. Organizations lack advanced techniques to evaluate the performance of individuals and departments that supports improving the quality of service. The introduction of AI-based applications in the government and private sectors will facilitate decision-makers in tracking and optimizing the efficiency of departments and individuals. This research aims to develop an intelligent framework for government organizations to improve the quality of services rendered to customers and businesses. In addition, it highlights the importance of AI policies in archiving metadata. This paper presents a framework for an organization that contains Chatbot, Sentiment Analysis, and Key Performance Indicators to improve the services. A synthetic dataset is employed as a testbed to evaluate the performance of the framework. The outcome of this study shows that the proposed framework able to improve the performance of organizations. Using this proposed framework, organizations can build a mechanism for their workforce to retrieve meaningful information. Moreover, it provides significant features include efficient data extraction, data management, and AI-based security for effective document management. © 2020 Science and Information Organization. All rights reserved.","AlGosaibi, Abdulelah Abdallah and Sait, Abdul Rahaman Wahab and AlOthman, Abdulaziz Fahad and AlHamed, Shadan",International Journal of Advanced Computer Science and Applications,,2020,10.14569/IJACSA.2020.0111233,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101461712&doi=10.14569%2fIJACSA.2020.0111233&partnerID=40&md5=09f20888f6e6b5720dd3b91bef263b5c,scopus.bib,2023-09-02 14:05:29,Unclassified
Sanabria2023,“A Great Way to Start the Conversation”: Evidence for the Use of an Adolescent Mental Health Chatbot Navigator for Youth at Risk of HIV and Other STIs,"Chatbot use is increasing for mobile health interventions on sensitive and stigmatized topics like mental health because of their anonymity and privacy. This anonymity provides acceptability to sexual and gendered minority youth (ages 16–24) at increased risk of HIV and other STIs with poor mental health due to higher levels of stigma, discrimination, and social isolation. This study evaluates the usability of Tabatha-YYC, a pilot chatbot navigator created to link these youth to mental health resources. Tabatha-YYC was developed using a Youth Advisory Board (n = 7). The final design underwent user testing (n = 20) through a think-aloud protocol, semi-structured interview, and a brief survey post-exposure which included the Health Information Technology Usability Evaluation Scale. The chatbot was found to be an acceptable mental health navigator by participants. This study provides important design methodology considerations and key insights into chatbot design preferences of youth at risk of STIs seeking mental health resources. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.","Sanabria, Gabriella and Greene, Karah Y. and Tran, Jennifer T. and Gilyard, Shelton and DiGiovanni, Lauren and Emmanuel, Patricia J. and Sanders, Lisa J. and Kosyluk, Kristin and Galea, Jerome T.",Journal of Technology in Behavioral Science,,2023,10.1007/s41347-023-00315-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159115973&doi=10.1007%2fs41347-023-00315-4&partnerID=40&md5=caecf3131f5f4bd49caa6a995119866f,scopus.bib,2023-09-02 14:05:29,Unclassified
Milton2018,Smart IoT and soft AI,"Soft artificial intelligence (AI) is defined as non-sentient AI designed to perform close to human level in one specific domain. This is in contrast to “Artificial General Intelligence” (AGI) which solves the problem for human level intelligence across all domains. Soft AI is a reality now in the new generation of smart Internet of Things devices like Amazon’s Alexa, Apple’s Siri or Microsoft’s Cortana, giving rise to concerns about privacy and how the technology is being used. This research is based around an experiment in “AI as a service” where fifteen chatbot agents using Google’s “Dialogflow” are deployed around the Queen Elizabeth Olympic Park in London for the general public to interact with. The physical devices are 3D printed representations of creatures living in the park, designed to fit with the park’s biodiversity remit. Park visitors interact with the creatures via their mobile phones, engaging in a conversation where the creature offers to tell them a memory in exchange for one of their own, while warning them that anything they say might be repeated to others. The scope of the work presented here is as follows. After explaining the details of the deployment and three month study, the conversational data collected from visitors is then anal-ysed. Following a review of the current literature, techniques for working with the unstructured natural language data are developed, leading to recommendations for the design of future conversational “chatbot” agents. The results show distinct patterns of conversation, from simple and direct “verb plus noun” commands to complex sentence structure. How users interact with the agents, given that they are conversing with a mechanism, is discussed and contrasted with the memories that they have agreed to share. The conclusion drawn from this work is that, while the current generation of devices only listen for commands from users, there is a danger that smart IoT devices in the future can be used as active information probes unless properly understood and regulated. We finish with observations on privacy and security based on our experiences here. © 2018 Institution of Engineering and Technology. All rights reserved.","Milton, R. and Hay, D. and Gray, S. and Buyuklieva, B. and Hudson-Smith, A.",IET Conference Publications,,2018,10.1049/cp.2018.0016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048431023&doi=10.1049%2fcp.2018.0016&partnerID=40&md5=9e7f3fd61a6baa88c462d800a1e2182b,scopus.bib,2023-09-02 14:05:29,Unclassified
Thomaz202043,Learning from the Dark Web: leveraging conversational agents in the era of hyper-privacy to enhance marketing,"The Web is a constantly evolving, complex system, with important implications for both marketers and consumers. In this paper, we contend that over the next five to ten years society will see a shift in the nature of the Web, as consumers, firms and regulators become increasingly concerned about privacy. In particular, we predict that, as a result of this privacy-focus, various information sharing and protection practices currently found on the Dark Web will be increasingly adapted in the overall Web, and in the process, firms will lose much of their ability to fuel a modern marketing machinery that relies on abundant, rich, and timely consumer data. In this type of controlled information-sharing environment, we foresee the emersion of two distinct types of consumers: (1) those generally willing to share their information with marketers (Buffs), and (2) those who generally deny access to their personal information (Ghosts). We argue that one way marketers can navigate this new environment is by effectively designing and deploying conversational agents (CAs), often referred to as “chatbots.” In particular, we propose that CAs may be used to understand and engage both types of consumers, while providing personalization, and serving both as a form of differentiation and as an important strategic asset for the firm—one capable of eliciting self-disclosure of otherwise private consumer information. © 2019, The Author(s).","Thomaz, Felipe and Salge, Carolina and Karahanna, Elena and Hulland, John",Journal of the Academy of Marketing Science,,2020,10.1007/s11747-019-00704-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075185738&doi=10.1007%2fs11747-019-00704-3&partnerID=40&md5=4e93fed65a8f584a08f0ed5fdb7198ab,scopus.bib,2023-09-02 14:05:29,Unclassified
Moore2022,Designing Virtual Reality-Based Conversational Agents to Train Clinicians in Verbal De-escalation Skills: Exploratory Usability Study,"Background: Violence and aggression are significant workplace challenges faced by clinicians worldwide. Traditional methods of training consist of “on-the-job learning” and role-play simulations. Although both approaches can result in improved skill levels, they are not without limitation. Interactive simulations using virtual reality (VR) can complement traditional training processes as a cost-effective, engaging, easily accessible, and flexible training tool. Objective: In this exploratory study, we aimed to determine the feasibility of and barriers to verbal engagement with a virtual agent in the context of the Code Black VR application. Code Black VR is a new interactive VR-based verbal de-escalation trainer that we developed based on the Clinical Training Through VR Design Framework. Methods: In total, 28 participants with varying clinical expertise from 4 local hospitals enrolled in the Western Sydney Local Health District Clinical Initiative Nurse program and Transition to Emergency Nursing Programs and participated in 1 of 5 workshops. They completed multiple playthroughs of the Code Black VR verbal de-escalation trainer application and verbally interacted with a virtual agent. We documented observations and poststudy reflection notes. After the playthroughs, the users completed the System Usability Scale and provided written comments on their experience. A thematic analysis was conducted on the results. Data were also obtained through the application itself, which also recorded the total interactions and successfully completed interactions. Results: The Code Black VR verbal de-escalation training application was well received. The findings reinforced the factors in the existing design framework and identified 3 new factors-motion sickness, perceived value, and privacy-to be considered for future application development. Conclusions: Verbal interaction with a virtual agent is feasible for training staff in verbal de-escalation skills. It is an effective medium to supplement clinician training in verbal de-escalation skills. We provide broader design considerations to guide further developments in this area. © Nathan Moore, Naseem Ahmadpour, Martin Brown, Philip Poronnik, Jennifer Davids. Originally published in JMIR Serious Games (https://games.jmir.org), 06.07.2022.","Moore, Nathan and Ahmadpour, Naseem and Brown, Martin and Poronnik, Philip and Davids, Jennifer",JMIR Serious Games,,2022,10.2196/38669,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134403821&doi=10.2196%2f38669&partnerID=40&md5=966aaef5bd2482e1ee9c39e11e1f1197,scopus.bib,2023-09-02 14:05:29,Unclassified
Williams2020314,From WOM to aWOM – the evolution of unpaid influence: a perspective article,"Purpose: Advances in artificial intelligence (AI) natural language processing may see the emergence of algorithmic word of mouth (aWOM), content created and shared by automated tools. As AI tools improve, aWOM will increase in volume and sophistication, displacing eWOM as an influence on customer decision-making. The purpose of this paper is to provide an overview of the socio technological trends that have encouraged the evolution of informal infulence strategies from WOM to aWOM. Design/methodology/approach: This paper examines the origins and path of development of influential customer communications from word of mouth (WOM) to electronic word of mouth (eWOM) and the emerging trend of aWOM. The growth of aWOM is theorized as a result of new developments in AI natural language processing tools along with autonomous distribution systems in the form of software robots and virtual assistants. Findings: aWOM may become a dominant source of information for tourists, as it can support multimodal delivery of useful contextual information. Individuals, organizations and social media platforms will have to ensure that aWOM is developed and deployed responsibly and ethically. Practical implications: aWOM may emerge as the dominant source of information for tourist decision-making, displacing WOM or eWOM. aWOM may also impact online opinion leaders, as they may be challenged by algorithmically generated content. aWOM tools may also generate content using sensors on personal devices, creating privacy and information security concerns if users did not give permission for such activities. Originality/value: This paper is the first to theorize the emergence of aWOM as autonomous AI communication within the framework of unpaid influence or WOM. As customer engagement will increasingly occur in algorithmic environments that comprise person–machine interactions, aWOM will influence future tourism research and practice. © 2019, Emerald Publishing Limited.","Williams, Nigel L. and Ferdinand, Nicole and Bustard, John",Tourism Review,,2020,10.1108/TR-05-2019-0171,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074495423&doi=10.1108%2fTR-05-2019-0171&partnerID=40&md5=606663eb06e78d0c6a4e8f253259ed32,scopus.bib,2023-09-02 14:05:29,Unclassified
Laban2020,The Effect of Personalization Techniques in Users' Perceptions of Conversational Recommender Systems,"Conversational recommender systems provide users with individually tailored recommendations in a flowing dialogue. These require users to disclose information proactively or reactively for receiving personalized recommendations, which can trigger users' resistance to the platform and to the recommendations. Accordingly, this study examined the extent to which user-initiated and system-initiated recommendations provided by a conversational recommender system influenced users' perceptions of it. The results of an online experiment entail that when recommendations are system-initiated, as compared to user-initiated, users perceive to be in less control and perceive the system as riskier. Furthermore, the results stress that systems that provide user-initiated or system-initiated recommendations do not differ in users' perceptions of anthropomorphism. © 2020 Owner/Author.","Laban, Guy and Araujo, Theo","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020",,2020,10.1145/3383652.3423890,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096954637&doi=10.1145%2f3383652.3423890&partnerID=40&md5=0e018747c6b5ebfecc7db0201a7ac0dc,scopus.bib,2023-09-02 14:05:29,Unclassified
Rastogi2022311,Eunoia: A Website for Self-CBT and Psychotherapy,"Cognitive behaviour therapy (CBT) is an effective treatment strategy for a variety of mental and emotional health disorders, such as anxiety and depression. CBT aims to assist you in recognising and challenging harmful ideas as well as learning practical self-help techniques. Internet technology is a viable addition to traditional therapy delivery because of its high penetration, capacity to gather and analyse data, and ability to engage with people. With the various CBT apps and websites, it is discovered that most of them required membership or hiring a therapist online in order to use CBT. They had resources added to them, but most of them lacked an appropriate structure or methodology. The objective of this paper is to achieve privacy, accessibility, and time-saving. In this paper, the online support for the delivery of Self-CBT is provided by a website called “Eunoia,” which gives numerous questionnaires to help patients identify difficult events or conditions in their lives, as well as worksheets and other resources such as chatbot for the patient’s therapy. This website focuses on interpersonal issues, emotional dysregulation, relationship issues, and workplace issues, and it can help in figuring out where the negative thoughts come from and how to utilise the worksheets as homework to work on emotions and thoughts. The questionnaire findings are calculated quite precisely. There is no correct answer in these questionnaires, thus the answer choice involves different points. Users of this Self-CBT website can complete their homework without the burden of lugging papers and worksheets around with them. Eunoia, the Self-CBT website, has yielded unexpected outcomes. Participants in this study went through stage 1 of Self-CBT, where they are required to complete questionnaires that assisted them in recognising their negative thoughts. They are quite pleased with the outcome. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Rastogi, Dhruv and Thakur, Shubhangi and Singh, Leena",Lecture Notes in Electrical Engineering,,2022,10.1007/978-981-19-4364-5_24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144560520&doi=10.1007%2f978-981-19-4364-5_24&partnerID=40&md5=f695972849919f4c931812359cd88ba4,scopus.bib,2023-09-02 14:05:29,Unclassified
Xu2022,A tool or a social being? A dynamic longitudinal investigation of functional use and relational use of AI voice assistants,"This study integrates two lines of research: technologies as tools and technologies as social beings, under the theoretical framework of dynamic systems, to investigate the reciprocal dynamics between functional use and relational use of artificial intelligence (AI) voice assistants, and the mediating roles of self-disclosure and privacy concerns. A two-wave longitudinal survey was conducted among 354 AI voice assistant users across 2 months. Factor analysis results supported the conceptualization and operationalization of functional use and relational use of voice assistants. Results from the cross-lagged panel model confirmed that functional use and relational use reinforced themselves over time, respectively. Relational use increased subsequent functional use, and relational use reinforced itself through self-disclosure. Surprisingly, functional use did not increase subsequent relational use; instead, longitudinal mediation analysis showed that functional use reduced subsequent relational use due to the lack of self-disclosure. Furthermore, while self-disclosure increased subsequent privacy concerns, privacy concerns did not reduce subsequent self-disclosure. © The Author(s) 2022.","Xu, Shan and Li, Wenbo",New Media and Society,,2022,10.1177/14614448221108112,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134288653&doi=10.1177%2f14614448221108112&partnerID=40&md5=fc64551b8d2cc48489b2e70c009f07f9,scopus.bib,2023-09-02 14:05:29,Unclassified
Ngo2014222,Improving simulation of continuous emotional facial expressions by analyzing videos of human facial activities,"Conversational agents are receiving significant attention from multiagent and human computer interaction research societies. In order to make conversational agents more believable and friendly, giving them the ability to express emotions is one of research fields which have drawn a lot of attention lately. In this paper, we propose a work on analysis of how emotional facial activities happen temporally. Our goal is to find the temporal patterns of facial activity of six basic emotions in order to improve the simulation of continuous emotional facial expressions on a 3D face of an embodied agent. Using facial expression recognition techniques, we first analyze a spontaneous video database in order to consider how facial activities are related to six basic emotions temporally. From there, we bring out the general temporal patterns for facial expressions of the six basic emotions. Then, based on the temporal patterns, we propose a scheme for displaying continuous emotional states of a conversational agent on a 3D face. © Springer International Publishing Switzerland 2014.","Ngo, Thi Duyen and Vu, Thi Hong Nhan and Nguyen, Viet Ha and Bui, The Duy",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2014,10.1007/978-3-319-13191-7_18,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910138259&doi=10.1007%2f978-3-319-13191-7_18&partnerID=40&md5=7eaaad2b759f5f4e2adc7e44cc454b5e,scopus.bib,2023-09-02 14:05:29,Unclassified
Liu2023,Can chatbots satisfy me? A mixed-method comparative study of satisfaction with task-oriented chatbots in mainland China and Hong Kong,"Task-oriented chatbots are gradually being used across the globe. Most notably, while chatbots have for a long time penetrated users’ daily lives in mainland China, Hong Kong is still struggling to improve and promote its chatbot services. To determine whether antecedents of satisfaction and usage intention differ based on different stages of chatbot adoption and development, we conduct a comparative study based on a research model that integrates the Delone and McLean Information System success model and privacy concerns. The model is developed and examined using a mixed-method approach. After conducting focus group interviews (N = 15) in both regions, online surveys were conducted in mainland China (N = 637) and Hong Kong (N = 647), respectively. Based on qualitative exploration, we identified critical factors of perceived quality and privacy concerns. The quantitative findings further illuminate the different roles of the antecedents in the two regions. The results show that usage intention can be positively influenced by satisfaction, and satisfaction can be increased by relevance, completeness, pleasure and assurance in both regions. However, response time and empathy are factors influencing satisfaction only in mainland China. Privacy concerns cannot influence satisfaction in both regions. © 2023 Elsevier Ltd","Liu, Yu-li and Hu, Bo and Yan, Wenjia and Lin, Zhi",Computers in Human Behavior,,2023,10.1016/j.chb.2023.107716,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150767976&doi=10.1016%2fj.chb.2023.107716&partnerID=40&md5=c9cf512ad105a11edcd8d2426371daf6,scopus.bib,2023-09-02 14:05:29,Unclassified
Sayegh-Jodehl2022,Use of Instant Messaging Software in a German Hospital—An Exploratory Investigation among Physicians,"Internationally, evidence exists that physicians use instant messaging services for communication tasks in everyday clinical practice However, there are only few data on physicians in Germany in this regard. Therefore, at the initiation of our project “DocTalk-Dialog meets Chatbot: Collaborative Learning and Teaching in the Process of Work”, we conducted a stakeholder survey with an exploratory research approach. The aim was to gain initial insights into use of instant messaging software and attitudes towards data security and advantages and disadvantages before implementing a data-secure in-house messaging platform. N = 70 physicians at Charité-Universitätsmedizin Berlin completed an exploratory questionnaire with closed and open-ended questions. Quantitative data were analyzed using descriptive statistics and qualitative data using thematic analysis. The use of messenger software was not widespread in the sample studied. Physicians most frequently used face-to-face contact for communication. On average, up to ten instant messages were exchanged per day, mainly among colleagues, to answer mutual questions, and to send pictures. With a high awareness of privacy-related restrictions among participating physicians, advantages such as fast and uncomplicated communication were also highlighted. An instant messenger solution that complies with the German data protection guidelines is needed and should be investigated in more detail. © 2022 by the authors.","Sayegh-Jodehl, Sabine and Mukowski-Kickhöfel, Rebecca and Linke, Diane and Müller-Birn, Claudia and Rose, Matthias",International Journal of Environmental Research and Public Health,,2022,10.3390/ijerph191912618,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139976639&doi=10.3390%2fijerph191912618&partnerID=40&md5=4a32a9efe61fc4cad500dd629c94a065,scopus.bib,2023-09-02 14:05:29,Unclassified
Kopplin2022232,CHATBOTS IN THE WORKPLACE: A TECHNOLOGY ACCEPTANCE STUDY APPLYING USES AND GRATIFICATIONS IN COWORKING SPACES,"The uses and gratifications approach is used to examine chatbot acceptance in coworking spaces, identifying how coworkers perceive the technology and may use it to facilitate their tasks. To do so, potential influence factors shaping technology acceptance are explored, and a sample of 101 German coworkers is employed to confirm the framework drawing on a quantitative combination of partial least squares structural equation modeling and necessary condition analysis. Instrumental and non-instrumental gratifications, as well as social norm, influence chatbot acceptance in the form of sufficient and necessary conditions, and social norm appears to have a more substantial impact than hedonic factors in terms of sufficiency. However, social norm is not a necessary condition. A moderator analysis reveals that privacy concerns, age and gender do not affect individuals’ intention to use a chatbot. Coworking space providers thus benefit from establishing a standard chatbot solution to leverage social norm, and the chosen solution needs to fulfill hedonic expectations in addition to being useful. Software vendors may also integrate dedicated interfaces to powerful solutions such as ChatGPT. © 2023 Taylor & Francis Group, LLC.","Kopplin, Cristopher Siegfried",Journal of Organizational Computing and Electronic Commerce,,2022,10.1080/10919392.2023.2215666,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161562343&doi=10.1080%2f10919392.2023.2215666&partnerID=40&md5=9f04f1cd8875cb1c38046c238b69bc51,scopus.bib,2023-09-02 14:05:29,Unclassified
Li2023e44479,"The Influence of Anthropomorphic Cues on Patients' Perceived Anthropomorphism, Social Presence, Trust Building, and Acceptance of Health Care Conversational Agents: Within-Subject Web-Based Experiment","BACKGROUND: The last decade has witnessed the rapid development of health care conversational agents (CAs); however, there are still great challenges in making health care CAs trustworthy and acceptable to patients. OBJECTIVE: Focusing on intelligent guidance CAs, a type of health care CA for web-based patient triage, this study aims to investigate how anthropomorphic cues influence patients' perceived anthropomorphism and social presence of such CAs and evaluate how these perceptions facilitate their trust-building process and acceptance behavior. METHODS: To test the research hypotheses, the video vignette methodology was used to evaluate patients' perceptions and acceptance of various intelligent guidance CAs. The anthropomorphic cues of CAs were manipulated in a 3×2 within-subject factorial experiment with 103 participants, with the factors of agent appearance (high, medium, and low anthropomorphic levels) and verbal cues (humanlike and machine-like verbal cues) as the within-subject variables. RESULTS: The 2-way repeated measures ANOVA analysis indicated that the higher anthropomorphic level of agent appearance significantly increased mindful anthropomorphism (high level>medium level: 4.57 vs 4.27; P=.01; high level>low level: 4.57 vs 4.04; P<.001; medium level>low level: 4.27 vs 4.04; P=.04), mindless anthropomorphism (high level>medium level: 5.39 vs 5.01; P<.001; high level>low level: 5.39 vs 4.85; P<.001), and social presence (high level>medium level: 5.19 vs 4.83; P<.001; high level>low level: 5.19 vs 4.72; P<.001), and the higher anthropomorphic level of verbal cues significantly increased mindful anthropomorphism (4.83 vs 3.76; P<.001), mindless anthropomorphism (5.60 vs 4.57; P<.001), and social presence (5.41 vs 4.41; P<.001). Meanwhile, a significant interaction between agent appearance and verbal cues (.004) was revealed. Second, the partial least squares results indicated that privacy concerns were negatively influenced by social presence (β=-.375; t312=4.494) and mindful anthropomorphism (β=-.112; t312=1.970). Privacy concerns (β=-.273; t312=9.558), social presence (β=.265; t312=4.314), and mindless anthropomorphism (β=.405; t312=7.145) predicted the trust in CAs, which further promoted the intention to disclose information (β=.675; t312=21.163), the intention to continuously use CAs (β=.190; t312=4.874), and satisfaction (β=.818; t312=46.783). CONCLUSIONS: The findings show that a high anthropomorphic level of agent appearance and verbal cues could improve the perceptions of mindful anthropomorphism and mindless anthropomorphism as well as social presence. Furthermore, mindless anthropomorphism and social presence significantly promoted patients' trust in CAs, and mindful anthropomorphism and social presence decreased privacy concerns. It is also worth noting that trust was an important antecedent and determinant of patients' acceptance of CAs, including their satisfaction, intention to disclose information, and intention to continuously use CAs. ©Qingchuan Li, Yan Luximon, Jiaxin Zhang. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 10.08.2023.","Li, Qingchuan and Luximon, Yan and Zhang, Jiaxin",Journal of medical Internet research,,2023,10.2196/44479,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167532440&doi=10.2196%2f44479&partnerID=40&md5=4a322c9dafd65a54dee3814ad16b43d8,scopus.bib,2023-09-02 14:05:29,Unclassified
Luria2020,Social Boundaries for Personal Agents in the Interpersonal Space of the Home,"The presence of voice activated personal assistants (VAPAs) in people's homes rises each year [31]. Industry efforts are invested in making interactions with VAPAs more personal by leveraging information from messages and calendars, and by accessing user accounts for 3rd party services. However, the use of personal data becomes more complicated in interpersonal spaces, such as people's homes. Should a shared agent access the information of many users? If it does, how should it navigate issues of privacy and control? Designers currently lack guidelines to help them design appropriate agent behaviors. We used Speed Dating to explore inchoate social mores around agent actions within a home, including issues of proactivity, interpersonal conflict, and agent prevarication. Findings offer new insights on how more socially sophisticated agents might sense, make judgements about, and navigate social roles and individuals. We discuss how our findings might impact future research and future agent behaviors. © 2020 Owner/Author.","Luria, Michal and Zheng, Rebecca and Huffman, Bennett and Huang, Shuangni and Zimmerman, John and Forlizzi, Jodi",Conference on Human Factors in Computing Systems - Proceedings,,2020,10.1145/3313831.3376311,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090149393&doi=10.1145%2f3313831.3376311&partnerID=40&md5=1242778052df38657f5c08e3145f042b,scopus.bib,2023-09-02 14:05:29,Unclassified
Sannon2020,“I just shared your responses”: Extending communication privacy management theory to interactions with conversational agents,"Conversational agents are increasingly becoming integrated into everyday technologies and can collect large amounts of data about users. As these agents mimic interpersonal interactions, we draw on communication privacy management theory to explore people's privacy expectations with conversational agents. We conducted a 3x3 factorial experiment in which we manipulated agents' social interactivity and data sharing practices to understand how these factors influence people's judgments about potential privacy violations and their evaluations of agents. Participants perceived agents that shared response data with advertisers more negatively compared to agents that shared such data with only their companies; perceptions of privacy violations did not differ between agents that shared data with their companies and agents that did not share information at all. Participants also perceived the socially interactive agent's sharing practices less negatively than those of the other agents, highlighting a potential privacy vulnerability that users are exposed to in interactions with socially interactive conversational agents. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Sannon, Shruti and Stoll, Brett and Difranzo, Dominic and Jung, Malte F. and Bazarova, Natalya N.",Proceedings of the ACM on Human-Computer Interaction,,2020,10.1145/3375188,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077779524&doi=10.1145%2f3375188&partnerID=40&md5=d2fb1e1b5b052270bcdb66dd4fb50664,scopus.bib,2023-09-02 14:05:29,Unclassified
Aslam2022,Chatbots in the frontline: drivers of acceptance,"Purpose: By extending the service robot acceptance model (sRAM), this study aims to explore and enhance the acceptance of chatbots. The study considered functional, relational, social, user and gratification elements in determining the acceptance of chatbots. Design/methodology/approach: By using the purposive sampling technique, data of 321 service customers, gathered from millennials through a questionnaire and subsequent PLS-SEM modeling, was applied for hypotheses testing. Findings: Findings revealed that the functional elements, perceived usefulness and perceived ease of use affect acceptance of chatbots. However, in social elements, only perceived social interactivity affects the acceptance of chatbots. Moreover, both user and gratification elements (hedonic motivation and symbolic motivation) significantly influence the acceptance of chatbots. Lastly, trust is the only contributing factor for the acceptance of chatbots in the relational elements. Practical implications: The study extends the literature related to chatbots and offers several guidelines to the service industry to effectively employ chatbots. Originality/value: This is one of the first studies that used newly developed sRAM in determining chatbot acceptance. Moreover, the study extended the sRAM by adding user and gratification elements and privacy concerns as originally sRAM model was limited to functional, relational and social elements. © 2022, Emerald Publishing Limited.","Aslam, Wajeeha and Ahmed Siddiqui, Danish and Arif, Imtiaz and Farhat, Kashif",Kybernetes,,2022,10.1108/K-11-2021-1119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132678993&doi=10.1108%2fK-11-2021-1119&partnerID=40&md5=1bfa8169e67e5bcd4d8732f5bb314dd0,scopus.bib,2023-09-02 14:05:29,Unclassified
Lappeman2023337,Trust and digital privacy: willingness to disclose personal information to banking chatbot services,"This study explored digital privacy concerns in the use of chatbots as a digital banking service. Three dimensions of trust were tested in relation to user self-disclosure in order to better understand the consumer-chatbot experience in banking. The methodology selected for this research study followed a conclusive, pre-experimental, two-group one-shot case study research design which made use of a non-probability snowballing sampling technique. Privacy concerns were found to have a significantly negative relationship with user self-disclosure in both treatment groups. Respondents exposed to their preferred banking brand experienced lower user self-disclosure and brand trust than those exposed to a fictitious banking brand within the South African context. It is recommended that companies using chatbots focus on easing privacy concerns and build foundations of trust. The gains that chatbots have made in the form of increased productivity and quality of customer service rely on relationships with users who need to disclose personal information. Through this study, we concluded that, despite its power to influence decision-making, the power of a brand is not enough for consumers to considerably increase self-disclosure. Rather, a bridge of trust (through education, communication and product development) is needed that encompasses all three elements of trust, which are brand trust, cognitive trust and emotional trust. Limited research exists on the relationship between financial services marketing and chatbot adoption. Thus, this study addressed a theoretical gap, by adding brand trust to existing studies on cognitive and emotional trust regarding user self-disclosure. © 2022, The Author(s), under exclusive licence to Springer Nature Limited.","Lappeman, James and Marlie, Siddeeqah and Johnson, Tamryn and Poggenpoel, Sloane",Journal of Financial Services Marketing,,2023,10.1057/s41264-022-00154-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128828206&doi=10.1057%2fs41264-022-00154-z&partnerID=40&md5=81143273edf753cda01ec6b7d8cb306e,scopus.bib,2023-09-02 14:05:29,Unclassified
Hendrickx2021373,Towards a New generation of Personalized Intelligent Conversational Agents,"The Personalized Intelligent Conversational Agents workshop focuses on both long-term engaging spoken dialogue systems and text-based chatbots, as well as conversational recommender systems. The goal of the workshop is to stimulate discussion around problems, challenges, possible solutions and research directions regarding the exploitation of natural language processing and machine learning techniques to learn user features and to use them to personalize the dialogue in the next generation of intelligent conversational agents.  © 2021 Owner/Author.","Hendrickx, Iris and Cena, Federica and Basar, Erkan and Di Caro, Luigi and Kunneman, Florian and Musi, Elena and Musto, Cataldo and Rapp, Amon and Van Waterschoot, Jelte","UMAP 2021 - Adjunct Publication of the 29th ACM Conference on User Modeling, Adaptation and Personalization",,2021,10.1145/3450614.3461453,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109218496&doi=10.1145%2f3450614.3461453&partnerID=40&md5=fa1895e100de96eb6ceb986363525c7c,scopus.bib,2023-09-02 14:05:29,Unclassified
Jose20221891,Latency Control for Keyword Spotting,"Conversational agents commonly utilize keyword spotting (KWS) to initiate voice interaction with the user. For user experience and privacy considerations, existing approaches to KWS largely focus on accuracy, which can often come at the expense of introduced latency. To address this tradeoff, we propose a novel approach to control KWS model latency and which generalizes to any loss function without explicit knowledge of the keyword endpoint. Through a single, tunable hyperparameter, our approach enables one to balance detection latency and accuracy for the targeted application. Empirically, we show that our approach gives superior performance under latency constraints when compared to existing methods. Namely, we make a substantial 25% relative false accepts improvement for a fixed latency target when compared to the baseline state-of-the-art. We also show that when our approach is used in conjunction with a max-pooling loss, we are able to improve relative false accepts by 25% at a fixed latency when compared to cross entropy loss. Copyright © 2022 ISCA.","Jose, Christin and Wang, Joseph and Strimel, Grant P. and Khursheed, Mohammad Omar and Mishchenko, Yuriy and Kulis, Brian","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",,2022,10.21437/Interspeech.2022-10608,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140059692&doi=10.21437%2fInterspeech.2022-10608&partnerID=40&md5=a307fb881cb744301d53b1be9edac0f4,scopus.bib,2023-09-02 14:05:29,Unclassified
Mirbabaie2021365,Hybrid intelligence in hospitals: towards a research agenda for collaboration,"Successful collaboration between clinicians is particularly relevant regarding the quality of care process. In this context, the utilization of hybrid intelligence, such as conversational agents (CAs), is a reasonable approach for the coordination of diverse tasks. While there is a great deal of literature involving collaboration, little effort has been made to integrate previous findings and evaluate research when applying CAs in hospitals. By conducting an extended and systematic literature review and semi-structured expert interviews, we identified four major challenges and derived propositions where in-depth research is needed: 1) audience and interdependency; 2) connectivity and embodiment; 3) trust and transparency; and 4) security, privacy, and ethics. The results are helpful for researchers as we discuss directions for future research on CAs for collaboration in a hospital setting enhancing team performance. Practitioners will be able to understand which difficulties must be considered before the actual application of CAs. © 2021, The Author(s).","Mirbabaie, Milad and Stieglitz, Stefan and Frick, Nicholas R. J.",Electronic Markets,,2021,10.1007/s12525-021-00457-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100249142&doi=10.1007%2fs12525-021-00457-4&partnerID=40&md5=54413627acf4e6f1ba641f6fea97b0e9,scopus.bib,2023-09-02 14:05:29,Unclassified
Fan2021,Utilization of self-diagnosis health chatbots in real-world settings: Case study,"Background: Artificial intelligence (AI)-driven chatbots are increasingly being used in health care, but most chatbots are designed for a specific population and evaluated in controlled settings. There is little research documenting how health consumers (eg, patients and caregivers) use chatbots for self-diagnosis purposes in real-world scenarios. Objective: The aim of this research was to understand how health chatbots are used in a real-world context, what issues and barriers exist in their usage, and how the user experience of this novel technology can be improved. Methods: We employed a data-driven approach to analyze the system log of a widely deployed self-diagnosis chatbot in China. Our data set consisted of 47,684 consultation sessions initiated by 16,519 users over 6 months. The log data included a variety of information, including users' nonidentifiable demographic information, consultation details, diagnostic reports, and user feedback. We conducted both statistical analysis and content analysis on this heterogeneous data set. Results: The chatbot users spanned all age groups, including middle-aged and older adults. Users consulted the chatbot on a wide range of medical conditions, including those that often entail considerable privacy and social stigma issues. Furthermore, we distilled 2 prominent issues in the use of the chatbot: (1) a considerable number of users dropped out in the middle of their consultation sessions, and (2) some users pretended to have health concerns and used the chatbot for nontherapeutic purposes. Finally, we identified a set of user concerns regarding the use of the chatbot, including insufficient actionable information and perceived inaccurate diagnostic suggestions. Conclusions: Although health chatbots are considered to be convenient tools for enhancing patient-centered care, there are issues and barriers impeding the optimal use of this novel technology. Designers and developers should employ user-centered approaches to address the issues and user concerns to achieve the best uptake and utilization. We conclude the paper by discussing several design implications, including making the chatbots more informative, easy-to-use, and trustworthy, as well as improving the onboarding experience to enhance user engagement. © Xiangmin Fan, Daren Chao, Zhan Zhang, Dakuo Wang, Xiaohua Li, Feng Tian.","Fan, Xiangmin and Chao, Daren and Zhang, Zhan and Wang, Dakuo and Li, Xiaohua and Tian, Feng",Journal of Medical Internet Research,,2021,10.2196/19928,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099267127&doi=10.2196%2f19928&partnerID=40&md5=099f5ac81a2627bfa35f9f2f449a14e0,scopus.bib,2023-09-02 14:05:29,Unclassified
Patil20194296,Artificial intelligence in financial services: Customer chatbot advisor adoption,"The growing sophistication technology has helped us exchange Information at our fingertips, eliminating the need for human support.” A platform designed to understand, learn and converse like a human and answer ad-hoc queries in real time is commonly referred to as a Chabot”. Chabot advisor is Artificial intelligence (AI) computer program that impersonates human communication in its natural format including text or spoken language using a technique such as NLP, image processing or video processing along with the end task completion as instructed by the user [1]. The purpose of the paper was to examine what are the drivers for Chabot advisor services adoption (CBA), focusing on financial services. This study presents the explanatory Chabot advisor services factors by extending the Technology Acceptance Model (TAM). The construct in the research are like perceived privacy, perceived security, enjoyment and social influence. This empirical study was conducted in Pune city in India by collecting primary data from 310 online financial services customers. Data collected was analyzed using structural equation modeling using PLS-SEM.The outcome of this study is vital to financial companies like banks, policymakers, technology services adoption literature and provide customer-centric financial services. ©BEIESP.","Patil, Kanchan and Kulkarni, Mugdha S.",International Journal of Innovative Technology and Exploring Engineering,,2019,10.35940/ijitee.A4928.119119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075213653&doi=10.35940%2fijitee.A4928.119119&partnerID=40&md5=8b1ee635f387a124edf722635a5757f1,scopus.bib,2023-09-02 14:05:29,Unclassified
Uohara2020361,The Essential Role of Technology in the Public Health Battle against COVID-19,"Technology has played an important role in responding to the novel coronavirus (SARS-CoV-2) and subsequent COVID-19 pandemic. The virus's blend of lethality and transmissibility have challenged officials and exposed critical limitations of the traditional public health apparatus. However, throughout this pandemic, technology has answered the call for a new form of public health that illustrates opportunities for enhanced agility, scale, and responsiveness. The authors share the Microsoft perspective and illustrate how technology has helped transform the public health landscape with new and refined capabilities - the efficacy and impact of which will be determined by history. Technologies like chatbot and virtualized patient care offer a mechanism to triage and distribute care at scale. Artificial intelligence and high-performance computing have accelerated research into understanding the virus and developing targeted therapeutics to treat infection and prevent transmission. New mobile contact tracing protocols that preserve patient privacy and civil liberties were developed in response to public concerns, creating new opportunities for privacy-sensitive technologies that aid efforts to prevent and control outbreaks. While much progress is still needed, the COVID-19 pandemic has highlighted technology's importance to public health security and pandemic preparedness. Future multi-stakeholder collaborations, including those with technology organizations, are needed to facilitate progress in overcoming the current pandemic, setting the stage for improved pandemic preparedness in the future. As lessons are assessed from the current pandemic, public officials should consider technology's role and continue to seek opportunities to supplement and improve on traditional approaches.  © Copyright 2020, Mary Ann Liebert, Inc.","Uohara, Michael Y. and Weinstein, James N. and Rhew, David C.",Population Health Management,,2020,10.1089/pop.2020.0187,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092681418&doi=10.1089%2fpop.2020.0187&partnerID=40&md5=44c125a84afaf99472ea7a6955252991,scopus.bib,2023-09-02 14:05:29,Unclassified
Mazzola202262,Privacy and Customer’s Education: NLP for Information Resources Suggestions and Expert Finder Systems,"Privacy is one of the key issues for citizen’s everyday online activities, with the United Nations defining it as “a human right in the digital age”. Despite the introduction of data privacy regulations almost everywhere around the globe, the biggest barrier to effectiveness is the customer’s capacity to map the privacy statement received with the regulation in force and understand their terms. This study advocates the creation of a convenient and cost-efficient question-answering service for answering customers’ queries on data privacy. It proposes a dual step approach, allowing consumers to ask support to a conversational agent boosted by a smart knowledge base, attempting to answer the question using the most appropriate legal document. Being the self-help approach insufficient, our system enacts a second step suggesting a ranked list of legal experts for focused advice. To achieve our objective, we need large enough and specialised dataset and we plan to apply state-of-the-art Natural Language Processing (NLP) techniques in the field of open domain question answering. This paper describes the initial steps and some early results we achieved in this direction and the next steps we propose to develop a one-stop solution for consumers privacy needs. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Mazzola, Luca and Waldis, Andreas and Shankar, Atreya and Argyris, Diamantis and Denzler, Alexander and Van Roey, Michiel",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,2022,10.1007/978-3-031-05563-8_5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133244714&doi=10.1007%2f978-3-031-05563-8_5&partnerID=40&md5=46ce4454eea16e04683c2ffffa641ed1,scopus.bib,2023-09-02 14:05:29,Unclassified
Gulenko20147,Chatbot for IT security training: Using motivational interviewing to improve security behaviour,"We conduct a pre-study with 25 participants on Mechanical Turk to find out which security behavioural problems are most important for online users. These questions are based on motivational interviewing (MI), an evidence-based treatment methodology that enables to train people about different kinds of behavioural changes. Based on that the chatbot is developed using Artificial Intelligence Markup Language (AIML). The chatbot is trained to speak about three topics: passwords, privacy and secure browsing. These three topics were 'most-wanted' by the users of the pre-study. With the chatbot three training sessions with people are conducted.","Gulenko, Iwan",CEUR Workshop Proceedings,,2014,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925244807&partnerID=40&md5=7e7b543484f443c7b00628529aea2784,scopus.bib,2023-09-02 14:05:29,Unclassified
Hendrickx2021,Take Back Control: User Privacy and Transparency Concerns in Personalized Conversational Agents,"We reflect on user privacy concerns, transparency and informed consent for long-term interactions with personalized conversational agents. We argue that the common practice of asking users to sign an informed consent form is insufficient to accommodate the privacy concerns of the user. We propose that long-term engaging personalized conversational agents must include an explicit mechanism in their conversations to allow users to have control over their personal information and to have transparency, i.e. about what is stored and who is allowed to view the stored personal information. c 2020  Copyright for this paper by its authors.","Hendrickx, Iris and Waterschoot, Jelte Van and Khan, Arif and Bosch, Louis Ten and Cucchiarini, Catia and Strik, Helmer",CEUR Workshop Proceedings,,2021,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109210222&partnerID=40&md5=4d68a3e4e6c59a8bce9b0decdc10c184,scopus.bib,2023-09-02 14:05:29,Unclassified
Matulis2023,"Relief in Sight? Chatbots, In-baskets, and the Overwhelmed Primary Care Clinician","The recent emergence of publically facing artificial intelligence (AI) chatbots has generated vigorous discussion in the lay public around the possibilities, liabilities, and uncertainties of the integration of such technology into everyday life. As primary care clinicians continue to struggle against ever-increasing loads of asynchronous, electronic work, the potential for AI to improve the quality and efficiency of this work looms large. In this essay, we discuss the basic premise of open-access AI chatbots such as CHATGPT, review prior applications of AI in healthcare, and preview some possible AI chatbot–assisted in-basket assistance including scenarios of communicating test results with patients, providing patient education, and clinical decision support in history taking, review of prior diagnostic test characteristics, and common management scenarios. We discuss important concerns related to the future adoption of this technology including the transparency of the training data used in developing these models, the level of oversight and trustworthiness of the information generated, and possible impacts on equity, bias, and patient privacy. A stepwise and balanced approach to simultaneously understand the capabilities and address the concerns associated with these tools will be needed before these tools can improve patient care. © 2023, The Author(s), under exclusive licence to Society of General Internal Medicine.","Matulis, John and McCoy, Rozalina",Journal of General Internal Medicine,,2023,10.1007/s11606-023-08271-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163659754&doi=10.1007%2fs11606-023-08271-8&partnerID=40&md5=446c992048766a3197cd81dee5ae7580,scopus.bib,2023-09-02 14:05:29,Unclassified
Mitsuno2022,Evaluation of a Daily Interactive Chatbot That Exchanges Information about Others through Long-Term Use in a Group of Friends Investigating Dialogue Experience and Privacy Concern,"The goal of this study is to realize a non-task-oriented dialogue agent that is accepted by people in the long term. One approach is using a dialogue strategy in which an agent shares information about other users who are not participating in the current dialogue. This study aims to develop a chatbot that is capable of sharing information about others and to examine its usefulness as well as its problems such as privacy concerns using a long-term empirical experiment in a real-world environment. The result of a 14-day experiment with 120 participants suggested that the usefulness of this dialogue strategy lies in its ability to maintain users’ motivation to interact with the agent and prevent them from having the impression that the agent is mechanical. However, irrespective of the presence of this dialogue strategy, it was suggested that the users were concerned about their privacy to the agent that collected their information on a daily basis. Based on these results, we discussed the relationship between the interestingness of the shared information and the users’ privacy concerns. © 2022, Japanese Society for Artificial Intelligence. All rights reserved.","Mitsuno, Seiya and Yoshikawa, Yuichiro and Ban, Midori and Ishiguro, Hiroshi",Transactions of the Japanese Society for Artificial Intelligence,,2022,10.1527/tjsai.37-3_IDS-I,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132854367&doi=10.1527%2ftjsai.37-3_IDS-I&partnerID=40&md5=729355c35849bc1ad568bc0b63a8bb2a,scopus.bib,2023-09-02 14:05:29,Unclassified
Guida2021,"Privacy policies between perception and learning through Legal Design: Ideas for an Educational Chatbot combining rights'awareness, optimized user experience and training efficacy","Legal Design is inspired by the concepts of Design Thinking and User Experience: the ultimate goal is to make citizens more aware with well-designed rules and procedures in terms of 'Proactive law', providing policies that are truly user-centered, tailored to the cognitive needs both expressed and hidden through continuous and transparent communication. Talking about privacy, there is a clear need, starting from the analysis of the texts of some documents (e.g.'information on the use of personal data' and 'consent'), to translate 'bureaucratic' requests into simpler questions, as to allow the more intuitive, usable and inclusive user experience. So, in the wake of the GDPR view too, we have been experimenting how the advantages of communicating and involving the citizens by design and by default can prove to be the right key so that the privacy documents they encounter in the everyday life can finally transmit transparency and a sense of control of the situation that are both much more substantial and immediately perceptible. The future developments of the project will be focused on enhancing access to safeguards for digital privacy, as well as citizens' awareness of their digital rights, a fortiori for the weakest subjects, with a chatbot providing personalized educational/assistance services. In the final stage I will be concepting a prototype of such an educational chatbot ranging between rights to be deployed, user experience to be exalted and training effectiveness to be ensured. © 2021 Copyright for this paper by its authors.","Guida, Sergio",CEUR Workshop Proceedings,,2021,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126392292&partnerID=40&md5=142fa04cbd4041cb5d8437e0df13b409,scopus.bib,2023-09-02 14:05:29,Unclassified
Rese2020,Chatbots in retailers’ customer communication: How to measure their acceptance?,"Currently, online retailers evaluate whether chatbots—software programs that interact with users using natural languages—could improve their customers' satisfaction. In a retail context, chatbots allow humans to pose shopping-related questions and receive answers in natural language without waiting for a salesperson or using other automated communication forms. However, until now, it has been unclear which customers accept this new communication form and which factors determine their acceptance. In this paper, we contrast the well-known technology acceptance model (TAM) with the lesser known uses and gratifications (U&G) theory, applying both approaches to measure the acceptance of the text-based “Emma” chatbot by its target segment. “Emma” was developed for the prepurchase phase of online fashion retailing and integrated into Facebook Messenger by the major German online retailer Zalando. Data were collected from 205 German Millennial respondents in a usability study. The results show that both utilitarian factors such as “authenticity of conversation” and “perceived usefulness,” as well as hedonic factors such as “perceived enjoyment”, positively influence the acceptance of “Emma”. However, privacy concerns and the immaturity of the technology had a negative effect on usage intention and frequency. The predictive power of both models was similar, showing little deviation, but U&G gives alternative insights into the customers’ motivation to use “Emma” compared to the TAM. © 2020 Elsevier Ltd","Rese, Alexandra and Ganster, Lena and Baier, Daniel",Journal of Retailing and Consumer Services,,2020,10.1016/j.jretconser.2020.102176,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086591217&doi=10.1016%2fj.jretconser.2020.102176&partnerID=40&md5=af3c9259879f038ff2aed735cd169d1c,scopus.bib,2023-09-02 14:05:29,Unclassified
Chi2017542,Pilot testing a digital pet avatar for older adults,"Social isolation in older adults is a major public health concern. An embodied conversational agent (ECA) has the potential to enhance older adults’ social interaction. However, little is known about older adults’ experience with an ECA. In this paper, we conducted a pilot study to examine the perceived acceptance and utility of a tablet-based conversational agent in the form of an avatar (termed “digital pet”) for older adults. We performed secondary analysis of data collected from a study that employed the use of a digital pet in ten older adults’ homes for three months. Most of the participants enjoyed the companionship, entertainment, reminders, and instant assistance from the digital pet. However, participants identified limited conversational ability and technical issues as system challenges. Privacy, dependence, and cost were major concerns. Future applications should maximize the agent's conversational ability and the system's overall usability. Our results can inform future designs of conversational agents for older adults, which need to include older adults as system co-designers to maximize usability and acceptance. © 2017 Elsevier Inc.","Chi, Nai-Ching and Sparks, Olivia and Lin, Shih-Yin and Lazar, Amanda and Thompson, Hilaire J. and Demiris, George",Geriatric Nursing,,2017,10.1016/j.gerinurse.2017.04.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018939180&doi=10.1016%2fj.gerinurse.2017.04.002&partnerID=40&md5=d3de5b51a279b2be8fdcafec5ca81f5b,scopus.bib,2023-09-02 14:05:29,Unclassified
Griffin2020504,Conversational Agents for Chronic Disease Self-Management: A Systematic Review,"We conducted a systematic literature review to assess how conversational agents have been used to facilitate chronic disease self-management. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework was used. Literature was searched across five databases, and we included full-text articles that contained primary research findings for text-based conversational agents focused on self-management for chronic diseases in adults. 1,606 studies were identified, and 12 met inclusion criteria. Outcomes were largely focused on usability of conversational agents, and participants mostly reported positive attitudes with some concerns related to privacy and shallow content. In several studies, there were improvements on the Patient Health Questionnaire (p<0.05), Generalized Anxiety Disorder Scale (p=0.004), Perceived Stress Scale (p=0.048), Flourishing Scale (p=0.032), and Overall Anxiety Severity and Impairment Scale (p<0.05). There is early evidence that suggests conversational agents are acceptable, usable, and may be effective in supporting self-management, particularly for mental health. ©2020 AMIA - All rights reserved.","Griffin, Ashley C. and Xing, Zhaopeng and Khairat, Saif and Wang, Yue and Bailey, Stacy and Arguello, Jaime and Chung, Arlene E.",AMIA ... Annual Symposium proceedings. AMIA Symposium,,2020,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105317634&partnerID=40&md5=37f3a3bf32d886b8dc9d46d9265f006a,scopus.bib,2023-09-02 14:05:29,Unclassified
Peng2022,Formative Evaluation of the Acceptance of HIV Prevention Artificial Intelligence Chatbots by Men Who Have Sex with Men in Malaysia: Focus Group Study,"Background: Mobile technologies are being increasingly developed to support the practice of medicine, nursing, and public health, including HIV testing and prevention. Chatbots using artificial intelligence (AI) are novel mobile health strategies that can promote HIV testing and prevention among men who have sex with men (MSM) in Malaysia, a hard-to-reach population at elevated risk of HIV, yet little is known about the features that are important to this key population. Objective: The aim of this study was to identify the barriers to and facilitators of Malaysian MSM’s acceptance of an AI chatbot designed to assist in HIV testing and prevention in relation to its perceived benefits, limitations, and preferred features among potential users. Methods: We conducted 5 structured web-based focus group interviews with 31 MSM in Malaysia between July 2021 and September 2021. The interviews were first recorded, transcribed, coded, and thematically analyzed using NVivo (version 9; QSR International). Subsequently, the unified theory of acceptance and use of technology was used to guide data analysis to map emerging themes related to the barriers to and facilitators of chatbot acceptance onto its 4 domains: performance expectancy, effort expectancy, facilitating conditions, and social influence. Results: Multiple barriers and facilitators influencing MSM’s acceptance of an AI chatbot were identified for each domain. Performance expectancy (ie, the perceived usefulness of the AI chatbot) was influenced by MSM’s concerns about the AI chatbot’s ability to deliver accurate information, its effectiveness in information dissemination and problem-solving, and its ability to provide emotional support and raise health awareness. Convenience, cost, and technical errors influenced the AI chatbot’s effort expectancy (ie, the perceived ease of use). Efficient linkage to health care professionals and HIV self-testing was reported as a facilitating condition of MSM’s receptiveness to using an AI chatbot to access HIV testing. Participants stated that social influence (ie, sociopolitical climate) factors influencing the acceptance of mobile technology that addressed HIV in Malaysia included privacy concerns, pervasive stigma against homosexuality, and the criminalization of same-sex sexual behaviors. Key design strategies that could enhance MSM’s acceptance of an HIV prevention AI chatbot included an anonymous user setting; embedding the chatbot in MSM-friendly web-based platforms; and providing user-guiding questions and options related to HIV testing, prevention, and treatment. Conclusions: This study provides important insights into key features and potential implementation strategies central to designing an AI chatbot as a culturally sensitive digital health tool to prevent stigmatized health conditions in vulnerable and systematically marginalized populations. Such features not only are crucial to designing effective user-centered and culturally situated mobile health interventions for MSM in Malaysia but also illuminate the importance of incorporating social stigma considerations into health technology implementation strategies. ©Mary L Peng, Jeffrey A Wickersham, Frederick L Altice, Roman Shrestha, Iskandar Azwa, Xin Zhou, Mohd Akbar Ab Halim, Wan Mohd Ikhtiaruddin, Vincent Tee, Adeeba Kamarulzaman, Zhao Ni.","Peng, Mary L. and Wickersham, Jeffrey A. and Altice, Frederick L. and Shrestha, Roman and Azwa, Iskandar and Zhou, Xin and Halim, Mohd Akbar Ab and Ikhtiaruddin, Wan Mohd and Tee, Vincent and Kamarulzaman, Adeeba and Ni, Zhao",JMIR Formative Research,,2022,10.2196/42055,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140263659&doi=10.2196%2f42055&partnerID=40&md5=f295f7cec4fbca5a3d082042f254a7ac,scopus.bib,2023-09-02 14:05:29,Unclassified
Duduka2022481,The Impact of Artificial Intelligence on Chatbot Design,"Artificial intelligence is transforming the way chatbots are created and used. The recent boom of artificial intelligence development is creating a whole new generation of intelligent approaches that enable a more efficient and effective design of chatbots. On the other hand, the increasing need and interest from the industry in artificial intelligence based solutions, is guaranteeing the necessary investment and applicational know-how that is pushing such solutions to a new dimension. Some relevant examples are e-commerce, health or education, which is the main focus of this work. This paper studies and analyses the impact that artificial intelligence models and solutions is having on the design and development of chatbots, when compared to the previously used approaches. Some of the most relevant current and future challenges in this domain are highlighted, which include language learning, sentiment interpretation, integration with other services, or data security and privacy issues. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Duduka, Jacint and Reis, Arsénio and Pereira, Rodrigo and Pires, Eduardo and Sousa, José and Pinto, Tiago",Communications in Computer and Information Science,,2022,10.1007/978-3-031-22918-3_39,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148035567&doi=10.1007%2f978-3-031-22918-3_39&partnerID=40&md5=4b9fb92c5295e4cf024d190bbbb0c494,scopus.bib,2023-09-02 14:05:29,Unclassified
Dhinagaran2022,"Designing, Developing, Evaluating, and Implementing a Smartphone-Delivered, Rule-Based Conversational Agent (DISCOVER): Development of a Conceptual Framework","Background: Conversational agents (CAs), also known as chatbots, are computer programs that simulate human conversations by using predetermined rule-based responses or artificial intelligence algorithms. They are increasingly used in health care, particularly via smartphones. There is, at present, no conceptual framework guiding the development of smartphone-based, rule-based CAs in health care. To fill this gap, we propose structured and tailored guidance for their design, development, evaluation, and implementation. Objective: The aim of this study was to develop a conceptual framework for the design, evaluation, and implementation of smartphone-delivered, rule-based, goal-oriented, and text-based CAs for health care. Methods: We followed the approach by Jabareen, which was based on the grounded theory method, to develop this conceptual framework. We performed 2 literature reviews focusing on health care CAs and conceptual frameworks for the development of mobile health interventions. We identified, named, categorized, integrated, and synthesized the information retrieved from the literature reviews to develop the conceptual framework. We then applied this framework by developing a CA and testing it in a feasibility study. Results: The Designing, Developing, Evaluating, and Implementing a Smartphone-Delivered, Rule-Based Conversational Agent (DISCOVER) conceptual framework includes 8 iterative steps grouped into 3 stages, as follows: design, comprising defining the goal, creating an identity, assembling the team, and selecting the delivery interface; development, including developing the content and building the conversation flow; and the evaluation and implementation of the CA. They were complemented by 2 cross-cutting considerations-user-centered design and privacy and security-that were relevant at all stages. This conceptual framework was successfully applied in the development of a CA to support lifestyle changes and prevent type 2 diabetes. Conclusions: Drawing on published evidence, the DISCOVER conceptual framework provides a step-by-step guide for developing rule-based, smartphone-delivered CAs. Further evaluation of this framework in diverse health care areas and settings and for a variety of users is needed to demonstrate its validity. Future research should aim to explore the use of CAs to deliver health care interventions, including behavior change and potential privacy and safety concerns. © 2022 JMIR Publications. All rights reserved.","Dhinagaran, Dhakshenya Ardhithy and Martinengo, Laura and Ho, Moon-Ho Ringo and Joty, Shafiq and Kowatsch, Tobias and Atun, Rifat and Car, Lorainne Tudor",JMIR mHealth and uHealth,,2022,10.2196/38740,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139572670&doi=10.2196%2f38740&partnerID=40&md5=a1475a83b0b14e62b570a1a4d92e6faa,scopus.bib,2023-09-02 14:05:29,Unclassified
Adel2022,Chatbot for construction firms using scalable blockchain network,"Information and Communication Technologies (ICT), including multimedia tools, email services, voice-based tools, and handheld computing tools, have been extensively used for automating and digitalizing different construction processes and activities. However, these technologies are subjected to single-point attacks or failures, manipulation, and lack of privacy and traceability. This study introduces a novel information exchange and management system for construction firms based on blockchain technology and chatbots. The system leverages the characteristics of blockchain technology in terms of peer-to-peer operation mode, data integrity, structuring, and privacy, and the chatbots' merits regarding ease of use and degree of automation. The system is developed for tracking work progress in construction projects as a generic use-case using a four-step approach. First, a private blockchain network is configured for data distribution and storage. Second, a smart contract is coded for regulating data writing/reading operations. Third, a chatbot is developed for data collection and retrieval through textual conversations. Fourth, serverless cloud function and cloudant database are configured to allow the linkage between the blockchain network and the chatbot. A prototype of the system is built and applied to a case study of non-residential construction project to test and verify its capabilities. Further, the system's performance is assessed in terms of the writing and reading latencies and the storage size. The system features can be extended by embedding mathematical algorithms to simultaneously analyze data and employing Inter-Planetary File System (IPFS) to maintain visuals and large-size data. © 2022 Elsevier B.V.","Adel, Kareem and Elhakeem, Ahmed and Marzouk, Mohamed",Automation in Construction,,2022,10.1016/j.autcon.2022.104390,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131422074&doi=10.1016%2fj.autcon.2022.104390&partnerID=40&md5=3b208292cf2b97c9afbed442e231ed80,scopus.bib,2023-09-02 14:05:29,Unclassified
Hernández-Trapote2008305,Embodied conversational agents for Voice-Biometric interfaces,"In this article we present a research scheme which aims to analyze the use of Embodied Conversational Agent (ECA) technology to improve the robustness and acceptability of speaker enrolment and verification dialogues designed to provide secure access through natural and intuitive speaker recognition. In order to find out the possible effects of the visual information channel provided by the ECA, tests were carried out in which users were divided into two groups, each interacting with a different interface (metaphor): an ECA Metaphor group -with an ECA-, and a VOICE Metaphor group -without an ECA-. Our evaluation methodology is based on the ITU-T P.851 recommendation for spoken dialogue system evaluation, which we have complemented to cover particular aspects with regard to the two major extra elements we have incorporated: secure access and an ECA. Our results suggest that likeability-type factors and system capabilities are perceived more positively by the ECA metaphor users than by the VOICE metaphor users. However, the ECA's presence seems to intensify users' privacy concerns. Copyright 2008 ACM.","Hernández-Trapote, Álvaro and López-Mencía, Beatriz and Díaz, David and Fernández-Pozo, Rubén and Caminero, Javier",ICMI'08: Proceedings of the 10th International Conference on Multimodal Interfaces,,2008,10.1145/1452392.1452454,https://www.scopus.com/inward/record.uri?eid=2-s2.0-63449104556&doi=10.1145%2f1452392.1452454&partnerID=40&md5=b12fbdb8584819659f5117121a747bbc,scopus.bib,2023-09-02 14:05:29,Unclassified
Hasal2021,"Chatbots: Security, privacy, data protection, and social aspects","Chatbots are artificial communication systems becoming increasingly popular and not all their security questions are clearly solved. People use chatbots for assistance in shopping, bank communication, meal delivery, healthcare, cars, and many other actions. However, it brings an additional security risk and creates serious security challenges which have to be handled. Understanding the underlying problems requires defining the crucial steps in the techniques used to design chatbots related to security. There are many factors increasing security threats and vulnerabilities. All of them are comprehensively studied, and security practices to decrease security weaknesses are presented. Modern chatbots are no longer rule-based models, but they employ modern natural language and machine learning techniques. Such techniques learn from a conversation, which can contain personal information. The paper discusses circumstances under which such data can be used and how chatbots treat them. Many chatbots operate on a social/messaging platform, which has their terms and conditions about data. The paper aims to present a comprehensive study of security aspects in communication with chatbots. The article could open a discussion and highlight the problems of data storage and usage obtained from the communication user—chatbot and propose some standards to protect the user. © 2021 The Authors. Concurrency and Computation: Practice and Experience published by John Wiley & Sons Ltd.","Hasal, Martin and Nowaková, Jana and Ahmed Saghair, Khalifa and Abdulla, Hussam and Snášel, Václav and Ogiela, Lidia",Concurrency and Computation: Practice and Experience,,2021,10.1002/cpe.6426,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107027640&doi=10.1002%2fcpe.6426&partnerID=40&md5=37385e4313531804f13c98d4d46cea2a,scopus.bib,2023-09-02 14:05:29,Unclassified
Calvaresi20211,EREBOTS: Privacy-compliant agent-based platform for multi-scenario personalized health-assistant chatbots,"Context. Asynchronous messaging is increasingly used to support human–machine inter-actions, generally implemented through chatbots. Such virtual entities assist the users in activities of different kinds (e.g., work, leisure, and health-related) and are becoming ingrained into humans’ habits due to factors including (i) the availability of mobile devices such as smartphones and tablets, (ii) the increasingly engaging nature of chatbot interactions, (iii) the release of dedicated APIs from messaging platforms, and (iv) increasingly complex AI-based mechanisms to power the bots’ behav-iors. Nevertheless, most of the modern chatbots rely on state machines (implementing conversational rules) and one-fits-all approaches, neglecting personalization, data-stream privacy management, multi-topic management/interconnection, and multimodal interactions. Objective. This work ad-dresses the challenges above through an agent-based framework for chatbot development named EREBOTS. Methods. The foundations of the framework are based on the implementation of (i) multi-front-end connectors and interfaces (i.e., Telegram, dedicated App, and web interface), (ii) enabling the configuration of multi-scenario behaviors (i.e., preventive physical conditioning, smoking cessa-tion, and support for breast-cancer survivors), (iii) online learning, (iv) personalized conversations and recommendations (i.e., mood boost, anti-craving persuasion, and balance-preserving physical exercises), and (v) responsive multi-device monitoring interface (i.e., doctor and admin). Results. EREBOTS has been tested in the context of physical balance preservation in social confinement times (due to the ongoing pandemic). Thirteen individuals characterized by diverse age, gender, and country distribution have actively participated in the experimentation, reporting advancements in the physical balance and overall satisfaction of the interaction and exercises’ variety they have been proposed. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Calvaresi, Davide and Calbimonte, Jean-Paul and Siboni, Enrico and Eggenschwiler, Stefan and Manzo, Gaetano and Hilfiker, Roger and Schumacher, Michael",Electronics (Switzerland),,2021,10.3390/electronics10060666,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102393472&doi=10.3390%2felectronics10060666&partnerID=40&md5=54dafd673b5c9a1bc4464dbb158a4a28,scopus.bib,2023-09-02 14:05:29,Unclassified
Kazim2021,Systematizing audit in algorithmic recruitment,"Business psychologists study and assess relevant individual differences, such as intelligence and personality, in the context of work. Such studies have informed the development of artificial intelligence systems (AI) designed to measure individual differences. This has been capitalized on by companies who have developed AI-driven recruitment solutions that include aggregation of appropriate candidates (Hiretual), interviewing through a chatbot (Paradox), video interview assessment (MyInterview), and CV-analysis (Textio), as well as estimation of psychometric characteristics through image-(Traitify) and game-based assessments (HireVue) and video interviews (Cammio). However, driven by concern that such high-impact technology must be used responsibly due to the potential for unfair hiring to result from the algorithms used by these tools, there is an active effort towards proving mechanisms of governance for such automation. In this article, we apply a systematic algorithm audit framework in the context of the ethically critical industry of algorithmic recruitment systems, exploring how audit assessments on AI-driven systems can be used to assure that such systems are being responsibly deployed in a fair and well-governed manner. We outline sources of risk for the use of algorithmic hiring tools, suggest the most appropriate opportunities for audits to take place, recommend ways to measure bias in algorithms, and discuss the transparency of algorithms. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Kazim, Emre and Koshiyama, Adriano Soares and Hilliard, Airlie and Polle, Roseline",Journal of Intelligence,,2021,10.3390/jintelligence9030046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115781934&doi=10.3390%2fjintelligence9030046&partnerID=40&md5=6e5fff246bbd335a925680dc300655c5,scopus.bib,2023-09-02 14:05:29,Unclassified
Fournier-Tombs2023,A Medical Ethics Framework for Conversational Artificial Intelligence,"The launch of OpenAI’s GPT-3 model in June 2020 began a new era for conversational chatbots. While there are chatbots that do not use artificial intelligence (AI), conversational chatbots integrate AI language models that allow for back-and-forth conversation between an AI system and a human user. GPT-3, since upgraded to GPT-4, harnesses a natural language processing technique called sentence embedding and allows for conversations with users that are more nuanced and realistic than before. The launch of this model came in the first few months of the COVID-19 pandemic, where increases in health care needs globally combined with social distancing measures made virtual medicine more relevant than ever. GPT-3 and other conversational models have been used for a wide variety of medical purposes, from providing basic COVID-19–related guidelines to personalized medical advice and even prescriptions. The line between medical professionals and conversational chatbots is somewhat blurred, notably in hard-to-reach communities where the chatbot replaced face-to-face health care. Considering these blurred lines and the circumstances accelerating the adoption of conversational chatbots globally, we analyze the use of these tools from an ethical perspective. Notably, we map out the many types of risks in the use of conversational chatbots in medicine to the principles of medical ethics. In doing so, we propose a framework for better understanding the effects of these chatbots on both patients and the medical field more broadly, with the hope of informing safe and appropriate future developments. © Eleonore Fournier-Tombs, Juliette McHardy.","Fournier-Tombs, Eleonore and McHardy, Juliette",Journal of Medical Internet Research,,2023,10.2196/43068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165788275&doi=10.2196%2f43068&partnerID=40&md5=4bab0dcf8b77bbaf4f834a1bdf405019,scopus.bib,2023-09-02 14:05:29,Unclassified
Inkster2018,"An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: Real-world data evaluation mixed-methods study","Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short-and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre-and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. © Becky Inkster, Shubhankar Sarda, Vinod Subramanian.","Inkster, Becky and Sarda, Shubhankar and Subramanian, Vinod",JMIR mHealth and uHealth,,2018,10.2196/12106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060334446&doi=10.2196%2f12106&partnerID=40&md5=ee4042f0f43089954f87f8eb3205565f,scopus.bib,2023-09-02 14:05:29,Unclassified
Figueroa2021,Conversational Physical Activity Coaches for Spanish and English Speaking Women: A User Design Study,"Introduction: Digital technologies, including text messaging and mobile phone apps, can be leveraged to increase people's physical activity and manage health. Chatbots, powered by artificial intelligence, can automatically interact with individuals through natural conversation. They may be more engaging than one-way messaging interventions. To our knowledge, physical activity chatbots have not been developed with low-income participants, nor in Spanish—the second most dominant language in the U.S. We recommend best practices for physical activity chatbots in English and Spanish for low-income women. Methods: We designed a prototype physical activity text-message based conversational agent based on various psychotherapeutic techniques. We recruited participants through SNAP-Ed (Supplemental Nutrition Assistance Program Education) in California (Alameda County) and Tennessee (Shelby County). We conducted qualitative interviews with participants during testing of our prototype chatbot, held a Wizard of Oz study, and facilitated a co-design workshop in Spanish with a subset of our participants. Results: We included 10 Spanish- and 8 English-speaking women between 27 and 41 years old. The majority was Hispanic/Latina (n = 14), 2 were White and 2 were Black/African American. More than half were monolingual Spanish speakers, and the majority was born outside the US (>50% in Mexico). Most participants were unfamiliar with chatbots and were initially skeptical. After testing our prototype, most users felt positively about health chatbots. They desired a personalized chatbot that addresses their concerns about privacy, and stressed the need for a comprehensive system to also aid with nutrition, health information, stress, and involve family members. Differences between English and monolingual Spanish speakers were found mostly in exercise app use, digital literacy, and the wish for family inclusion. Conclusion: Low-income Spanish- and English-speaking women are interested in using chatbots to improve their physical activity and other health related aspects. Researchers developing health chatbots for this population should focus on issues of digital literacy, app familiarity, linguistic and cultural issues, privacy concerns, and personalization. Designing and testing this intervention for and with this group using co-creation techniques and involving community partners will increase the probability that it will ultimately be effective. © Copyright © 2021 Figueroa, Luo, Jacobo, Munoz, Manuel, Chan, Canny and Aguilera.","Figueroa, Caroline A. and Luo, Tiffany C. and Jacobo, Andrea and Munoz, Alan and Manuel, Minx and Chan, David and Canny, John and Aguilera, Adrian",Frontiers in Digital Health,,2021,10.3389/fdgth.2021.747153,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131227176&doi=10.3389%2ffdgth.2021.747153&partnerID=40&md5=17837b264b5c443418797030ad583d4f,scopus.bib,2023-09-02 14:05:29,Unclassified
Roca2020,Microservice chatbot architecture for chronic patient support,"Chatbots are able to provide support to patients suffering from very different conditions. Patients with chronic diseases or comorbidities could benefit the most from chatbots which can keep track of their condition, provide specific information, encourage adherence to medication, etc. To perform these functions, chatbots need a suitable underlying software architecture. In this paper, we introduce a chatbot architecture for chronic patient support grounded on three pillars: scalability by means of microservices, standard data sharing models through HL7 FHIR and standard conversation modeling using AIML. We also propose an innovative automation mechanism to convert FHIR resources into AIML files, thus facilitating the interaction and data gathering of medical and personal information that ends up in patient health records. To align the way people interact with each other using messaging platforms with the chatbot architecture, we propose these very same channels for the chatbot-patient interaction, paying special attention to security and privacy issues. Finally, we present a monitored-data study performed in different chronic diseases, and we present a prototype implementation tailored for one specific chronic disease, psoriasis, showing how this new architecture allows the change, the addition or the improvement of different parts of the chatbot in a dynamic and flexible way, providing a substantial improvement in the development of chatbots used as virtual assistants for chronic patients. © 2019 Elsevier Inc.","Roca, Surya and Sancho, Jorge and García, José and Alesanco, Álvaro",Journal of Biomedical Informatics,,2020,10.1016/j.jbi.2019.103305,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077322086&doi=10.1016%2fj.jbi.2019.103305&partnerID=40&md5=bf7bbf24a0a82d95fd11aae98395bea1,scopus.bib,2023-09-02 14:05:29,Unclassified
Dwivedi2023,"“So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy","Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts. © 2023 The Authors","Dwivedi, Yogesh K. and Kshetri, Nir and Hughes, Laurie and Slade, Emma Louise and Jeyaraj, Anand and Kar, Arpan Kumar and Baabdullah, Abdullah M. and Koohang, Alex and Raghavan, Vishnupriya and Ahuja, Manju and Albanna, Hanaa and Albashrawi, Mousa Ahmad and Al-Busaidi, Adil S. and Balakrishnan, Janarthanan and Barlette, Yves and Basu, Sriparna and Bose, Indranil and Brooks, Laurence and Buhalis, Dimitrios and Carter, Lemuria and Chowdhury, Soumyadeb and Crick, Tom and Cunningham, Scott W. and Davies, Gareth H. and Davison, Robert M. and Dé, Rahul and Dennehy, Denis and Duan, Yanqing and Dubey, Rameshwar and Dwivedi, Rohita and Edwards, John S. and Flavián, Carlos and Gauld, Robin and Grover, Varun and Hu, Mei-Chih and Janssen, Marijn and Jones, Paul and Junglas, Iris and Khorana, Sangeeta and Kraus, Sascha and Larsen, Kai R. and Latreille, Paul and Laumer, Sven and Malik, F. Tegwen and Mardani, Abbas and Mariani, Marcello and Mithas, Sunil and Mogaji, Emmanuel and Nord, Jeretta Horn and O'Connor, Siobhan and Okumus, Fevzi and Pagani, Margherita and Pandey, Neeraj and Papagiannidis, Savvas and Pappas, Ilias O. and Pathak, Nishith and Pries-Heje, Jan and Raman, Ramakrishnan and Rana, Nripendra P. and Rehm, Sven-Volker and Ribeiro-Navarrete, Samuel and Richter, Alexander and Rowe, Frantz and Sarker, Suprateek and Stahl, Bernd Carsten and Tiwari, Manoj Kumar and van der Aalst, Wil and Venkatesh, Viswanath and Viglia, Giampaolo and Wade, Michael and Walton, Paul and Wirtz, Jochen and Wright, Ryan",International Journal of Information Management,,2023,10.1016/j.ijinfomgt.2023.102642,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149886538&doi=10.1016%2fj.ijinfomgt.2023.102642&partnerID=40&md5=07a92f9d615bd212010a31ca0fe70bec,scopus.bib,2023-09-02 14:05:29,Unclassified
Bouhia20221159,Drivers of privacy concerns when interacting with a chatbot in a customer service encounter,"Purpose: This study aims to examine the antecedents of privacy concerns in the era of artificial intelligence. Specifically, it focuses on the impact of various factors related to interactions with a chatbot (creepiness and perceived risk) and individual traits (familiarity with chatbots and need for privacy) in relation to privacy when interacting with a chatbot in the context of financial services. The moderating effect of gender on these relationships was also examined. Design/methodology/approach: A total of 430 Canadians responded to an online questionnaire after interacting with a chatbot in the context of a simulated auto insurance quote. A structural equation model was used to test the hypotheses. Findings: The results showed that privacy concerns are influenced primarily by creepiness, followed by perceived risk and the need for privacy. The last two relationships are moderated by gender. Conversely, familiarity with chatbots does not affect privacy concerns in this context. Originality/value: This study is the first to consider the influence of creepiness as an antecedent of privacy concerns arising from interactions with AI tools and highlight its key impacts. It also shows how gender moderates specific relationships in this context. © 2022, Emerald Publishing Limited.","Bouhia, Mariem and Rajaobelina, Lova and PromTep, Sandrine and Arcand, Manon and Ricard, Line",International Journal of Bank Marketing,,2022,10.1108/IJBM-09-2021-0442,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130135261&doi=10.1108%2fIJBM-09-2021-0442&partnerID=40&md5=67e13d769c9207a4239369d88b4bd042,scopus.bib,2023-09-02 14:05:29,Unclassified
Song2022,Should the chatbot “save itself” or “be helped by others”? The influence of service recovery types on consumer perceptions of recovery satisfaction,"The application of artificial intelligence is considered essential to adapt to a new cycle of industrial transformation and technological advancements in many fields and industries. The extensive use of artificial intelligence technology is expected to improve the level and quality of services provided by companies adopting these methods. In this study, we propose a novel approach to self-recovery by chatbot systems after service failures based on social response theory. Moreover, we explore differences in consumer perceptions of different service recovery types and their impact on recovery satisfaction, and discusses whether the intelligence of the computational agent also has an effect. We present the results of three scenario-based experiments, which demonstrate the positive effect of chatbot self-recovery on consumer satisfaction, and show the mediating paths of service recovery types in terms of perceived functional value and privacy risks as well as the boundary condition of the level of robot intelligence. This work expands the range of applications of chatbots in the service industry and provides a new framework for the governance of artificial intelligence. © 2022 Elsevier B.V.","Song, Mengmeng and Du, Jingzhe and Xing, Xinyu and Mou, Jian",Electronic Commerce Research and Applications,,2022,10.1016/j.elerap.2022.101199,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138060925&doi=10.1016%2fj.elerap.2022.101199&partnerID=40&md5=2bdc113abb59c10118799e383b809033,scopus.bib,2023-09-02 14:05:29,Unclassified
Motger2021347,Integrating Adaptive Mechanisms into Mobile Applications Exploiting User Feedback,"Mobile applications have become a commodity in multiple daily scenarios. Their increasing complexity has led mobile software ecosystems to become heterogeneous in terms of hardware specifications, features and context of use, among others. For their users, fully exploiting their potential has become challenging. While enacting software systems with adaptation mechanisms has proven to ease this burden from users, mobile devices present specific challenges related to privacy and security concerns. Nevertheless, rather than being a limitation, users can play a proactive role in the adaptation loop by providing valuable feedback for runtime adaptation. To this end, we propose the use of chatbots to interact with users through a human-like smart conversational process. We depict a work-in-progress proposal of an end-to-end framework to integrate semi-automatic adaptation mechanisms for mobile applications. These mechanisms include the integration of both implicit and explicit user feedback for autonomous user categorization and execution of enactment action plans. We illustrate the applicability of such techniques through a set of scenarios from the Mozilla mobile applications suite. We envisage that our proposal will improve user experience by bridging the gap between users’ needs and the capabilities of their mobile devices through an intuitive and minimally invasive conversational mechanism. © 2021, Springer Nature Switzerland AG.","Motger, Quim and Franch, Xavier and Marco, Jordi",Lecture Notes in Business Information Processing,,2021,10.1007/978-3-030-75018-3_23,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111164309&doi=10.1007%2f978-3-030-75018-3_23&partnerID=40&md5=f5a523a708437fe0be1f015acfd94b75,scopus.bib,2023-09-02 14:05:29,Unclassified
WOS:000911440600005,"Privacy and Customer's Education: NLP for Information Resources
Suggestions and Expert Finder Systems","Privacy is one of the key issues for citizen's everyday online
activities, with the United Nations defining it as ``a human right in
the digital age{''}. Despite the introduction of data privacy
regulations almost everywhere around the globe, the biggest barrier to
effectiveness is the customer's capacity to map the privacy statement
received with the regulation in force and understand their terms. This
study advocates the creation of a convenient and cost-efficient
question-answering service for answering customers' queries on data
privacy. It proposes a dual step approach, allowing consumers to ask
support to a conversational agent boosted by a smart knowledge base,
attempting to answer the question using the most appropriate legal
document. Being the self-help approach insufficient, our system enacts a
second step suggesting a ranked list of legal experts for focused
advice. To achieve our objective, we need large enough and specialised
dataset and we plan to apply state-of-the-art Natural Language
Processing (NLP) techniques in the field of open domain question
answering. This paper describes the initial steps and some early results
we achieved in this direction and the next steps we propose to develop a
one-stop solution for consumers privacy needs.","Mazzola, Luca and Waldis, Andreas and Shankar, Atreya and Argyris,
Diamantis and Denzler, Alexander and Van Roey, Michiel",,"HCI FOR CYBERSECURITY, PRIVACY AND TRUST, HCI-CPT 2022",2022,10.1007/978-3-031-05563-8\_5,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000521736100050,"A Banking Chatbot Security Control Procedure for Protecting User Data
Security and Privacy","The rise of AI has prompted the financial business to enter the
intelligent financial technology (FinTech). Chatbot with AI technologies
is an important member of FinTech. The financial industry is actively
introducing chatbot to enhance the market competitive advantage. Many
banks and card issuers in the United States have introduced or developed
chatbots from 2017 to increase user convenience and assist business
promotion of financial institutions. However, chatbot with AI features
may infringe customer security and personal privacy. Security has become
an important issue that Chatbot must pay attention to. In order to
improve the security of chatbot, this paper analyzes the security
strategies of e-commerce (EC), and combines the AI security principles
to plan the Chatbot Security Control Procedure (CSCP). CSCP uses
security specifications confirmation, specifications implementation,
inspection activity and improvement manners four stages to monitor
chatbot. Banking chatbot with CSPS can hold advantages of chatbots,
reduce the security risk, and concretely protect customer data security
and personal privacy.","Lai, Sen-Tarng and Leu, Fang-Yie and Lin, Jeng-Wei",,"ADVANCES ON BROADBAND AND WIRELESS COMPUTING, COMMUNICATION AND
APPLICATIONS, BWCCA-2018",2019,10.1007/978-3-030-02613-4\_50,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000501543800199,"``Hear me out{''}: Smart Speaker Based Conversational Agent to Monitor
Symptoms in Mental Health","Difference in features of voice such as tone, volume, intonation, and
rate of speech have been suggested as sensitive and valid measures of
mental illness. Researchers have used analysis of voice recordings
during phone calls, response to the IVR systems and smartphone based
conversational agents as a marker in continuous monitoring of symptoms
and effect of treatment in patients with mental illness. While these
methods of recording the patient's voice have been considered efficient,
they come with a number of issues in terms of adoption, privacy,
security, data storage etc. To address these issues we propose a smart
speaker based conversational agent - ``Hear me out{''}. In this paper,
we describe the proposed system, rationale behind using smart speakers,
and the challenges we are facing in the design of the system.","Maharjan, Raju and Baekgaard, Per and Bardram, Jakob E.",,"UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT
CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE
2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS",2019,10.1145/3341162.3346270,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000756587600003,"IDENTIFYING RELEVANT SEGMENTS OF POTENTIAL BANKING CHATBOT USERS BASED
ON TECHNOLOGY ADOPTION BEHAVIOR","Purpose Chatbot technology is expected to revolutionize customer service
in financial institutions. However, the adoption of customer service
chatbots in banking remains low. Therefore, the aim of this paper is to
identify relevant segments of potential banking chatbot users based on
technology adoption behavior.
Design/Methodology/Approach - Data for the research was collected
through an online questionnaire in Romania using the non-probability
sampling method. The 287 questionnaires were analyzed using hierarchical
and k-means cluster analysis.
Findings and implications - The analysis revealed three distinct
segments: Innovators (2696), consisting of highly educated young women
employed in the business sector; the Late Majority (55\%), consisting of
young women with higher education degrees who work in services-related
fields; and Laggards (19\%), consisting of educated middle-aged men
employed in the business sector. New significant differences among
demographic: and banking behavior variables weft observed across the
profiles of potential banking chatbot user segments.
Limitations - The study is based on a non-probability sample collected
from only one country, with a rather small sample size.
Originality -Technology acceptance variables (perceived usefulness,
perceived ease of use), expanded to include constructs such as awareness
of service, perceived privacy risk, and perceived compatibility, were
found to be appro priate for customer segmentation purposes in the
context of chatbot applications based on artificial intelligence. The
study also revealed a new innovator demographic profile.","Alt, Monika-Anetta and Ibolya, Vizeli",MARKET-TRZISTE,,2021,10.22598/mt/2021.33.2.165,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000854073700027,"Thematic Analysis on User Reviews for Depression and Anxiety Chatbot
Apps: Machine Learning Approach","Background: Anxiety and depression are among the most commonly prevalent
mental health disorders worldwide. Chatbot apps can play an important
role in relieving anxiety and depression. Users' reviews of chatbot apps
are considered an important source of data for exploring users' opinions
and satisfaction.
Objective: This study aims to explore users' opinions, satisfaction, and
attitudes toward anxiety and depression chatbot apps by conducting a
thematic analysis of users' reviews of 11 anxiety and depression chatbot
apps collected from the Google Play Store and Apple App Store. In
addition, we propose a workflow to provide a methodological approach for
future analysis of app review comments.
Methods: We analyzed 205,581 user review comments from chatbots designed
for users with anxiety and depression symptoms. Using scraper tools and
Google Play Scraper and App Store Scraper Python libraries, we extracted
the text and metadata. The reviews were divided into positive and
negative meta-themes based on users' rating per review. We analyzed the
reviews using word frequencies of bigrams and words in pairs. A topic
modeling technique, latent Dirichlet allocation, was applied to identify
topics in the reviews and analyzed to detect themes and subthemes.
Results: Thematic analysis was conducted on 5 topics for each
sentimental set. Reviews were categorized as positive or negative. For
positive reviews, the main themes were confidence and affirmation
building, adequate analysis, and consultation, caring as a friend, and
ease of use. For negative reviews, the results revealed the following
themes: usability issues, update issues, privacy, and noncreative
conversations.
Conclusions: Using a machine learning approach, we were able to analyze
>= 200,000 comments and categorize them into themes, allowing us to
observe users' expectations effectively despite some negative factors. A
methodological workflow is provided for the future analysis of review
comments.","Ahmed, Arfan and Aziz, Sarah and Khalifa, Mohamed and Shah, Uzair and
Hassan, Asma and Abd-Alrazaq, Alaa and Househ, Mowafa",JMIR FORMATIVE RESEARCH,,2022,10.2196/27654,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000765484500015,Smart Speakers: The Next Frontier in mHealth,"The rapid dissemination and adoption of smart speakers has enabled
substantial opportunities to improve human health. Just as the
introduction of the mobile phone led to considerable health innovation,
smart speaker computing systems carry several unique advantages that
have the potential to catalyze new fields of health research,
particularly in out-of-hospital environments. The recent rise and
ubiquity of these smart computing systems holds significant potential
for enhancing chronic disease management, enabling passive
identification of unwitnessed medical emergencies, detecting subtle
changes in human behavior and cognition, limiting isolation, and
potentially allowing widespread, passive, remote monitoring of
respiratory diseases that impact public health. There are 3 broad
mechanisms for how a smart speaker can interact with a person to improve
health. These include (1) as an intelligent conversational agent, (2) as
a passive identifier of medically relevant diagnostic sounds, and (3) by
active sensing using the device's internal hardware to measure
physiologic parameters, such as with active sonar, radar, or computer
vision. Each of these different modalities has specific clinical use
cases, all of which need to be balanced against potential privacy
concerns, equity concerns related to system access, and regulatory
frameworks which have not yet been developed for this unique type of
passive data collection.","Sunshine, Jacob",JMIR MHEALTH AND UHEALTH,,2022,10.2196/28686,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000774798100001,"The Impact of Chatbots on Customer Loyalty: A Systematic Literature
Review","More and more companies have implemented chatbots on their websites to
provide support to their visitors on a 24/7 basis. The new customer
wants to spend less and less time and therefore expects to reach a
company anytime and anywhere, regardless of time, location, and channel.
This study provides insight into the influence of chatbots on customer
loyalty. System quality, service quality, and information quality are
crucial dimensions that a chatbot must meet to give a good customer
experience. To make a chatbot more personal, companies can alter the
language style. Human-like chatbots lead to greater satisfaction and
trust among customers, leading to greater adoption of the chatbot. The
results of this study showed that a connection between chatbots and
customer loyalty is very likely. Besides, some customers suffer from the
privacy paradox because of personalization. Implications of this study
are discussed.","Jenneboer, Liss and Herrando, Carolina and Constantinides, Efthymios",JOURNAL OF THEORETICAL AND APPLIED ELECTRONIC COMMERCE RESEARCH,,2022,10.3390/jtaer17010011,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000518623400005,Ethical Artificial Intelligence for Digital Health Organizations,"This technical report describes the methods undertaken by a US-based
Digital Health company (X2AI or X2 for short) to develop an ethical code
for startup environments and other organizations delivering emotional
artificial intelligence (AI) services, especially for mental health
support. With a growing demand worldwide for scalable, affordable, and
accessible health care solutions, the use of AI offers tremendous
potential to improve emotional well-being. To realize this potential, it
is imperative that AI service providers prioritize clear and consistent
ethical guidelines that align with global considerations regarding user
safety and privacy. This report offers a template for an ethical code
that can be implemented by other emotional AI services and their
affiliates. It includes practical guidelines for integrating support
from clients, collaborators, and research partners. It also shows how
existing ethical systems can inform the development of AI ethics.","Joerin, Angela and Rauws, Michiel and Fulmer, Russell and Black, Valerie",CUREUS JOURNAL OF MEDICAL SCIENCE,,2020,10.7759/cureus.7202,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:001011268400001,"To chat or bot to chat: Ethical issues with using chatbots in mental
health","This paper presents a critical review of key ethical issues raised by
the emergence of mental health chatbots. Chatbots use varying degrees of
artificial intelligence and are increasingly deployed in many different
domains including mental health. The technology may sometimes be
beneficial, such as when it promotes access to mental health information
and services. Yet, chatbots raise a variety of ethical concerns that are
often magnified in people experiencing mental ill-health. These ethical
challenges need to be appreciated and addressed throughout the
technology pipeline. After identifying and examining four important
ethical issues by means of a recognised ethical framework comprised of
five key principles, the paper offers recommendations to guide chatbot
designers, purveyers, researchers and mental health practitioners in the
ethical creation and deployment of chatbots for mental health.","Coghlan, Simon and Leins, Kobi and Sheldrick, Susie and Cheong, Marc and
Gooding, Piers and D'Alfonso, Simon",DIGITAL HEALTH,,2023,10.1177/20552076231183542,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000462004900001,"Can Your Phone Be Your Therapist? Young People's Ethical Perspectives on
the Use of Fully Automated Conversational Agents (Chatbots) in Mental
Health Support","Over the last decade, there has been an explosion of digital
interventions that aim to either supplement or replace face-to-face
mental health services. More recently. a number of automated
conversational agents have also been made available. which respond to
users in ways that mirror a real-life interaction. What are the social
and ethical concerns that arise from these advances? In this article. we
discuss, from a young person's perspective, the strengths and
limitations of using chatbots in mental health support. We also outline
what we consider to be minimum ethical standards for these platforms.
including issues surrounding privacy and confidentiality. efficacy. and
safety. and review three existing platforms (Woebot. Joy. and Wysa)
according to our proposed framework. It is our hope that this article
will stimulate ethical debate among app developers. practitioners. young
people. and other stakeholders. and inspire ethically responsible
practice in digital mental health.","Kretzschmar, Kira and Tyroll, Holly and Pavarini, Gabriela and Manzini,
Arianna and Singh, Ilina and Sharudin, Aysha and Pavlov, Boris and
Davis, Charlie and Mooney, Daniel and Kibble, Eleyna and Tuckwell,
George and Lewis, Grace and Heelas, Jasmine and Dixon, James and
Bransby-Meehan, Jessica and Katz, Jessica and Seeney, Laura and Lee,
Angela and Allegri, Martino and Beard, Maud and Aithani, Nav and Lumbis,
Nellie and Walker, Niahm and Macfarlane, Poppy and Bonnett, Samantha and
Martin, Sophie and Speakman, Sophie and NeurOx Young Peoples Advisory
Grp",BIOMEDICAL INFORMATICS INSIGHTS,,2019,10.1177/1178222619829083,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:001034069900001,Applying the Digital Health Social Justice Guide,"Introduction Digital health, the use of apps, text-messaging, and online
interventions, can revolutionize healthcare and make care more
equitable. Currently, digital health interventions are often not
designed for those who could benefit most and may have unintended
consequences. In this paper, we explain how privacy vulnerabilities and
power imbalances, including racism and sexism, continue to influence
health app design and research. We provide guidelines for researchers to
design, report and evaluate digital health studies to maximize social
justice in health.Methods From September 2020 to April 2021, we held
five discussion and brainstorming sessions with researchers, students,
and community partners to develop the guide and the key questions. We
additionally conducted an informal literature review, invited experts to
review our guide, and identified examples from our own digital health
study and other studies.Results We identified five overarching topics
with key questions and subquestions to guide researchers in designing or
evaluating a digital health research study. The overarching topics are:
1. Equitable distribution; 2. Equitable design; 3. Privacy and data
return; 4. Stereotype and bias; 5. Structural racism.Conclusion We
provide a guide with five key topics and questions for social justice
digital health research. Encouraging researchers and practitioners to
ask these questions will help to spark a transformation in digital
health toward more equitable and ethical research. Future work needs to
determine if the quality of studies can improve when researchers use
this guide.","Figueroa, Caroline A. and Murayama, Hikari and Amorim, Priscila Carcamo
and White, Alison and Quiterio, Ashley and Luo, Tiffany and Aguilera,
Adrian and Smith, Angela D. R. and Lyles, Courtney R. and Robinson,
Victoria and von Vacano, Claudia",FRONTIERS IN DIGITAL HEALTH,,2022,10.3389/fdgth.2022.807886,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000895694000004,"AI Technologies for Delivering Government Services to Citizens: Benefits
and Challenges","This research presents a comprehensive understanding of AI in the public
sector based on a review of 78 studies. The literature review indicates
that an AI-analytical model and AI-based automation system are mostly
used at the organizational level whilst AI-recommender and chatbot
applications are implemented within the citizens' services context. The
results reveal that AI benefits such as cost reduction and
decision-making improvements are accrued by governments. Further, the
benefits of personalization and positive user experiences are directly
useful to citizens. The review highlights that developing and adopting
AI, presents two categories of challenges: AI obstacles at the
organizational level, such as employees' resistance, lack of managerial,
and financial support, and second - AI dilemmas linked to citizens such
as AI ambiguity, bias, and privacy. Accordingly, this study provides
recommendations for further research on AI within the government and the
public sector.","Mohamad, Ibrahim and Hughes, Laurie and Dwivedi, Yogesh K. and Alalwan,
Ali Abdallah",,ROLE OF DIGITAL TECHNOLOGIES IN SHAPING THE POST-PANDEMIC WORLD,2022,10.1007/978-3-031-15342-6\_4,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000851402000025,"The Role of AI Chatbots in Mental Health Related Public Services in a
(Post)Pandemic World: A Review and Future Research Agenda","The purpose of this paper is to explore the advances in artificial
intelligence (AI) chatbots as part of public services, mainly when
applied to mental health in today's post-pandemic world. The adoption of
AI chatbots to keep up with basic customer support business activities
is based on extensive knowledge, both from the hard (software
development) and the soft side (increasing the added value to the
service/product). However, using chatbots as extenders of public
services to support mental health in pandemic times is an emerging
research topic. Hence, the paper identifies niche and under-explored
research gaps in state-of-the-art literature, thus contributing to the
body of academic knowledge. The paper adopts a design science approach
to formulate the problem statement, articulate the objectives of target
solutions, and propose a design and development framework for future
mental health chatbots by employing an extensive literature review.
Findings from this paper emphasize considerations of ethical issues and
governance, purposeful and goal-oriented design, and AI-based technology
as critical enablers for designing new mental health chatbots. The paper
contributes to the knowledge by providing clear and structured future
research priorities and offers a framework for designing more effective
and intelligent mental health chatbots that public organizations and
managers may find useful.","Damij, Nadja and Bhattacharya, Suman",,"2022 IEEE TECHNOLOGY AND ENGINEERING MANAGEMENT CONFERENCE (TEMSCON
EUROPE)",2022,10.1109/TEMSCONEUROPE54743.2022.9801962,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000935268200001,"What if the devil is my guardian angel: ChatGPT as a case study of using
chatbots in education","Artificial Intelligence (AI) technologies have been progressing
constantly and being more visible in different aspects of our lives. One
recent phenomenon is ChatGPT, a chatbot with a conversational artificial
intelligence interface that was developed by OpenAI. As one of the most
advanced artificial intelligence applications, ChatGPT has drawn much
public attention across the globe. In this regard, this study examines
ChatGPT in education, among early adopters, through a qualitative
instrumental case study. Conducted in three stages, the first stage of
the study reveals that the public discourse in social media is generally
positive and there is enthusiasm regarding its use in educational
settings. However, there are also voices who are approaching cautiously
using ChatGPT in educational settings. The second stage of the study
examines the case of ChatGPT through lenses of educational
transformation, response quality, usefulness, personality and emotion,
and ethics. In the third and final stage of the study, the investigation
of user experiences through ten educational scenarios revealed various
issues, including cheating, honesty and truthfulness of ChatGPT, privacy
misleading, and manipulation. The findings of this study provide several
research directions that should be considered to ensure a safe and
responsible adoption of chatbots, specifically ChatGPT, in education.","Tlili, Ahmed and Shehata, Boulus and Adarkwah, Michael Agyemang and
Bozkurt, Aras and Hickey, Daniel T. and Huang, Ronghuai and Agyemang,
Brighter",SMART LEARNING ENVIRONMENTS,,2023,10.1186/s40561-023-00237-x,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000546552800001,"Intelligent Conversational Agents in Mental Healthcare Services: A
Thematic Analysis of User Perceptions","Background: The emerging Artificial Intelligence (AI) based
Conversational Agents (CA) capable of delivering evidence-based
psychotherapy presents a unique opportunity to solve longstanding issues
such as social stigma and demand-supply imbalance associated with
traditional mental health care services. However, the emerging
literature points to several socio-ethical challenges which may act as
inhibitors to the adoption in the minds of the consumers. We also
observe a paucity of research focusing on determinants of adoption and
use of AI-based CAs in mental healthcare. In this setting, this study
aims to understand the factors influencing the adoption and use of
Intelligent CAs in mental healthcare by examining the perceptions of
actual users.
Method: The study followed a qualitative approach based on netnography
and used a rigorous iterative thematic analysis of publicly available
user reviews of popular mental health chatbots to develop a
comprehensive framework of factors influencing the user's decision to
adopt mental healthcare CA.
Results: We developed a comprehensive thematic map comprising of four
main themes, namely, perceived risk, perceived benefits, trust, and
perceived anthropomorphism, along with its 12 constituent subthemes that
provides a visualization of the factors that govern the user's adoption
and use of mental healthcare CA.
Conclusions: Insights from our research could guide future research on
mental healthcare CA use behavior. Additionally, it could also aid
designers in framing better design decisions that meet consumer
expectations. Our research could also guide healthcare policymakers and
regulators in integrating this technology into formal healthcare
delivery systems.","Prakash, Ashish Viswanath and Das, Saini",PACIFIC ASIA JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS,,2020,10.17705/1pais.12201,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000627564200007,"Value Co-Creation in Smart Services: A Functional Affordances
Perspective on Smart Personal Assistants","In the realm of smart services, smart personal assistants (SPAs) have
become a popular medium for value co-creation between service providers
and users. The market success of SPAs is largely based on their
innovative material properties, such as natural language user
interfaces, machine learning-powered request handling and service
provision, and anthropomorphism. In different combinations, these
properties offer users entirely new ways to intuitively and
interactively achieve their goals and thus co-create value with service
providers. But how does the nature of the SPA shape value co-creation
processes? In this paper, we look through a functional affordances lens
to theorize about the effects of different types of SPAs (i.e., with
different combinations of material properties) on users' value
co-creation processes. Specifically, we collected SPAs from research and
practice by reviewing scientific literature and web resources, developed
a taxonomy of SPAs' material properties, and performed a cluster
analysis to group SPAs of a similar nature. We then derived 2 general
and 11 cluster-specific propositions on how different material
properties of SPAs can yield different affordances for value
co-creation. With our work, we point out that smart services require
researchers and practitioners to fundamentally rethink value co-creation
as well as revise affordances theory to address the dynamic nature of
smart technology as a service counterpart.","Knote, Robin and Janson, Andreas and Soellner, Matthias and Leimeister,
Jan Marco",JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS,,2021,10.17705/1jais.00667,,webofscience.bib,2023-09-02 14:05:29,Unclassified
WOS:000666754300001,"Monolingual and Cross-Lingual Intent Detection without Training Data in
Target Languages","Due to recent DNN advancements, many NLP problems can be effectively
solved using transformer-based models and supervised data.
Unfortunately, such data is not available in some languages. This
research is based on assumptions that (1) training data can be obtained
by the machine translating it from another language; (2) there are
cross-lingual solutions that work without the training data in the
target language. Consequently, in this research, we use the English
dataset and solve the intent detection problem for five target languages
(German, French, Lithuanian, Latvian, and Portuguese). When seeking the
most accurate solutions, we investigate BERT-based word and sentence
transformers together with eager learning classifiers (CNN, BERT
fine-tuning, FFNN) and lazy learning approach (Cosine similarity as the
memory-based method). We offer and evaluate several strategies to
overcome the data scarcity problem with machine translation,
cross-lingual models, and a combination of the previous two. The
experimental investigation revealed the robustness of sentence
transformers under various cross-lingual conditions. The accuracy equal
to similar to 0.842 is achieved with the English dataset with completely
monolingual models is considered our top-line. However, cross-lingual
approaches demonstrate similar accuracy levels reaching similar to
0.831, similar to 0.829, similar to 0.853, similar to 0.831, and similar
to 0.813 on German, French, Lithuanian, Latvian, and Portuguese
languages.","Kapociute-Dzikiene, Jurgita and Salimbajevs, Askars and Skadins, Raivis",ELECTRONICS,,2021,10.3390/electronics10121412,,webofscience.bib,2023-09-02 14:05:29,Unclassified
